{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86a8f0e",
   "metadata": {},
   "source": [
    "# COS 760 Research Project: Analysing Sentiments for Low-resource African Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a3c357-1a7b-4731-bfb1-c3db6af9d407",
   "metadata": {
    "id": "b3a3c357-1a7b-4731-bfb1-c3db6af9d407"
   },
   "source": [
    "## Group Members: Mihir Arjun, Troy Clark, Hamza Mokiwa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566879365751e0a2",
   "metadata": {
    "id": "566879365751e0a2"
   },
   "source": [
    "### Establishing Baselines with Monolingual Long Short-Term Memory networks(LSTMs) and pre-trained Multilingual transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d058d144-ec71-42a2-ba89-92e7d9062a0d",
   "metadata": {
    "id": "d058d144-ec71-42a2-ba89-92e7d9062a0d"
   },
   "source": "#### First we need to install the datasets"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cc4f81-df43-4e94-8dc6-c84fef76a32c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T08:48:24.488062Z",
     "start_time": "2025-04-30T08:48:21.121613Z"
    },
    "id": "01cc4f81-df43-4e94-8dc6-c84fef76a32c",
    "outputId": "8e2007e2-99c1-419e-a6de-61ce7cb2b609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (0.31.4)\n",
      "Requirement already satisfied: packaging in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\mihir - university\\2025\\cos 760\\project\\nlp-research\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "054dd69e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T14:09:51.019371Z",
     "start_time": "2025-04-30T14:09:49.433052Z"
    },
    "id": "054dd69e",
    "outputId": "9881dfc4-84c9-4e9a-e130-9b364095b515"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Mihir - University\\2025\\COS 760\\Project\\nlp-research\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Swahili (swa) dataset from disk...\n",
      "Swahili dataset loaded!\n",
      "Loading Portuguese (por) dataset from disk...\n",
      "Portuguese dataset loaded!\n",
      "Loading Sesotho (sot) dataset from disk...\n",
      "Sesotho dataset loaded!\n",
      "Swahili dataset size: 1810 examples\n",
      "Portuguese dataset size: 3063 examples\n",
      "Sesotho dataset size: 2177 examples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "def load_local_datasets():\n",
    "    swa_path = \"./datasets/afrisenti/swa\"\n",
    "    por_path = \"./datasets/afrisenti/por\"\n",
    "    sot_path = \"./datasets/news\"\n",
    "\n",
    "    if not all(os.path.exists(path) for path in [swa_path, por_path,sot_path]):\n",
    "        print(\"One or more dataset directories not found. Please check the paths.\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(\"Loading Swahili (swa) dataset from disk...\")\n",
    "    swa_dataset = load_from_disk(swa_path)\n",
    "    print(\"Swahili dataset loaded!\")\n",
    "\n",
    "    print(\"Loading Portuguese (por) dataset from disk...\")\n",
    "    por_dataset = load_from_disk(por_path)\n",
    "    print(\"Portuguese dataset loaded!\")\n",
    "\n",
    "    print(\"Loading Sesotho (sot) dataset from disk...\")\n",
    "    sot_dataset = load_dataset(\"csv\",  data_files=\"datasets/sotho-news/sotho_news_dataset.csv\")\n",
    "    print(\"Sesotho dataset loaded!\")\n",
    "\n",
    "    return swa_dataset, por_dataset, sot_dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    swa, por, sot = load_local_datasets()\n",
    "\n",
    "    if swa is not None:\n",
    "        print(f\"Swahili dataset size: {len(swa['train'])} examples\")\n",
    "    if por is not None:\n",
    "        print(f\"Portuguese dataset size: {len(por['train'])} examples\")\n",
    "    if sot is not None:\n",
    "        print(f\"Sesotho dataset size: {len(sot['train'])} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9822d",
   "metadata": {
    "id": "0bf9822d"
   },
   "source": [
    "## Now that the datasets have been loaded, we can start creating our LSTM baseline models below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2a9bc",
   "metadata": {
    "id": "7cc2a9bc"
   },
   "source": "### First we will build an LSTM model for Swahili"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28f49b",
   "metadata": {
    "id": "3d28f49b",
    "outputId": "ccf43988-a21b-45df-cbf1-d8297d13f708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Swahili dataset loaded successfully!\n",
      "Available columns in train split: ['tweet', 'label']\n",
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 1810\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 453\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 748\n",
      "    })\n",
      "})\n",
      "Train set size: 1810\n",
      "Test set size: 748\n",
      "Validation set size: 453\n",
      "Label mapping: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "Vocabulary size: 3055\n",
      "Model architecture:\n",
      "LSTMSentiment(\n",
      "  (embedding): Embedding(3055, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.55it/s]\n",
      "Epoch 1/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 36.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 0.9255\n",
      "  Val Loss: 0.8964, Val Accuracy: 0.5872, Val F1: 0.4377\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.84it/s]\n",
      "Epoch 2/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 42.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 0.8834\n",
      "  Val Loss: 0.9085, Val Accuracy: 0.5872, Val F1: 0.4720\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.59it/s]\n",
      "Epoch 3/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 32.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 0.8355\n",
      "  Val Loss: 0.9070, Val Accuracy: 0.5960, Val F1: 0.5168\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.93it/s]\n",
      "Epoch 4/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 32.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 0.7643\n",
      "  Val Loss: 0.9697, Val Accuracy: 0.5762, Val F1: 0.4923\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.20it/s]\n",
      "Epoch 5/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 0.6388\n",
      "  Val Loss: 1.0302, Val Accuracy: 0.5497, Val F1: 0.5318\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.23it/s]\n",
      "Epoch 6/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 0.5488\n",
      "  Val Loss: 1.2454, Val Accuracy: 0.5055, Val F1: 0.5120\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.92it/s]\n",
      "Epoch 7/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 28.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 0.4460\n",
      "  Val Loss: 1.2486, Val Accuracy: 0.5585, Val F1: 0.5315\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.64it/s]\n",
      "Epoch 8/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 26.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 0.3874\n",
      "  Val Loss: 1.5211, Val Accuracy: 0.4857, Val F1: 0.4953\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.96it/s]\n",
      "Epoch 9/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 32.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 0.2739\n",
      "  Val Loss: 1.5772, Val Accuracy: 0.5055, Val F1: 0.5088\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.60it/s]\n",
      "Epoch 10/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 35.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 0.2220\n",
      "  Val Loss: 1.5910, Val Accuracy: 0.5541, Val F1: 0.5337\n",
      "------------------------------------------------------------\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:00<00:00, 27.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8965\n",
      "Test Accuracy: 0.5936\n",
      "Test F1 Score: 0.4446\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        80\n",
      "     neutral       0.59      1.00      0.74       444\n",
      "    positive       0.50      0.00      0.01       224\n",
      "\n",
      "    accuracy                           0.59       748\n",
      "   macro avg       0.36      0.33      0.25       748\n",
      "weighted avg       0.50      0.59      0.44       748\n",
      "\n",
      "Results saved to swahili_lstm_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Mihir - University\\2025\\COS 760\\Project\\nlp-research\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Mihir - University\\2025\\COS 760\\Project\\nlp-research\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Mihir - University\\2025\\COS 760\\Project\\nlp-research\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "class SwahiliSentimentDataset(Dataset):\n",
    "    def __init__(self, tweets, labels, vocab, label_map):\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.tweets[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "\n",
    "        tokenized = [self.vocab.get(word, self.vocab['<UNK>']) for word in tweet.split()]\n",
    "        return torch.tensor(tokenized, dtype=torch.long), torch.tensor(self.label_map[label], dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tweets, labels = zip(*batch)\n",
    "\n",
    "    tweets_padded = pad_sequence(tweets, batch_first=True, padding_value=0)\n",
    "    return tweets_padded, torch.stack(labels)\n",
    "\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "                           bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "\n",
    "\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for tweets, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            outputs = model(tweets)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for tweets, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
    "                tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(tweets)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_swahili_lstm_model.pt\")\n",
    "            print(\"  Saved new best model!\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, label_list):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tweets, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(tweets)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "    class_names = [label_list[i] for i in range(len(label_list))]\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return test_loss, test_accuracy, test_f1\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        swa_dataset = load_from_disk(\"./datasets/afrisenti/swa\")\n",
    "        print(\"Swahili dataset loaded successfully!\")\n",
    "\n",
    "        print(f\"Available columns in train split: {swa_dataset['train'].column_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Dataset structure: {swa_dataset}\")\n",
    "    print(f\"Train set size: {len(swa_dataset['train'])}\")\n",
    "    print(f\"Test set size: {len(swa_dataset['test'])}\")\n",
    "    print(f\"Validation set size: {len(swa_dataset['validation'])}\")\n",
    "\n",
    "    train_tweets = swa_dataset['train']['tweet']\n",
    "    train_labels = swa_dataset['train']['label']\n",
    "    val_tweets = swa_dataset['validation']['tweet']\n",
    "    val_labels = swa_dataset['validation']['label']\n",
    "    test_tweets = swa_dataset['test']['tweet']\n",
    "    test_labels = swa_dataset['test']['label']\n",
    "\n",
    "    unique_labels = set(train_labels + val_labels + test_labels)\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "    print(f\"Label mapping: {label_to_idx}\")\n",
    "\n",
    "    word_counts = Counter()\n",
    "    for tweet in train_tweets:\n",
    "        word_counts.update(tweet.split())\n",
    "\n",
    "    min_freq = 2\n",
    "    vocabulary = {'<PAD>': 0, '<UNK>': 1}\n",
    "    vocab_idx = 2\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocabulary[word] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "\n",
    "    print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "    train_dataset = SwahiliSentimentDataset(train_tweets, train_labels, vocabulary, label_to_idx)\n",
    "    val_dataset = SwahiliSentimentDataset(val_tweets, val_labels, vocabulary, label_to_idx)\n",
    "    test_dataset = SwahiliSentimentDataset(test_tweets, test_labels, vocabulary, label_to_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    model = LSTMSentiment(\n",
    "        vocab_size=len(vocabulary),\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=len(unique_labels),\n",
    "        n_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=vocabulary['<PAD>']\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"Model architecture:\\n{model}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_swahili_lstm_model.pt\"))\n",
    "\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_f1 = evaluate_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        label_list=list(idx_to_label.values())\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"num_layers\": NUM_LAYERS,\n",
    "        \"dropout\": DROPOUT,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"vocab_size\": len(vocabulary)\n",
    "    }\n",
    "\n",
    "\n",
    "    pd.DataFrame([results]).to_csv(\"swahili_lstm_results.csv\", index=False)\n",
    "    print(f\"Results saved to swahili_lstm_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e693c96",
   "metadata": {
    "id": "5e693c96"
   },
   "source": "### Next, we build an LSTM model for Mozambican Portuguese:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e04f9",
   "metadata": {
    "id": "d62e04f9",
    "outputId": "bdcd025b-048b-42a1-acf7-7381b7015aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Mozambican Portuguese dataset loaded successfully!\n",
      "Available columns in train split: ['tweet', 'label']\n",
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 3063\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 767\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 3662\n",
      "    })\n",
      "})\n",
      "Train set size: 3063\n",
      "Test set size: 3662\n",
      "Validation set size: 767\n",
      "Label mapping: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "Vocabulary size: 4075\n",
      "Model architecture:\n",
      "LSTMSentiment(\n",
      "  (embedding): Embedding(4075, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 96/96 [00:12<00:00,  7.80it/s]\n",
      "Epoch 1/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 19.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 1.0226\n",
      "  Val Loss: 0.9994, Val Accuracy: 0.5215, Val F1: 0.3575\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|██████████| 96/96 [00:15<00:00,  6.37it/s]\n",
      "Epoch 2/10 - Validation: 100%|██████████| 24/24 [00:00<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 0.9703\n",
      "  Val Loss: 0.9651, Val Accuracy: 0.5450, Val F1: 0.4652\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  6.98it/s]\n",
      "Epoch 3/10 - Validation: 100%|██████████| 24/24 [00:00<00:00, 24.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 0.8965\n",
      "  Val Loss: 0.9932, Val Accuracy: 0.5567, Val F1: 0.4923\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  6.95it/s]\n",
      "Epoch 4/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 20.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 0.7983\n",
      "  Val Loss: 0.9902, Val Accuracy: 0.5606, Val F1: 0.5459\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|██████████| 96/96 [00:14<00:00,  6.67it/s]\n",
      "Epoch 5/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 0.6935\n",
      "  Val Loss: 1.0411, Val Accuracy: 0.5528, Val F1: 0.5396\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  6.92it/s]\n",
      "Epoch 6/10 - Validation: 100%|██████████| 24/24 [00:00<00:00, 25.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 0.5816\n",
      "  Val Loss: 1.1400, Val Accuracy: 0.5424, Val F1: 0.5358\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  7.09it/s]\n",
      "Epoch 7/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 21.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 0.4691\n",
      "  Val Loss: 1.2334, Val Accuracy: 0.5593, Val F1: 0.5388\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|██████████| 96/96 [00:14<00:00,  6.71it/s]\n",
      "Epoch 8/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 0.3591\n",
      "  Val Loss: 1.4979, Val Accuracy: 0.5332, Val F1: 0.5243\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  7.02it/s]\n",
      "Epoch 9/10 - Validation: 100%|██████████| 24/24 [00:00<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 0.3022\n",
      "  Val Loss: 1.4727, Val Accuracy: 0.5111, Val F1: 0.5080\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  6.88it/s]\n",
      "Epoch 10/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 0.2282\n",
      "  Val Loss: 1.6321, Val Accuracy: 0.5332, Val F1: 0.5234\n",
      "------------------------------------------------------------\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 115/115 [00:04<00:00, 25.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8757\n",
      "Test Accuracy: 0.6393\n",
      "Test F1 Score: 0.5655\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.15      0.21       655\n",
      "     neutral       0.67      0.92      0.78      2379\n",
      "    positive       0.62      0.08      0.14       628\n",
      "\n",
      "    accuracy                           0.64      3662\n",
      "   macro avg       0.54      0.38      0.37      3662\n",
      "weighted avg       0.60      0.64      0.57      3662\n",
      "\n",
      "Results saved to portuguese_lstm_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "class PorSentimentDataset(Dataset):\n",
    "    def __init__(self, tweets, labels, vocab, label_map):\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.tweets[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        tokenized = [self.vocab.get(word, self.vocab['<UNK>']) for word in tweet.split()]\n",
    "        return torch.tensor(tokenized, dtype=torch.long), torch.tensor(self.label_map[label], dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tweets, labels = zip(*batch)\n",
    "    tweets_padded = pad_sequence(tweets, batch_first=True, padding_value=0)\n",
    "    return tweets_padded, torch.stack(labels)\n",
    "\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "                           bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for tweets, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(tweets)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for tweets, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
    "                tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(tweets)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_portuguese_lstm_model.pt\")\n",
    "            print(\"  Saved new best model!\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, label_list):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tweets, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(tweets)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    class_names = [label_list[i] for i in range(len(label_list))]\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return test_loss, test_accuracy, test_f1\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    try:\n",
    "        por_dataset = load_from_disk(\"./datasets/afrisenti/por\")\n",
    "        print(\"Mozambican Portuguese dataset loaded successfully!\")\n",
    "\n",
    "        print(f\"Available columns in train split: {por_dataset['train'].column_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Dataset structure: {por_dataset}\")\n",
    "    print(f\"Train set size: {len(por_dataset['train'])}\")\n",
    "    print(f\"Test set size: {len(por_dataset['test'])}\")\n",
    "    print(f\"Validation set size: {len(por_dataset['validation'])}\")\n",
    "\n",
    "    train_tweets = por_dataset['train']['tweet']\n",
    "    train_labels = por_dataset['train']['label']\n",
    "    val_tweets = por_dataset['validation']['tweet']\n",
    "    val_labels = por_dataset['validation']['label']\n",
    "    test_tweets = por_dataset['test']['tweet']\n",
    "    test_labels = por_dataset['test']['label']\n",
    "\n",
    "    unique_labels = set(train_labels + val_labels + test_labels)\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "    print(f\"Label mapping: {label_to_idx}\")\n",
    "\n",
    "    word_counts = Counter()\n",
    "    for tweet in train_tweets:\n",
    "        word_counts.update(tweet.split())\n",
    "\n",
    "    min_freq = 2\n",
    "    vocabulary = {'<PAD>': 0, '<UNK>': 1}\n",
    "    vocab_idx = 2\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocabulary[word] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "\n",
    "    print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "    train_dataset = PorSentimentDataset(train_tweets, train_labels, vocabulary, label_to_idx)\n",
    "    val_dataset = PorSentimentDataset(val_tweets, val_labels, vocabulary, label_to_idx)\n",
    "    test_dataset = PorSentimentDataset(test_tweets, test_labels, vocabulary, label_to_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    model = LSTMSentiment(\n",
    "        vocab_size=len(vocabulary),\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=len(unique_labels),\n",
    "        n_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=vocabulary['<PAD>']\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"Model architecture:\\n{model}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_portuguese_lstm_model.pt\"))\n",
    "\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_f1 = evaluate_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        label_list=list(idx_to_label.values())\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"num_layers\": NUM_LAYERS,\n",
    "        \"dropout\": DROPOUT,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"vocab_size\": len(vocabulary)\n",
    "    }\n",
    "\n",
    "\n",
    "    pd.DataFrame([results]).to_csv(\"portuguese_lstm_results.csv\", index=False)\n",
    "    print(f\"Results saved to portuguese_lstm_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b24b1c44eb59b2",
   "metadata": {
    "id": "23b24b1c44eb59b2"
   },
   "source": "### Lastly, we build an LSTM model for Sesotho\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed05fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:44:06.391800Z",
     "start_time": "2025-05-03T07:43:58.107727Z"
    },
    "id": "0ed05fc8",
    "outputId": "895e8856-7a7a-4670-fb05-5811f6f236fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Sesotho dataset loaded successfully!\n",
      "Available columns in train split: ['headline', 'label', '__index_level_0__']\n",
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['headline', 'label', '__index_level_0__'],\n",
      "        num_rows: 1305\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['headline', 'label', '__index_level_0__'],\n",
      "        num_rows: 436\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['headline', 'label', '__index_level_0__'],\n",
      "        num_rows: 436\n",
      "    })\n",
      "})\n",
      "Train set size: 1305\n",
      "Test set size: 436\n",
      "Validation set size: 436\n",
      "Label mapping: {'neutral': 0, 'negative': 1, 'positive': 2}\n",
      "Vocabulary size: 876\n",
      "Model architecture:\n",
      "LSTMSentiment(\n",
      "  (embedding): Embedding(876, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 50.00it/s]\n",
      "Epoch 1/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 212.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 0.7751\n",
      "  Val Loss: 0.7289, Val Accuracy: 0.6950, Val F1: 0.5699\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 51.51it/s]\n",
      "Epoch 2/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 202.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 0.6275\n",
      "  Val Loss: 0.7368, Val Accuracy: 0.7179, Val F1: 0.6419\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 52.90it/s]\n",
      "Epoch 3/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 215.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 0.5516\n",
      "  Val Loss: 0.7012, Val Accuracy: 0.7317, Val F1: 0.6920\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 56.79it/s]\n",
      "Epoch 4/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 200.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 0.5039\n",
      "  Val Loss: 0.7370, Val Accuracy: 0.7385, Val F1: 0.6711\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 57.91it/s]\n",
      "Epoch 5/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 212.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 0.4261\n",
      "  Val Loss: 0.7007, Val Accuracy: 0.7271, Val F1: 0.7154\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 55.86it/s]\n",
      "Epoch 6/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 215.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 0.3852\n",
      "  Val Loss: 0.7299, Val Accuracy: 0.7638, Val F1: 0.7379\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 59.33it/s]\n",
      "Epoch 7/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 218.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 0.2882\n",
      "  Val Loss: 0.7523, Val Accuracy: 0.7454, Val F1: 0.7287\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 58.32it/s]\n",
      "Epoch 8/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 218.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 0.2573\n",
      "  Val Loss: 0.7572, Val Accuracy: 0.7156, Val F1: 0.7123\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 57.66it/s]\n",
      "Epoch 9/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 199.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 0.1974\n",
      "  Val Loss: 0.8882, Val Accuracy: 0.7271, Val F1: 0.7143\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 53.81it/s]\n",
      "Epoch 10/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 222.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 0.1676\n",
      "  Val Loss: 0.9858, Val Accuracy: 0.7385, Val F1: 0.7134\n",
      "------------------------------------------------------------\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 14/14 [00:00<00:00, 237.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9303\n",
      "Test Accuracy: 0.7202\n",
      "Test F1 Score: 0.7024\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.83      0.25      0.38        20\n",
      "    negative       0.77      0.87      0.82       308\n",
      "    positive       0.49      0.38      0.43       108\n",
      "\n",
      "    accuracy                           0.72       436\n",
      "   macro avg       0.70      0.50      0.54       436\n",
      "weighted avg       0.71      0.72      0.70       436\n",
      "\n",
      "Results saved to sesotho_lstm_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "class SotSentimentDataset(Dataset):\n",
    "    def __init__(self, headlines, labels, vocab, label_map):\n",
    "        self.headlines = headlines\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.headlines[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "\n",
    "        tokenized = [self.vocab.get(word, self.vocab['<UNK>']) for word in tweet.split()]\n",
    "        return torch.tensor(tokenized, dtype=torch.long), torch.tensor(self.label_map[label], dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    headlines, labels = zip(*batch)\n",
    "\n",
    "    headlines_padded = pad_sequence(headlines, batch_first=True, padding_value=0)\n",
    "    return headlines_padded, torch.stack(labels)\n",
    "\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "                           bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "\n",
    "\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for headlines, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            headlines, labels = headlines.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            outputs = model(headlines)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for headlines, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
    "                headlines, labels = headlines.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(headlines)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_portuguese_lstm_model.pt\")\n",
    "            print(\"  Saved new best model!\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, label_list):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for headlines, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            headlines, labels = headlines.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(headlines)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "    class_names = [label_list[i] for i in range(len(label_list))]\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return test_loss, test_accuracy, test_f1\n",
    "\n",
    "def main():\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        sot_dataset = load_from_disk(\"./datasets/sesotho_news_dataset\")\n",
    "        print(\"Sesotho dataset loaded successfully!\")\n",
    "\n",
    "\n",
    "        print(f\"Available columns in train split: {sot_dataset['train'].column_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    print(f\"Dataset structure: {sot_dataset}\")\n",
    "    print(f\"Train set size: {len(sot_dataset['train'])}\")\n",
    "    print(f\"Test set size: {len(sot_dataset['test'])}\")\n",
    "    print(f\"Validation set size: {len(sot_dataset['validation'])}\")\n",
    "\n",
    "\n",
    "    train_headlines = sot_dataset['train']['headline']\n",
    "    train_labels = sot_dataset['train']['label']\n",
    "    val_headlines = sot_dataset['validation']['headline']\n",
    "    val_labels = sot_dataset['validation']['label']\n",
    "    test_headlines = sot_dataset['test']['headline']\n",
    "    test_labels = sot_dataset['test']['label']\n",
    "\n",
    "\n",
    "\n",
    "    unique_labels = set(train_labels + val_labels + test_labels)\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "    print(f\"Label mapping: {label_to_idx}\")\n",
    "\n",
    "\n",
    "    word_counts = Counter()\n",
    "    for headline in train_headlines:\n",
    "        word_counts.update(headline.split())\n",
    "\n",
    "\n",
    "    min_freq = 2\n",
    "    vocabulary = {'<PAD>': 0, '<UNK>': 1}\n",
    "    vocab_idx = 2\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocabulary[word] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "\n",
    "    print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "\n",
    "    train_dataset = SotSentimentDataset(train_headlines, train_labels, vocabulary, label_to_idx)\n",
    "    val_dataset = SotSentimentDataset(val_headlines, val_labels, vocabulary, label_to_idx)\n",
    "    test_dataset = SotSentimentDataset(test_headlines, test_labels, vocabulary, label_to_idx)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "    model = LSTMSentiment(\n",
    "        vocab_size=len(vocabulary),\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=len(unique_labels),\n",
    "        n_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=vocabulary['<PAD>']\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "    print(f\"Model architecture:\\n{model}\")\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), \"best_sesotho_lstm_model.pt\");\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_sesotho_lstm_model.pt\"))\n",
    "\n",
    "\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_f1 = evaluate_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        label_list=list(idx_to_label.values())\n",
    "    )\n",
    "\n",
    "\n",
    "    results = {\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"num_layers\": NUM_LAYERS,\n",
    "        \"dropout\": DROPOUT,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"vocab_size\": len(vocabulary)\n",
    "    }\n",
    "\n",
    "\n",
    "    pd.DataFrame([results]).to_csv(\"sesotho_lstm_results.csv\", index=False)\n",
    "    print(f\"Results saved to sesotho_lstm_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5c5f7b5502b53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:43:38.538623Z",
     "start_time": "2025-05-03T07:43:38.497686Z"
    },
    "id": "55f5c5f7b5502b53",
    "outputId": "f9d260ae-74e5-46ad-c252-cfbc7ff3a8ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1305/1305 [00:00<00:00, 326273.65 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 436/436 [00:00<00:00, 109014.40 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 436/436 [00:00<00:00, 145297.68 examples/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bbb7afbfe25ad22",
   "metadata": {
    "id": "5bbb7afbfe25ad22"
   },
   "source": "# We now create Baselines with pre-trained Multilingual transformers"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## AfroXLMR\n",
   "id": "288861ae8072fb15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaab94162e258de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T10:23:51.886403Z",
     "start_time": "2025-05-17T10:23:43.459518Z"
    },
    "id": "2aaab94162e258de",
    "outputId": "1e65fc6d-a6e0-4a6a-8434-edb89d881d27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets peft evaluate plotly --quiet\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# por_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"pt-MZ\")\n",
    "# swa_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"swa\")\n",
    "# sot_dataset=load_dataset(\"hamza-student-123/nlp-assignment-news-data\",'sot')\n",
    "#\n",
    "# for ds in [por_dataset,swa_dataset,sot_dataset]: # Change to all three later\n",
    "#     for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "#         if ds[lbl].column_names[0]== \"tweet\":\n",
    "#             ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "#         else:\n",
    "#             ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "#\n",
    "# por_df = por_dataset[\"train\"].to_pandas()\n",
    "# swa_df = swa_dataset[\"train\"].to_pandas()\n",
    "# sot_df = sot_dataset[\"train\"].to_pandas()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Baseline with [AfroXLMR](https://huggingface.co/Davlan/afro-xlmr-large)\n",
   "id": "febee723e76e99d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd162b829f304976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T10:44:54.201226Z",
     "start_time": "2025-05-20T07:13:00.134826Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 6539283,
     "status": "error",
     "timestamp": 1747593813857,
     "user": {
      "displayName": "Hamza Mokiwa",
      "userId": "01797446784641706967"
     },
     "user_tz": -120
    },
    "id": "bd162b829f304976",
    "outputId": "bd393c51-1f99-4a82-9bf0-8d4ae2b385c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-20 09:13:11,166 - INFO - Using device: cpu\n",
      "2025-05-20 09:13:11,167 - INFO - Loading model: Davlan/afro-xlmr-base...\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-20 09:13:13,444 - INFO - Loading data...\n",
      "2025-05-20 09:13:17,088 - INFO - Data loaded successfully: 3063 training, 767 validation, 3662 test examples\n",
      "2025-05-20 09:13:17,089 - INFO - Creating data loaders...\n",
      "2025-05-20 09:13:17,093 - INFO - Starting training...\n",
      "2025-05-20 09:13:17,093 - INFO - Epoch 1/10\n",
      "Training: 100%|██████████| 192/192 [16:16<00:00,  5.09s/it, loss=1.0726]\n",
      "Evaluating: 100%|██████████| 48/48 [00:47<00:00,  1.02it/s]\n",
      "2025-05-20 09:30:21,098 - INFO - Epoch 1 results:\n",
      "2025-05-20 09:30:21,099 - INFO - Train Loss: 0.9542, Time: 976.75s\n",
      "2025-05-20 09:30:21,100 - INFO - Val Loss: 0.9054, Accuracy: 0.5515, Precision: 0.5978, Recall: 0.5515, F1: 0.5506\n",
      "2025-05-20 09:30:21,102 - INFO - New best model with F1: 0.5506\n",
      "2025-05-20 09:30:21,102 - INFO - Epoch 2/10\n",
      "Training: 100%|██████████| 192/192 [17:11<00:00,  5.37s/it, loss=0.8349]\n",
      "Evaluating: 100%|██████████| 48/48 [00:50<00:00,  1.05s/it]\n",
      "2025-05-20 09:48:23,713 - INFO - Epoch 2 results:\n",
      "2025-05-20 09:48:23,714 - INFO - Train Loss: 0.7844, Time: 1032.00s\n",
      "2025-05-20 09:48:23,715 - INFO - Val Loss: 0.7728, Accuracy: 0.6610, Precision: 0.6649, Recall: 0.6610, F1: 0.6618\n",
      "2025-05-20 09:48:23,717 - INFO - New best model with F1: 0.6618\n",
      "2025-05-20 09:48:23,717 - INFO - Epoch 3/10\n",
      "Training: 100%|██████████| 192/192 [17:15<00:00,  5.39s/it, loss=0.9245]\n",
      "Evaluating: 100%|██████████| 48/48 [00:51<00:00,  1.07s/it]\n",
      "2025-05-20 10:06:30,717 - INFO - Epoch 3 results:\n",
      "2025-05-20 10:06:30,718 - INFO - Train Loss: 0.6774, Time: 1035.69s\n",
      "2025-05-20 10:06:30,719 - INFO - Val Loss: 0.7805, Accuracy: 0.6571, Precision: 0.6705, Recall: 0.6571, F1: 0.6601\n",
      "2025-05-20 10:06:30,719 - INFO - Epoch 4/10\n",
      "Training: 100%|██████████| 192/192 [16:31<00:00,  5.17s/it, loss=0.4034]\n",
      "Evaluating: 100%|██████████| 48/48 [00:49<00:00,  1.04s/it]\n",
      "2025-05-20 10:23:52,577 - INFO - Epoch 4 results:\n",
      "2025-05-20 10:23:52,577 - INFO - Train Loss: 0.5652, Time: 991.88s\n",
      "2025-05-20 10:23:52,578 - INFO - Val Loss: 0.8392, Accuracy: 0.6623, Precision: 0.6678, Recall: 0.6623, F1: 0.6631\n",
      "2025-05-20 10:23:52,580 - INFO - New best model with F1: 0.6631\n",
      "2025-05-20 10:23:52,580 - INFO - Epoch 5/10\n",
      "Training: 100%|██████████| 192/192 [17:29<00:00,  5.46s/it, loss=0.7792]\n",
      "Evaluating: 100%|██████████| 48/48 [00:51<00:00,  1.07s/it]\n",
      "2025-05-20 10:42:13,308 - INFO - Epoch 5 results:\n",
      "2025-05-20 10:42:13,309 - INFO - Train Loss: 0.4695, Time: 1049.16s\n",
      "2025-05-20 10:42:13,309 - INFO - Val Loss: 0.8688, Accuracy: 0.6688, Precision: 0.6784, Recall: 0.6688, F1: 0.6704\n",
      "2025-05-20 10:42:13,312 - INFO - New best model with F1: 0.6704\n",
      "2025-05-20 10:42:13,313 - INFO - Epoch 6/10\n",
      "Training: 100%|██████████| 192/192 [16:40<00:00,  5.21s/it, loss=0.1259]\n",
      "Evaluating: 100%|██████████| 48/48 [00:49<00:00,  1.03s/it]\n",
      "2025-05-20 10:59:43,801 - INFO - Epoch 6 results:\n",
      "2025-05-20 10:59:43,802 - INFO - Train Loss: 0.3940, Time: 1000.95s\n",
      "2025-05-20 10:59:43,802 - INFO - Val Loss: 0.9208, Accuracy: 0.6806, Precision: 0.6809, Recall: 0.6806, F1: 0.6807\n",
      "2025-05-20 10:59:43,805 - INFO - New best model with F1: 0.6807\n",
      "2025-05-20 10:59:43,805 - INFO - Epoch 7/10\n",
      "Training: 100%|██████████| 192/192 [17:19<00:00,  5.41s/it, loss=0.2641]\n",
      "Evaluating: 100%|██████████| 48/48 [00:47<00:00,  1.01it/s]\n",
      "2025-05-20 11:17:50,935 - INFO - Epoch 7 results:\n",
      "2025-05-20 11:17:50,935 - INFO - Train Loss: 0.3406, Time: 1039.54s\n",
      "2025-05-20 11:17:50,936 - INFO - Val Loss: 1.0043, Accuracy: 0.6662, Precision: 0.6648, Recall: 0.6662, F1: 0.6641\n",
      "2025-05-20 11:17:50,936 - INFO - Epoch 8/10\n",
      "Training: 100%|██████████| 192/192 [15:46<00:00,  4.93s/it, loss=0.0379]\n",
      "Evaluating: 100%|██████████| 48/48 [00:46<00:00,  1.04it/s]\n",
      "2025-05-20 11:34:23,340 - INFO - Epoch 8 results:\n",
      "2025-05-20 11:34:23,341 - INFO - Train Loss: 0.2807, Time: 946.08s\n",
      "2025-05-20 11:34:23,341 - INFO - Val Loss: 1.0684, Accuracy: 0.6636, Precision: 0.6645, Recall: 0.6636, F1: 0.6630\n",
      "2025-05-20 11:34:23,342 - INFO - Epoch 9/10\n",
      "Training: 100%|██████████| 192/192 [15:45<00:00,  4.92s/it, loss=0.5671]\n",
      "Evaluating: 100%|██████████| 48/48 [00:46<00:00,  1.03it/s]\n",
      "2025-05-20 11:50:55,335 - INFO - Epoch 9 results:\n",
      "2025-05-20 11:50:55,336 - INFO - Train Loss: 0.2516, Time: 945.49s\n",
      "2025-05-20 11:50:55,336 - INFO - Val Loss: 1.1093, Accuracy: 0.6623, Precision: 0.6627, Recall: 0.6623, F1: 0.6612\n",
      "2025-05-20 11:50:55,337 - INFO - Epoch 10/10\n",
      "Training: 100%|██████████| 192/192 [15:49<00:00,  4.94s/it, loss=0.0142]\n",
      "Evaluating: 100%|██████████| 48/48 [00:47<00:00,  1.02it/s]\n",
      "2025-05-20 12:07:31,892 - INFO - Epoch 10 results:\n",
      "2025-05-20 12:07:31,892 - INFO - Train Loss: 0.2138, Time: 949.30s\n",
      "2025-05-20 12:07:31,893 - INFO - Val Loss: 1.1290, Accuracy: 0.6636, Precision: 0.6637, Recall: 0.6636, F1: 0.6634\n",
      "2025-05-20 12:07:31,894 - INFO - Loading best model for testing...\n",
      "2025-05-20 12:07:31,899 - INFO - Evaluating on test set...\n",
      "Evaluating: 100%|██████████| 229/229 [03:43<00:00,  1.03it/s]\n",
      "2025-05-20 12:11:15,238 - INFO - Test Results:\n",
      "2025-05-20 12:11:15,239 - INFO - Loss: 1.0980\n",
      "2025-05-20 12:11:15,240 - INFO - Accuracy: 0.6674\n",
      "2025-05-20 12:11:15,241 - INFO - Precision: 0.6926\n",
      "2025-05-20 12:11:15,241 - INFO - Recall: 0.6674\n",
      "2025-05-20 12:11:15,241 - INFO - F1 Score: 0.6751\n",
      "2025-05-20 12:11:15,255 - INFO - Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to afroxlmr_results_por.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:11:17,558 - INFO - Model saved to ./xmlr_sentiment_model_por\n",
      "2025-05-20 12:11:17,675 - INFO - Using device: cpu\n",
      "2025-05-20 12:11:17,676 - INFO - Loading model: Davlan/afro-xlmr-base...\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-20 12:11:20,054 - INFO - Loading data...\n",
      "2025-05-20 12:11:21,866 - INFO - Data loaded successfully: 1810 training, 453 validation, 748 test examples\n",
      "2025-05-20 12:11:21,867 - INFO - Creating data loaders...\n",
      "2025-05-20 12:11:21,868 - INFO - Starting training...\n",
      "2025-05-20 12:11:21,869 - INFO - Epoch 1/10\n",
      "Training: 100%|██████████| 114/114 [10:14<00:00,  5.39s/it, loss=0.9087]\n",
      "Evaluating: 100%|██████████| 29/29 [00:27<00:00,  1.04it/s]\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-20 12:22:04,868 - INFO - Epoch 1 results:\n",
      "2025-05-20 12:22:04,869 - INFO - Train Loss: 0.9067, Time: 615.00s\n",
      "2025-05-20 12:22:04,870 - INFO - Val Loss: 0.8670, Accuracy: 0.6115, Precision: 0.5303, Recall: 0.6115, F1: 0.5535\n",
      "2025-05-20 12:22:04,871 - INFO - New best model with F1: 0.5535\n",
      "2025-05-20 12:22:04,872 - INFO - Epoch 2/10\n",
      "Training: 100%|██████████| 114/114 [09:56<00:00,  5.23s/it, loss=0.6659]\n",
      "Evaluating: 100%|██████████| 29/29 [00:29<00:00,  1.02s/it]\n",
      "2025-05-20 12:32:31,063 - INFO - Epoch 2 results:\n",
      "2025-05-20 12:32:31,064 - INFO - Train Loss: 0.7680, Time: 596.68s\n",
      "2025-05-20 12:32:31,065 - INFO - Val Loss: 0.8396, Accuracy: 0.5872, Precision: 0.5999, Recall: 0.5872, F1: 0.5874\n",
      "2025-05-20 12:32:31,067 - INFO - New best model with F1: 0.5874\n",
      "2025-05-20 12:32:31,068 - INFO - Epoch 3/10\n",
      "Training: 100%|██████████| 114/114 [10:02<00:00,  5.28s/it, loss=1.0694]\n",
      "Evaluating: 100%|██████████| 29/29 [00:29<00:00,  1.00s/it]\n",
      "2025-05-20 12:43:02,163 - INFO - Epoch 3 results:\n",
      "2025-05-20 12:43:02,164 - INFO - Train Loss: 0.6360, Time: 602.02s\n",
      "2025-05-20 12:43:02,165 - INFO - Val Loss: 0.8412, Accuracy: 0.6313, Precision: 0.6124, Recall: 0.6313, F1: 0.6102\n",
      "2025-05-20 12:43:02,167 - INFO - New best model with F1: 0.6102\n",
      "2025-05-20 12:43:02,168 - INFO - Epoch 4/10\n",
      "Training:  18%|█▊        | 20/114 [01:51<08:41,  5.55s/it, loss=0.6072]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 327\u001B[39m\n\u001B[32m    325\u001B[39m \u001B[38;5;66;03m# langs = ['sot']\u001B[39;00m\n\u001B[32m    326\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m langs:\n\u001B[32m--> \u001B[39m\u001B[32m327\u001B[39m     \u001B[43mevaluate_afro_xlmr_for_lang\u001B[49m\u001B[43m(\u001B[49m\u001B[43ml\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 269\u001B[39m, in \u001B[36mevaluate_afro_xlmr_for_lang\u001B[39m\u001B[34m(language)\u001B[39m\n\u001B[32m    267\u001B[39m \u001B[38;5;66;03m# Train\u001B[39;00m\n\u001B[32m    268\u001B[39m start_time = time.time()\n\u001B[32m--> \u001B[39m\u001B[32m269\u001B[39m train_loss = \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# train_epoch(model, train_loader, scheduler, device)\u001B[39;00m\n\u001B[32m    270\u001B[39m train_time = time.time() - start_time\n\u001B[32m    272\u001B[39m \u001B[38;5;66;03m# Validate\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 155\u001B[39m, in \u001B[36mtrain_epoch\u001B[39m\u001B[34m(model, dataloader, optimizer, scheduler, device)\u001B[39m\n\u001B[32m    153\u001B[39m loss.backward()\n\u001B[32m    154\u001B[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001B[32m1.0\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m155\u001B[39m \u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    156\u001B[39m scheduler.step()\n\u001B[32m    158\u001B[39m progress_bar.set_postfix({\u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss.item()\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m})\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:124\u001B[39m, in \u001B[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    122\u001B[39m opt = opt_ref()\n\u001B[32m    123\u001B[39m opt._opt_called = \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__get__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__class__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001B[39m, in \u001B[36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    480\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    481\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    482\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    483\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m485\u001B[39m out = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    486\u001B[39m \u001B[38;5;28mself\u001B[39m._optimizer_step_code()\n\u001B[32m    488\u001B[39m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001B[39m, in \u001B[36m_use_grad_for_differentiable.<locals>._use_grad\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     77\u001B[39m     torch.set_grad_enabled(\u001B[38;5;28mself\u001B[39m.defaults[\u001B[33m\"\u001B[39m\u001B[33mdifferentiable\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     78\u001B[39m     torch._dynamo.graph_break()\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m     ret = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     81\u001B[39m     torch._dynamo.graph_break()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001B[39m, in \u001B[36mAdam.step\u001B[39m\u001B[34m(self, closure)\u001B[39m\n\u001B[32m    234\u001B[39m     beta1, beta2 = group[\u001B[33m\"\u001B[39m\u001B[33mbetas\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    236\u001B[39m     has_complex = \u001B[38;5;28mself\u001B[39m._init_group(\n\u001B[32m    237\u001B[39m         group,\n\u001B[32m    238\u001B[39m         params_with_grad,\n\u001B[32m   (...)\u001B[39m\u001B[32m    243\u001B[39m         state_steps,\n\u001B[32m    244\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m246\u001B[39m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    250\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    251\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mamsgrad\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    256\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    257\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    258\u001B[39m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweight_decay\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    259\u001B[39m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43meps\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    260\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmaximize\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    261\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mforeach\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    262\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcapturable\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    263\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdifferentiable\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    264\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfused\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    265\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mgrad_scale\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    266\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfound_inf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    267\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdecoupled_weight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdecoupled_weight_decay\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    268\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    270\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001B[39m, in \u001B[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    145\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(*args, **kwargs)\n\u001B[32m    146\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001B[39m, in \u001B[36madam\u001B[39m\u001B[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[39m\n\u001B[32m    930\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    931\u001B[39m     func = _single_tensor_adam\n\u001B[32m--> \u001B[39m\u001B[32m933\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    934\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    935\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    936\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    937\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    938\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    939\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    940\u001B[39m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m=\u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    941\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    942\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[43m=\u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    947\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    948\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    949\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    950\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    951\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    952\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoupled_weight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoupled_weight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    953\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\torch\\optim\\adam.py:439\u001B[39m, in \u001B[36m_single_tensor_adam\u001B[39m\u001B[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001B[39m\n\u001B[32m    436\u001B[39m     device_beta1 = beta1\n\u001B[32m    438\u001B[39m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m439\u001B[39m \u001B[43mexp_avg\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlerp_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_beta1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    441\u001B[39m \u001B[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001B[39;00m\n\u001B[32m    442\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m differentiable \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(beta2, Tensor):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets peft evaluate plotly sentencepiece --quiet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from datasets import load_dataset\n",
    "# import torch_optimizer as optim\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(language):\n",
    "    try:\n",
    "        if language=='por':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"por\",trust_remote_code=True)\n",
    "        elif language=='swa':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"swa\",trust_remote_code=True)\n",
    "        elif language=='sot':\n",
    "            chosen_dataset=load_dataset(\"hamza-student-123/nlp-assignment-news-data\",'sot')\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        for ds in [chosen_dataset]: # Change to all three later\n",
    "            for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "                if ds[lbl].column_names[0]== \"tweet\":\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "                else:\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "\n",
    "        train_df  = chosen_dataset[\"train\"].to_pandas()\n",
    "        val_df  = chosen_dataset[\"validation\"].to_pandas()\n",
    "        test_df  = chosen_dataset[\"test\"].to_pandas()\n",
    "        logger.info(f\"Data loaded successfully: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test examples\")\n",
    "        return train_df, val_df, test_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Function to create DataLoaders\n",
    "def create_data_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, text_column='text', label_column='label'):\n",
    "    train_dataset = SentimentDataset(\n",
    "        texts=train_df[text_column].tolist(),\n",
    "        labels=train_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        texts=val_df[text_column].tolist(),\n",
    "        labels=val_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        texts=test_df[text_column].tolist(),\n",
    "        labels=test_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Tuple of (loss, accuracy, precision, recall, f1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, class_names):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_afro_xlmr_for_lang(language):\n",
    "    config = {\n",
    "        'model_name': 'Davlan/afro-xlmr-base',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    logger.info(f\"Loading model: {config['model_name']}...\")\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['model_name'])\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=config['num_labels']\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{language}')\n",
    "\n",
    "    # Create data loaders\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column']\n",
    "    )\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=config['warmup_steps'],\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    logger.info(\"Starting training...\")\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        logger.info(f\"Epoch {epoch + 1}/{config['epochs']}\")\n",
    "\n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_loader,optimizer,scheduler, device) # train_epoch(model, train_loader, scheduler, device)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1} results:\")\n",
    "        logger.info(f\"Train Loss: {train_loss:.4f}, Time: {train_time:.2f}s\")\n",
    "        logger.info(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            logger.info(f\"New best model with F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Load best model for testing\n",
    "    if best_model_state:\n",
    "        logger.info(\"Loading best model for testing...\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Test evaluation\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{language}.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Save model\n",
    "    logger.info(\"Saving model...\")\n",
    "    model_save_path = f'./xmlr_sentiment_model_{language}'\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    logger.info(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# evaluate_afro_xlmr()\n",
    "langs = ['por','swa']\n",
    "# langs = ['sot']\n",
    "for l in langs:\n",
    "    evaluate_afro_xlmr_for_lang(l)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Evaluation for Sesotho",
   "id": "ef70660a07aec178"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139b49723ff4d98",
   "metadata": {
    "id": "4139b49723ff4d98"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers datasets peft evaluate plotly sentencepiece --quiet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from datasets import load_dataset\n",
    "# import torch_optimizer as optim\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.label_mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}  # Label conversion\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.label_mapping[self.labels[idx]]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(language):\n",
    "    try:\n",
    "        if language=='por':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"por\",trust_remote_code=True)\n",
    "        elif language=='swa':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"swa\",trust_remote_code=True)\n",
    "        elif language=='sot':\n",
    "            chosen_dataset=load_dataset(\"hamza-student-123/nlp-assignment-news-data\",'sot')\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        for ds in [chosen_dataset]: # Change to all three later\n",
    "            for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "                if ds[lbl].column_names[0]== \"tweet\":\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "                else:\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "\n",
    "        train_df  = chosen_dataset[\"train\"].to_pandas()\n",
    "        val_df  = chosen_dataset[\"validation\"].to_pandas()\n",
    "        test_df  = chosen_dataset[\"test\"].to_pandas()\n",
    "        logger.info(f\"Data loaded successfully: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test examples\")\n",
    "        return train_df, val_df, test_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Function to create DataLoaders\n",
    "def create_data_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, text_column='text', label_column='label'):\n",
    "    train_dataset = SentimentDataset(\n",
    "        texts=train_df[text_column].tolist(),\n",
    "        labels=train_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        texts=val_df[text_column].tolist(),\n",
    "        labels=val_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        texts=test_df[text_column].tolist(),\n",
    "        labels=test_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Tuple of (loss, accuracy, precision, recall, f1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, class_names):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_afro_xlmr_for_lang(language):\n",
    "    config = {\n",
    "        'model_name': 'Davlan/afro-xlmr-base',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    logger.info(f\"Loading model: {config['model_name']}...\")\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['model_name'])\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=config['num_labels']\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{language}')\n",
    "\n",
    "    # Create data loaders\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column']\n",
    "    )\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=config['warmup_steps'],\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    logger.info(\"Starting training...\")\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        logger.info(f\"Epoch {epoch + 1}/{config['epochs']}\")\n",
    "\n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_loader,optimizer,scheduler, device) # train_epoch(model, train_loader, scheduler, device)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1} results:\")\n",
    "        logger.info(f\"Train Loss: {train_loss:.4f}, Time: {train_time:.2f}s\")\n",
    "        logger.info(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            logger.info(f\"New best model with F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Load best model for testing\n",
    "    if best_model_state:\n",
    "        logger.info(\"Loading best model for testing...\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Test evaluation\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{language}.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Save model\n",
    "    logger.info(\"Saving model...\")\n",
    "    model_save_path = f'./xmlr_sentiment_model_{language}'\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    logger.info(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "langs = ['sot']\n",
    "for l in langs:\n",
    "    evaluate_afro_xlmr_for_lang(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbaf73c7a762eab",
   "metadata": {
    "id": "2bbaf73c7a762eab"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f40a394aebaa6",
   "metadata": {
    "id": "e96f40a394aebaa6"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a4400037a4682",
   "metadata": {
    "id": "88a4400037a4682"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac4ce50a2e9546bd",
   "metadata": {
    "id": "ac4ce50a2e9546bd"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0cf85b26ad1bb5f",
   "metadata": {
    "id": "d0cf85b26ad1bb5f"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61953463fc0ec2b9",
   "metadata": {
    "id": "61953463fc0ec2b9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54c1d7e0be0ea4ed",
   "metadata": {
    "id": "54c1d7e0be0ea4ed"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d56a54d7b786fe",
   "metadata": {
    "id": "87d56a54d7b786fe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab953850b10d116a",
   "metadata": {
    "id": "ab953850b10d116a"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff377d11fb5368",
   "metadata": {
    "id": "9aff377d11fb5368"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e765e9d0d36f08a",
   "metadata": {
    "id": "5e765e9d0d36f08a"
   },
   "source": [
    "\n",
    "This will be through using Cross-Lingual transfer learning (CLTL) with Swahili data with the aim of improving model performance on Sesotho.\n",
    "This decision was made because...(sesotho has less resources for example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb657ff158095",
   "metadata": {
    "id": "48cb657ff158095"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78def7c99cf8e077",
   "metadata": {
    "id": "78def7c99cf8e077"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd40509cfc1fb0",
   "metadata": {
    "id": "e0fd40509cfc1fb0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73aad88c7d909859",
   "metadata": {
    "id": "73aad88c7d909859"
   },
   "source": [
    "\n",
    "Furthermore, we explore how linguistic nuances within our affect classification across languages. There is a particular focus on Sesotho models because...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa610ae72db2bddc",
   "metadata": {
    "id": "fa610ae72db2bddc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f0b76bd6b6d033a",
   "metadata": {
    "id": "6f0b76bd6b6d033a"
   },
   "source": [
    "\n",
    "Link: [SHAP docs](https://shap.readthedocs.io/en/latest/)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## mBERT\n",
    "\n",
    "### Baseline with [mBERT](https://huggingface.co/google-bert/bert-base-multilingual-cased)\n"
   ],
   "id": "6b81947d17b90728"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b897654a94b25",
   "metadata": {
    "id": "e69b897654a94b25",
    "outputId": "5f020195-2ae9-4704-8a8e-21ce32d0bf5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/python3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e04cbcf2f4883c1",
   "metadata": {
    "id": "5e04cbcf2f4883c1"
   },
   "source": [
    "\n",
    "Link: [LIME docs](https://uc-r.github.io/lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6175a1aa9caa92",
   "metadata": {
    "id": "9a6175a1aa9caa92",
    "outputId": "995ff0b7-014c-4eff-afb4-bd26904a36a8",
    "tags": [
     "mbert"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting benchmarking with LIME explanations...\n",
      "\n",
      "Processing Swahili dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 14853.57 examples/s]\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 12564.27 examples/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 13980.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating LIME explanations for Swahili...\n",
      "  Generated explanation 1/10 for sample 654\n",
      "  Generated explanation 2/10 for sample 114\n",
      "  Generated explanation 3/10 for sample 25\n",
      "  Generated explanation 4/10 for sample 281\n",
      "  Generated explanation 5/10 for sample 250\n",
      "  Generated explanation 6/10 for sample 228\n",
      "  Generated explanation 7/10 for sample 142\n",
      "  Generated explanation 8/10 for sample 104\n",
      "  Generated explanation 9/10 for sample 692\n",
      "  Generated explanation 10/10 for sample 558\n",
      "\n",
      "Processing Portuguese dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10175/2280496632.py:343: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 14149.98 examples/s]\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 12529.87 examples/s]\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 14905.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='229' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [229/229 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating LIME explanations for Portuguese...\n",
      "  Generated explanation 1/10 for sample 2619\n",
      "  Generated explanation 2/10 for sample 456\n",
      "  Generated explanation 3/10 for sample 102\n",
      "  Generated explanation 4/10 for sample 3037\n",
      "  Generated explanation 5/10 for sample 1126\n",
      "  Generated explanation 6/10 for sample 1003\n",
      "  Generated explanation 7/10 for sample 914\n",
      "  Generated explanation 8/10 for sample 571\n",
      "  Generated explanation 9/10 for sample 3016\n",
      "  Generated explanation 10/10 for sample 419\n",
      "\n",
      "Processing Sesotho dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1741/1741 [00:00<00:00, 8214.19 examples/s]\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 12935.68 examples/s]\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 13669.38 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating LIME explanations for Sesotho...\n",
      "  Generated explanation 1/10 for sample 163\n",
      "  Generated explanation 2/10 for sample 28\n",
      "  Generated explanation 3/10 for sample 6\n",
      "  Generated explanation 4/10 for sample 189\n",
      "  Generated explanation 5/10 for sample 70\n",
      "  Generated explanation 6/10 for sample 62\n",
      "  Generated explanation 7/10 for sample 57\n",
      "  Generated explanation 8/10 for sample 35\n",
      "  Generated explanation 9/10 for sample 188\n",
      "  Generated explanation 10/10 for sample 26\n",
      "\n",
      "Results saved to: /home/troy/Documents/nlp-research/benchmark_results/mbert_benchmark_results_20250612_225610.csv\n",
      "LIME explanations summary saved to: /home/troy/Documents/nlp-research/lime_explanations/explanations_20250612_225610/explanations_summary.json\n",
      "\n",
      "==== BENCHMARKING WITH LIME EXPLANATIONS COMPLETE ====\n",
      "\n",
      "Results Summary:\n",
      "      Dataset  Model      Loss  Accuracy        F1  Precision    Recall\n",
      "0     Swahili  mBERT  1.035671  0.582888  0.440901   0.373173  0.582888\n",
      "1  Portuguese  mBERT  1.078578  0.176952  0.079557   0.350615  0.176952\n",
      "2     Sesotho  mBERT  1.198339  0.178899  0.093481   0.064011  0.178899\n",
      "\n",
      "LIME Explanations saved in: /home/troy/Documents/nlp-research/lime_explanations/explanations_20250612_225610\n",
      "Files generated:\n",
      "- Individual HTML explanations for each sample\n",
      "- JSON files with detailed explanation data\n",
      "- Summary statistics of feature importance\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "run_timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "os.makedirs(\"./benchmark_results\", exist_ok=True)\n",
    "os.makedirs(\"./lime_explanations\", exist_ok=True)\n",
    "\n",
    "output_csv = os.path.abspath(f\"./benchmark_results/mbert_benchmark_results_{run_timestamp}.csv\")\n",
    "explanations_dir = os.path.abspath(f\"./lime_explanations/explanations_{run_timestamp}\")\n",
    "os.makedirs(explanations_dir, exist_ok=True)\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    \"Dataset\", \"Model\", \"Loss\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\"\n",
    "])\n",
    "\n",
    "try:\n",
    "    swa_dataset = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "except Exception as e:\n",
    "    swa_dataset = None\n",
    "\n",
    "try:\n",
    "    por_dataset = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "except Exception as e:\n",
    "    por_dataset = None\n",
    "\n",
    "try:\n",
    "    sot_dataset = load_dataset(\"csv\", data_files={\"train\": \"./datasets/sotho-news/sotho_news_dataset.csv\"})\n",
    "except Exception as e:\n",
    "    sot_dataset = None\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "class ModelPredictor:\n",
    "    \"\"\"Wrapper class for LIME explanations\"\"\"\n",
    "    def __init__(self, model, tokenizer, device, num_labels):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.num_labels = num_labels\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict_proba(self, texts):\n",
    "        \"\"\"Predict probabilities for LIME\"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probas = F.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        return probas.cpu().numpy()\n",
    "\n",
    "def generate_lime_explanations(model_predictor, test_texts, test_labels, dataset_name, \n",
    "                              label_names=None, num_samples=10):\n",
    "    \"\"\"Generate LIME explanations for sample predictions\"\"\"\n",
    "    \n",
    "    explainer = LimeTextExplainer(class_names=label_names or [f\"Class_{i}\" for i in range(3)])\n",
    "    \n",
    "    sample_indices = random.sample(range(len(test_texts)), min(num_samples, len(test_texts)))\n",
    "    explanations_data = []\n",
    "    \n",
    "    print(f\"\\nGenerating LIME explanations for {dataset_name}...\")\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        try:\n",
    "            text = test_texts[idx]\n",
    "            true_label = test_labels[idx]\n",
    "            \n",
    "            pred_proba = model_predictor.predict_proba([text])[0]\n",
    "            pred_label = np.argmax(pred_proba)\n",
    "            \n",
    "            exp = explainer.explain_instance(\n",
    "                text, \n",
    "                model_predictor.predict_proba, \n",
    "                num_features=10,\n",
    "                num_samples=1000\n",
    "            )\n",
    "            \n",
    "            explanation_data = {\n",
    "                'sample_id': idx,\n",
    "                'text': text,\n",
    "                'true_label': int(true_label),\n",
    "                'predicted_label': int(pred_label),\n",
    "                'prediction_probability': float(pred_proba[pred_label]),\n",
    "                'all_probabilities': pred_proba.tolist(),\n",
    "                'lime_explanation': []\n",
    "            }\n",
    "            \n",
    "            for feature, importance in exp.as_list():\n",
    "                explanation_data['lime_explanation'].append({\n",
    "                    'feature': feature,\n",
    "                    'importance': float(importance)\n",
    "                })\n",
    "            \n",
    "            explanations_data.append(explanation_data)\n",
    "            \n",
    "            html_file = os.path.join(explanations_dir, f\"{dataset_name}_sample_{idx}_explanation.html\")\n",
    "            exp.save_to_file(html_file)\n",
    "            \n",
    "            print(f\"  Generated explanation {i+1}/{len(sample_indices)} for sample {idx}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating explanation for sample {idx}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Save explanations as JSON\n",
    "    json_file = os.path.join(explanations_dir, f\"{dataset_name}_lime_explanations.json\")\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(explanations_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return explanations_data\n",
    "\n",
    "def get_benchmark_metrics(dataset_name, dataset, num_labels):\n",
    "\n",
    "    if dataset is None:\n",
    "        return None, None\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        num_labels=num_labels\n",
    "    ).to(device)\n",
    "\n",
    "    text_column = None\n",
    "    label_column = None\n",
    "\n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in text_candidates:\n",
    "            if candidate in columns:\n",
    "                text_column = candidate\n",
    "                break\n",
    "        if text_column:\n",
    "            break\n",
    "\n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in label_candidates:\n",
    "            if candidate in columns:\n",
    "                label_column = candidate\n",
    "                break\n",
    "        if label_column:\n",
    "            break\n",
    "\n",
    "    if text_column is None:\n",
    "        for split in dataset:\n",
    "            for col in dataset[split].column_names:\n",
    "                if isinstance(dataset[split][col][0], str):\n",
    "                    text_column = col\n",
    "                    break\n",
    "            if text_column:\n",
    "                break\n",
    "\n",
    "    if text_column is None:\n",
    "        return None, None\n",
    "\n",
    "    if label_column is None:\n",
    "        return None, None\n",
    "\n",
    "    required_splits = [\"train\", \"validation\", \"test\"]\n",
    "    missing_splits = [split for split in required_splits if split not in dataset]\n",
    "\n",
    "    if missing_splits:\n",
    "        if \"train\" in dataset:\n",
    "            train_valid_test = {}\n",
    "\n",
    "            for split in dataset:\n",
    "                if split in required_splits:\n",
    "                    train_valid_test[split] = dataset[split]\n",
    "\n",
    "            if \"train\" in dataset and (\"validation\" not in train_valid_test or \"test\" not in train_valid_test):\n",
    "                if \"validation\" not in train_valid_test:\n",
    "                    if \"test\" not in train_valid_test:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                        test_valid_split = split_datasets[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = test_valid_split[\"train\"]\n",
    "                        train_valid_test[\"test\"] = test_valid_split[\"test\"]\n",
    "                    else:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = split_datasets[\"test\"]\n",
    "                else:\n",
    "                    split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                    train_valid_test[\"test\"] = split_datasets[\"test\"]\n",
    "\n",
    "            dataset = DatasetDict(train_valid_test)\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    label_mapping = None\n",
    "    label_names = None\n",
    "    for split in dataset:\n",
    "        if isinstance(dataset[split][label_column][0], str):\n",
    "            all_labels = set()\n",
    "            for example in dataset[split][label_column]:\n",
    "                all_labels.add(example)\n",
    "\n",
    "            sorted_labels = sorted(all_labels)\n",
    "            label_mapping = {label: i for i, label in enumerate(sorted_labels)}\n",
    "            label_names = sorted_labels\n",
    "            break\n",
    "\n",
    "    processed_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in dataset.items():\n",
    "        texts = split_dataset[text_column]\n",
    "\n",
    "        if label_mapping:\n",
    "            labels = [label_mapping[label] for label in split_dataset[label_column]]\n",
    "        else:\n",
    "            labels = []\n",
    "            for label in split_dataset[label_column]:\n",
    "                if isinstance(label, (int, np.integer)):\n",
    "                    labels.append(int(label))\n",
    "                elif isinstance(label, str):\n",
    "                    try:\n",
    "                        labels.append(int(label))\n",
    "                    except ValueError:\n",
    "                        labels.append(0)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "\n",
    "        processed_dataset[split_name] = Dataset.from_dict({\n",
    "            \"text\": texts,\n",
    "            \"label\": labels\n",
    "        })\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    tokenized_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in processed_dataset.items():\n",
    "        tokenized_split = split_dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "        tokenized_dataset[split_name] = tokenized_split\n",
    "\n",
    "        for required_col in [\"input_ids\", \"attention_mask\", \"label\"]:\n",
    "            if required_col not in tokenized_split.column_names:\n",
    "                return None, None\n",
    "\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=f\"./benchmark_results/{dataset_name}_{run_timestamp}\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        logging_dir=f\"./benchmark_results/{dataset_name}_{run_timestamp}/logs\",\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=eval_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        benchmark_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "        \n",
    "        model_predictor = ModelPredictor(model, tokenizer, device, num_labels)\n",
    "        test_texts = processed_dataset[\"test\"][\"text\"]\n",
    "        test_labels = processed_dataset[\"test\"][\"label\"]\n",
    "        \n",
    "        lime_explanations = generate_lime_explanations(\n",
    "            model_predictor, test_texts, test_labels, dataset_name, \n",
    "            label_names=label_names, num_samples=10\n",
    "        )\n",
    "\n",
    "        return benchmark_results, lime_explanations\n",
    "    except Exception as e:\n",
    "        print(f\"Error in benchmarking {dataset_name}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "available_datasets = []\n",
    "if swa_dataset:\n",
    "    available_datasets.append((\"Swahili\", swa_dataset, 3))\n",
    "if por_dataset:\n",
    "    available_datasets.append((\"Portuguese\", por_dataset, 3))\n",
    "if sot_dataset:\n",
    "    available_datasets.append((\"Sesotho\", sot_dataset, 3))\n",
    "\n",
    "all_results = []\n",
    "all_explanations = {}\n",
    "\n",
    "print(\"Starting benchmarking with LIME explanations...\")\n",
    "\n",
    "for dataset_name, dataset, num_labels in available_datasets:\n",
    "    try:\n",
    "        print(f\"\\nProcessing {dataset_name} dataset...\")\n",
    "        results, explanations = get_benchmark_metrics(dataset_name, dataset, num_labels)\n",
    "\n",
    "        if results:\n",
    "            results_df = results_df._append({\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"Model\": \"mBERT\",\n",
    "                \"Loss\": results.get(\"eval_loss\"),\n",
    "                \"Accuracy\": results.get(\"eval_accuracy\"),\n",
    "                \"F1\": results.get(\"eval_f1\"),\n",
    "                \"Precision\": results.get(\"eval_precision\"),\n",
    "                \"Recall\": results.get(\"eval_recall\")\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            all_results.append({\"Dataset\": dataset_name, \"Results\": results})\n",
    "            if explanations:\n",
    "                all_explanations[dataset_name] = explanations\n",
    "        else:\n",
    "            print(f\"Failed to process {dataset_name} dataset\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dataset_name}: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nResults saved to: {output_csv}\")\n",
    "except Exception as e:\n",
    "    emergency_path = f\"./emergency_results_{run_timestamp}.csv\"\n",
    "    results_df.to_csv(emergency_path, index=False)\n",
    "    print(f\"\\nEmergency results saved to: {emergency_path}\")\n",
    "\n",
    "if all_explanations:\n",
    "    summary_file = os.path.join(explanations_dir, \"explanations_summary.json\")\n",
    "    explanation_summary = {}\n",
    "    \n",
    "    for dataset_name, explanations in all_explanations.items():\n",
    "        summary_stats = {\n",
    "            'total_explanations': len(explanations),\n",
    "            'average_prediction_confidence': np.mean([exp['prediction_probability'] for exp in explanations]),\n",
    "            'correct_predictions': sum(1 for exp in explanations if exp['true_label'] == exp['predicted_label']),\n",
    "            'top_important_features': {}\n",
    "        }\n",
    "        \n",
    "        feature_importance = {}\n",
    "        for exp in explanations:\n",
    "            for feature_data in exp['lime_explanation']:\n",
    "                feature = feature_data['feature']\n",
    "                importance = abs(feature_data['importance'])\n",
    "                if feature in feature_importance:\n",
    "                    feature_importance[feature].append(importance)\n",
    "                else:\n",
    "                    feature_importance[feature] = [importance]\n",
    "        \n",
    "        avg_feature_importance = {\n",
    "            feature: np.mean(importances) \n",
    "            for feature, importances in feature_importance.items()\n",
    "        }\n",
    "        \n",
    "        sorted_features = sorted(avg_feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "        summary_stats['top_important_features'] = dict(sorted_features[:10])\n",
    "        \n",
    "        explanation_summary[dataset_name] = summary_stats\n",
    "    \n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(explanation_summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(results_df)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "acd5015c08fc631"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fine-Tuning BERT\n",
   "id": "39cde647348a8cd0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eaa462",
   "metadata": {
    "id": "37eaa462",
    "outputId": "b581ac85-7100-4eea-ce39-57cd01cd6f91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:40:55,321 - INFO - Successfully loaded Swahili dataset from HuggingFace Hub\n",
      "2025-05-10 00:40:57,013 - INFO - Successfully loaded Portuguese dataset from HuggingFace Hub\n",
      "2025-05-10 00:40:57,013 - INFO - Successfully loaded Portuguese dataset from HuggingFace Hub\n",
      "2025-05-10 00:40:57,269 - INFO - Successfully loaded Sesotho dataset from CSV\n",
      "2025-05-10 00:40:57,271 - INFO - Available datasets: ['Swahili', 'Portuguese', 'Sesotho']\n",
      "2025-05-10 00:40:57,272 - INFO - \n",
      "==== FINE-TUNING ON SWAHILI DATASET ====\n",
      "2025-05-10 00:40:57,272 - INFO - Starting fine-tuning for Swahili\n",
      "2025-05-10 00:40:57,273 - INFO - Using device: cuda\n",
      "2025-05-10 00:40:57,269 - INFO - Successfully loaded Sesotho dataset from CSV\n",
      "2025-05-10 00:40:57,271 - INFO - Available datasets: ['Swahili', 'Portuguese', 'Sesotho']\n",
      "2025-05-10 00:40:57,272 - INFO - \n",
      "==== FINE-TUNING ON SWAHILI DATASET ====\n",
      "2025-05-10 00:40:57,272 - INFO - Starting fine-tuning for Swahili\n",
      "2025-05-10 00:40:57,273 - INFO - Using device: cuda\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-10 00:40:58,304 - INFO - Dataset Swahili structure:\n",
      "2025-05-10 00:40:58,305 - INFO -   - Split: train, Examples: 1810\n",
      "2025-05-10 00:40:58,306 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,306 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,306 - INFO -   - Split: validation, Examples: 453\n",
      "2025-05-10 00:40:58,306 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,307 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,307 - INFO -   - Split: test, Examples: 748\n",
      "2025-05-10 00:40:58,307 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,307 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,308 - INFO - For Swahili, using text_column=tweet, label_column=label\n",
      "2025-05-10 00:40:58,310 - INFO - Created label mapping for Swahili: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:40:58,304 - INFO - Dataset Swahili structure:\n",
      "2025-05-10 00:40:58,305 - INFO -   - Split: train, Examples: 1810\n",
      "2025-05-10 00:40:58,306 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,306 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,306 - INFO -   - Split: validation, Examples: 453\n",
      "2025-05-10 00:40:58,306 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,307 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,307 - INFO -   - Split: test, Examples: 748\n",
      "2025-05-10 00:40:58,307 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,307 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,308 - INFO - For Swahili, using text_column=tweet, label_column=label\n",
      "2025-05-10 00:40:58,310 - INFO - Created label mapping for Swahili: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:40:58,317 - INFO - Processed train split: 1810 examples\n",
      "2025-05-10 00:40:58,322 - INFO - Processed validation split: 453 examples\n",
      "2025-05-10 00:40:58,327 - INFO - Processed test split: 748 examples\n",
      "2025-05-10 00:40:58,317 - INFO - Processed train split: 1810 examples\n",
      "2025-05-10 00:40:58,322 - INFO - Processed validation split: 453 examples\n",
      "2025-05-10 00:40:58,327 - INFO - Processed test split: 748 examples\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 17231.17 examples/s]\n",
      "2025-05-10 00:40:58,456 - INFO - Tokenized train split: 1810 examples\n",
      "2025-05-10 00:40:58,457 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 17231.17 examples/s]\n",
      "2025-05-10 00:40:58,456 - INFO - Tokenized train split: 1810 examples\n",
      "2025-05-10 00:40:58,457 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 16432.89 examples/s]\n",
      "2025-05-10 00:40:58,511 - INFO - Tokenized validation split: 453 examples\n",
      "2025-05-10 00:40:58,511 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 16432.89 examples/s]\n",
      "2025-05-10 00:40:58,511 - INFO - Tokenized validation split: 453 examples\n",
      "2025-05-10 00:40:58,511 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 17553.81 examples/s]\n",
      "2025-05-10 00:40:58,579 - INFO - Tokenized test split: 748 examples\n",
      "2025-05-10 00:40:58,579 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 17553.81 examples/s]\n",
      "2025-05-10 00:40:58,579 - INFO - Tokenized test split: 748 examples\n",
      "2025-05-10 00:40:58,579 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "2025-05-10 00:40:58,601 - INFO - Starting fine-tuning Swahili with 1810 examples\n",
      "2025-05-10 00:40:58,601 - INFO - Starting fine-tuning Swahili with 1810 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [342/342 01:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.840700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.909700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.954400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.925500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.864900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.838700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.889400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.896900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.890300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.918200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.838300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.826100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.864500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.787600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.773600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.747900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.816300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.783100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.744800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.855600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:42:41,517 - INFO - Model saved to ./models/swahili/model.pt\n",
      "2025-05-10 00:42:41,567 - INFO - Tokenizer saved to ./models/swahili\n",
      "2025-05-10 00:42:41,567 - INFO - Label mapping saved to ./models/swahili/label_mapping.json\n",
      "2025-05-10 00:42:41,568 - INFO - Model config saved to ./models/swahili/config.json\n",
      "2025-05-10 00:42:41,568 - INFO - Training completed in 102.97 seconds\n",
      "2025-05-10 00:42:41,569 - INFO - Evaluating on validation set with 453 examples\n",
      "2025-05-10 00:42:41,567 - INFO - Tokenizer saved to ./models/swahili\n",
      "2025-05-10 00:42:41,567 - INFO - Label mapping saved to ./models/swahili/label_mapping.json\n",
      "2025-05-10 00:42:41,568 - INFO - Model config saved to ./models/swahili/config.json\n",
      "2025-05-10 00:42:41,568 - INFO - Training completed in 102.97 seconds\n",
      "2025-05-10 00:42:41,569 - INFO - Evaluating on validation set with 453 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-10 00:42:44,114 - INFO - Evaluating on test set with 748 examples\n",
      "2025-05-10 00:42:48,308 - INFO - Model metrics saved to ./models/swahili/metrics.json\n",
      "2025-05-10 00:42:48,309 - INFO - ============== RESULTS FOR Swahili ==============\n",
      "2025-05-10 00:42:48,309 - INFO - Training loss: 0.8556\n",
      "2025-05-10 00:42:48,310 - INFO - Validation results: {'eval_loss': 0.9941654205322266, 'eval_accuracy': 0.5209713024282561, 'eval_f1': 0.48724343479019466, 'eval_precision': 0.458357269134707, 'eval_recall': 0.5209713024282561, 'eval_runtime': 2.5441, 'eval_samples_per_second': 178.059, 'eval_steps_per_second': 11.399, 'epoch': 3.0}\n",
      "2025-05-10 00:42:48,310 - INFO - Test results: {'eval_loss': 0.9500337243080139, 'eval_accuracy': 0.5347593582887701, 'eval_f1': 0.504784295364511, 'eval_precision': 0.5145401534051629, 'eval_recall': 0.5347593582887701, 'eval_runtime': 4.1913, 'eval_samples_per_second': 178.465, 'eval_steps_per_second': 11.214, 'epoch': 3.0}\n",
      "2025-05-10 00:42:48,308 - INFO - Model metrics saved to ./models/swahili/metrics.json\n",
      "2025-05-10 00:42:48,309 - INFO - ============== RESULTS FOR Swahili ==============\n",
      "2025-05-10 00:42:48,309 - INFO - Training loss: 0.8556\n",
      "2025-05-10 00:42:48,310 - INFO - Validation results: {'eval_loss': 0.9941654205322266, 'eval_accuracy': 0.5209713024282561, 'eval_f1': 0.48724343479019466, 'eval_precision': 0.458357269134707, 'eval_recall': 0.5209713024282561, 'eval_runtime': 2.5441, 'eval_samples_per_second': 178.059, 'eval_steps_per_second': 11.399, 'epoch': 3.0}\n",
      "2025-05-10 00:42:48,310 - INFO - Test results: {'eval_loss': 0.9500337243080139, 'eval_accuracy': 0.5347593582887701, 'eval_f1': 0.504784295364511, 'eval_precision': 0.5145401534051629, 'eval_recall': 0.5347593582887701, 'eval_runtime': 4.1913, 'eval_samples_per_second': 178.465, 'eval_steps_per_second': 11.214, 'epoch': 3.0}\n",
      "2025-05-10 00:42:48,328 - INFO - \n",
      "==== FINE-TUNING ON PORTUGUESE DATASET ====\n",
      "2025-05-10 00:42:48,329 - INFO - Starting fine-tuning for Portuguese\n",
      "2025-05-10 00:42:48,330 - INFO - Using device: cuda\n",
      "2025-05-10 00:42:48,328 - INFO - \n",
      "==== FINE-TUNING ON PORTUGUESE DATASET ====\n",
      "2025-05-10 00:42:48,329 - INFO - Starting fine-tuning for Portuguese\n",
      "2025-05-10 00:42:48,330 - INFO - Using device: cuda\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-10 00:42:49,284 - INFO - Dataset Portuguese structure:\n",
      "2025-05-10 00:42:49,285 - INFO -   - Split: train, Examples: 3063\n",
      "2025-05-10 00:42:49,287 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,287 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,288 - INFO -   - Split: validation, Examples: 767\n",
      "2025-05-10 00:42:49,288 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,288 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,289 - INFO -   - Split: test, Examples: 3662\n",
      "2025-05-10 00:42:49,289 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,289 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,289 - INFO - For Portuguese, using text_column=tweet, label_column=label\n",
      "2025-05-10 00:42:49,284 - INFO - Dataset Portuguese structure:\n",
      "2025-05-10 00:42:49,285 - INFO -   - Split: train, Examples: 3063\n",
      "2025-05-10 00:42:49,287 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,287 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,288 - INFO -   - Split: validation, Examples: 767\n",
      "2025-05-10 00:42:49,288 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,288 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,289 - INFO -   - Split: test, Examples: 3662\n",
      "2025-05-10 00:42:49,289 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,289 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,289 - INFO - For Portuguese, using text_column=tweet, label_column=label\n",
      "2025-05-10 00:42:49,294 - INFO - Created label mapping for Portuguese: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:42:49,306 - INFO - Processed train split: 3063 examples\n",
      "2025-05-10 00:42:49,294 - INFO - Created label mapping for Portuguese: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:42:49,306 - INFO - Processed train split: 3063 examples\n",
      "2025-05-10 00:42:49,312 - INFO - Processed validation split: 767 examples\n",
      "2025-05-10 00:42:49,324 - INFO - Processed test split: 3662 examples\n",
      "2025-05-10 00:42:49,312 - INFO - Processed validation split: 767 examples\n",
      "2025-05-10 00:42:49,324 - INFO - Processed test split: 3662 examples\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 18815.56 examples/s]\n",
      "2025-05-10 00:42:49,509 - INFO - Tokenized train split: 3063 examples\n",
      "2025-05-10 00:42:49,510 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 18815.56 examples/s]\n",
      "2025-05-10 00:42:49,509 - INFO - Tokenized train split: 3063 examples\n",
      "2025-05-10 00:42:49,510 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 17370.86 examples/s]\n",
      "2025-05-10 00:42:49,576 - INFO - Tokenized validation split: 767 examples\n",
      "2025-05-10 00:42:49,576 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 17370.86 examples/s]\n",
      "2025-05-10 00:42:49,576 - INFO - Tokenized validation split: 767 examples\n",
      "2025-05-10 00:42:49,576 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 19218.93 examples/s]\n",
      "2025-05-10 00:42:49,789 - INFO - Tokenized test split: 3662 examples\n",
      "2025-05-10 00:42:49,789 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 19218.93 examples/s]\n",
      "2025-05-10 00:42:49,789 - INFO - Tokenized test split: 3662 examples\n",
      "2025-05-10 00:42:49,789 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "2025-05-10 00:42:49,811 - INFO - Starting fine-tuning Portuguese with 3063 examples\n",
      "2025-05-10 00:42:49,811 - INFO - Starting fine-tuning Portuguese with 3063 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='576' max='576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [576/576 02:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.069100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.973400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.888400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.893400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.962300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.925500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.918400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.874500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.784100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.745700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.832900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.697100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.778600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.812300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.632300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.789300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.487700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.651900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.661000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.619700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.650300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.530500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.646300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.580200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.500300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:45:48,836 - INFO - Model saved to ./models/portuguese/model.pt\n",
      "2025-05-10 00:45:48,903 - INFO - Tokenizer saved to ./models/portuguese\n",
      "2025-05-10 00:45:48,904 - INFO - Label mapping saved to ./models/portuguese/label_mapping.json\n",
      "2025-05-10 00:45:48,905 - INFO - Model config saved to ./models/portuguese/config.json\n",
      "2025-05-10 00:45:48,905 - INFO - Training completed in 179.09 seconds\n",
      "2025-05-10 00:45:48,906 - INFO - Evaluating on validation set with 767 examples\n",
      "2025-05-10 00:45:48,903 - INFO - Tokenizer saved to ./models/portuguese\n",
      "2025-05-10 00:45:48,904 - INFO - Label mapping saved to ./models/portuguese/label_mapping.json\n",
      "2025-05-10 00:45:48,905 - INFO - Model config saved to ./models/portuguese/config.json\n",
      "2025-05-10 00:45:48,905 - INFO - Training completed in 179.09 seconds\n",
      "2025-05-10 00:45:48,906 - INFO - Evaluating on validation set with 767 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='277' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:45:53,405 - INFO - Evaluating on test set with 3662 examples\n",
      "2025-05-10 00:46:15,012 - INFO - Model metrics saved to ./models/portuguese/metrics.json\n",
      "2025-05-10 00:46:15,013 - INFO - ============== RESULTS FOR Portuguese ==============\n",
      "2025-05-10 00:46:15,014 - INFO - Training loss: 0.5003\n",
      "2025-05-10 00:46:15,014 - INFO - Validation results: {'eval_loss': 0.8650572299957275, 'eval_accuracy': 0.6192959582790091, 'eval_f1': 0.6183814552471274, 'eval_precision': 0.6188338690391852, 'eval_recall': 0.6192959582790091, 'eval_runtime': 4.4974, 'eval_samples_per_second': 170.542, 'eval_steps_per_second': 10.673, 'epoch': 3.0}\n",
      "2025-05-10 00:46:15,014 - INFO - Test results: {'eval_loss': 0.8389994502067566, 'eval_accuracy': 0.6318951392681594, 'eval_f1': 0.6440944722079657, 'eval_precision': 0.668456862074707, 'eval_recall': 0.6318951392681594, 'eval_runtime': 21.6037, 'eval_samples_per_second': 169.508, 'eval_steps_per_second': 10.6, 'epoch': 3.0}\n",
      "2025-05-10 00:46:15,012 - INFO - Model metrics saved to ./models/portuguese/metrics.json\n",
      "2025-05-10 00:46:15,013 - INFO - ============== RESULTS FOR Portuguese ==============\n",
      "2025-05-10 00:46:15,014 - INFO - Training loss: 0.5003\n",
      "2025-05-10 00:46:15,014 - INFO - Validation results: {'eval_loss': 0.8650572299957275, 'eval_accuracy': 0.6192959582790091, 'eval_f1': 0.6183814552471274, 'eval_precision': 0.6188338690391852, 'eval_recall': 0.6192959582790091, 'eval_runtime': 4.4974, 'eval_samples_per_second': 170.542, 'eval_steps_per_second': 10.673, 'epoch': 3.0}\n",
      "2025-05-10 00:46:15,014 - INFO - Test results: {'eval_loss': 0.8389994502067566, 'eval_accuracy': 0.6318951392681594, 'eval_f1': 0.6440944722079657, 'eval_precision': 0.668456862074707, 'eval_recall': 0.6318951392681594, 'eval_runtime': 21.6037, 'eval_samples_per_second': 169.508, 'eval_steps_per_second': 10.6, 'epoch': 3.0}\n",
      "2025-05-10 00:46:15,044 - INFO - \n",
      "==== FINE-TUNING ON SESOTHO DATASET ====\n",
      "2025-05-10 00:46:15,046 - INFO - Starting fine-tuning for Sesotho\n",
      "2025-05-10 00:46:15,046 - INFO - Using device: cuda\n",
      "2025-05-10 00:46:15,044 - INFO - \n",
      "==== FINE-TUNING ON SESOTHO DATASET ====\n",
      "2025-05-10 00:46:15,046 - INFO - Starting fine-tuning for Sesotho\n",
      "2025-05-10 00:46:15,046 - INFO - Using device: cuda\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-10 00:46:16,263 - INFO - Dataset Sesotho structure:\n",
      "2025-05-10 00:46:16,264 - INFO -   - Split: train, Examples: 2177\n",
      "2025-05-10 00:46:16,264 - INFO -   - Features: {'headline': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:46:16,264 - INFO -   - Columns: ['headline', 'label']\n",
      "2025-05-10 00:46:16,265 - INFO - For Sesotho, using text_column=headline, label_column=label\n",
      "2025-05-10 00:46:16,265 - INFO - Creating missing splits: ['validation', 'test'] for Sesotho\n",
      "2025-05-10 00:46:16,263 - INFO - Dataset Sesotho structure:\n",
      "2025-05-10 00:46:16,264 - INFO -   - Split: train, Examples: 2177\n",
      "2025-05-10 00:46:16,264 - INFO -   - Features: {'headline': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:46:16,264 - INFO -   - Columns: ['headline', 'label']\n",
      "2025-05-10 00:46:16,265 - INFO - For Sesotho, using text_column=headline, label_column=label\n",
      "2025-05-10 00:46:16,265 - INFO - Creating missing splits: ['validation', 'test'] for Sesotho\n",
      "2025-05-10 00:46:16,286 - INFO - Created label mapping for Sesotho: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:46:16,286 - INFO - Created label mapping for Sesotho: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:46:16,309 - INFO - Processed train split: 1741 examples\n",
      "2025-05-10 00:46:16,319 - INFO - Processed validation split: 218 examples\n",
      "2025-05-10 00:46:16,309 - INFO - Processed train split: 1741 examples\n",
      "2025-05-10 00:46:16,319 - INFO - Processed validation split: 218 examples\n",
      "2025-05-10 00:46:16,325 - INFO - Processed test split: 218 examples\n",
      "2025-05-10 00:46:16,325 - INFO - Processed test split: 218 examples\n",
      "Map: 100%|██████████| 1741/1741 [00:00<00:00, 16136.04 examples/s]\n",
      "2025-05-10 00:46:16,469 - INFO - Tokenized train split: 1741 examples\n",
      "2025-05-10 00:46:16,469 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 1741/1741 [00:00<00:00, 16136.04 examples/s]\n",
      "2025-05-10 00:46:16,469 - INFO - Tokenized train split: 1741 examples\n",
      "2025-05-10 00:46:16,469 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 12709.48 examples/s]\n",
      "2025-05-10 00:46:16,523 - INFO - Tokenized validation split: 218 examples\n",
      "2025-05-10 00:46:16,524 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 12709.48 examples/s]\n",
      "2025-05-10 00:46:16,523 - INFO - Tokenized validation split: 218 examples\n",
      "2025-05-10 00:46:16,524 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 13070.29 examples/s]\n",
      "2025-05-10 00:46:16,577 - INFO - Tokenized test split: 218 examples\n",
      "2025-05-10 00:46:16,578 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 13070.29 examples/s]\n",
      "2025-05-10 00:46:16,577 - INFO - Tokenized test split: 218 examples\n",
      "2025-05-10 00:46:16,578 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "2025-05-10 00:46:16,603 - INFO - Starting fine-tuning Sesotho with 1741 examples\n",
      "2025-05-10 00:46:16,603 - INFO - Starting fine-tuning Sesotho with 1741 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [327/327 01:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.859900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.623600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.704200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.757600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.780200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.715400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.678900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.700500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.627700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.718200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.605400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.637100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.664300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.513500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.642300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.656700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.554300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:48:00,473 - INFO - Model saved to ./models/sesotho/model.pt\n",
      "2025-05-10 00:48:00,544 - INFO - Tokenizer saved to ./models/sesotho\n",
      "2025-05-10 00:48:00,545 - INFO - Label mapping saved to ./models/sesotho/label_mapping.json\n",
      "2025-05-10 00:48:00,546 - INFO - Model config saved to ./models/sesotho/config.json\n",
      "2025-05-10 00:48:00,546 - INFO - Training completed in 103.94 seconds\n",
      "2025-05-10 00:48:00,547 - INFO - Evaluating on validation set with 218 examples\n",
      "2025-05-10 00:48:00,544 - INFO - Tokenizer saved to ./models/sesotho\n",
      "2025-05-10 00:48:00,545 - INFO - Label mapping saved to ./models/sesotho/label_mapping.json\n",
      "2025-05-10 00:48:00,546 - INFO - Model config saved to ./models/sesotho/config.json\n",
      "2025-05-10 00:48:00,546 - INFO - Training completed in 103.94 seconds\n",
      "2025-05-10 00:48:00,547 - INFO - Evaluating on validation set with 218 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-10 00:48:01,850 - INFO - Evaluating on test set with 218 examples\n",
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-10 00:48:03,137 - INFO - Model metrics saved to ./models/sesotho/metrics.json\n",
      "2025-05-10 00:48:03,138 - INFO - ============== RESULTS FOR Sesotho ==============\n",
      "2025-05-10 00:48:03,139 - INFO - Training loss: 0.5543\n",
      "2025-05-10 00:48:03,139 - INFO - Validation results: {'eval_loss': 0.5815077424049377, 'eval_accuracy': 0.7706422018348624, 'eval_f1': 0.758784555256037, 'eval_precision': 0.7473307497627334, 'eval_recall': 0.7706422018348624, 'eval_runtime': 1.3009, 'eval_samples_per_second': 167.578, 'eval_steps_per_second': 10.762, 'epoch': 3.0}\n",
      "2025-05-10 00:48:03,139 - INFO - Test results: {'eval_loss': 0.6644694209098816, 'eval_accuracy': 0.7064220183486238, 'eval_f1': 0.6912700646963953, 'eval_precision': 0.6767571962526091, 'eval_recall': 0.7064220183486238, 'eval_runtime': 1.2845, 'eval_samples_per_second': 169.71, 'eval_steps_per_second': 10.899, 'epoch': 3.0}\n",
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-10 00:48:03,137 - INFO - Model metrics saved to ./models/sesotho/metrics.json\n",
      "2025-05-10 00:48:03,138 - INFO - ============== RESULTS FOR Sesotho ==============\n",
      "2025-05-10 00:48:03,139 - INFO - Training loss: 0.5543\n",
      "2025-05-10 00:48:03,139 - INFO - Validation results: {'eval_loss': 0.5815077424049377, 'eval_accuracy': 0.7706422018348624, 'eval_f1': 0.758784555256037, 'eval_precision': 0.7473307497627334, 'eval_recall': 0.7706422018348624, 'eval_runtime': 1.3009, 'eval_samples_per_second': 167.578, 'eval_steps_per_second': 10.762, 'epoch': 3.0}\n",
      "2025-05-10 00:48:03,139 - INFO - Test results: {'eval_loss': 0.6644694209098816, 'eval_accuracy': 0.7064220183486238, 'eval_f1': 0.6912700646963953, 'eval_precision': 0.6767571962526091, 'eval_recall': 0.7064220183486238, 'eval_runtime': 1.2845, 'eval_samples_per_second': 169.71, 'eval_steps_per_second': 10.899, 'epoch': 3.0}\n",
      "2025-05-10 00:48:03,167 - INFO - \n",
      "==== FINE-TUNING COMPLETE ====\n",
      "2025-05-10 00:48:03,167 - INFO - \n",
      "==== FINE-TUNING COMPLETE ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset      | Acc (val)  | F1 (val)   | Acc (test) | F1 (test)  | Model Dir           \n",
      "Swahili      | 0.5210     | 0.4872     | 0.5348     | 0.5048     | ./models/swahili\n",
      "Portuguese   | 0.6193     | 0.6184     | 0.6319     | 0.6441     | ./models/portuguese\n",
      "Sesotho      | 0.7706     | 0.7588     | 0.7064     | 0.6913     | ./models/sesotho\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    swa_dataset = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "    logger.info(\"Successfully loaded Swahili dataset from HuggingFace Hub\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Swahili dataset: {e}\")\n",
    "    swa_dataset = None\n",
    "\n",
    "try:\n",
    "    por_dataset = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "    logger.info(\"Successfully loaded Portuguese dataset from HuggingFace Hub\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Portuguese dataset: {e}\")\n",
    "    por_dataset = None\n",
    "\n",
    "try:\n",
    "    sot_dataset = load_dataset(\"csv\", data_files={\"train\": \"./datasets/sotho-news/sotho_news_dataset.csv\"})\n",
    "    logger.info(\"Successfully loaded Sesotho dataset from CSV\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Sesotho dataset: {e}\")\n",
    "    sot_dataset = None\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def finetune_and_evaluate(dataset_name, dataset, num_labels):\n",
    "    logger.info(f\"Starting fine-tuning for {dataset_name}\")\n",
    "\n",
    "    if dataset is None:\n",
    "        logger.error(f\"Dataset {dataset_name} is None, cannot proceed with fine-tuning\")\n",
    "        return None\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    model_save_dir = f\"./models/{dataset_name.lower()}\"\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        num_labels=num_labels\n",
    "    ).to(device)\n",
    "\n",
    "    logger.info(f\"Dataset {dataset_name} structure:\")\n",
    "    for split in dataset:\n",
    "        logger.info(f\"  - Split: {split}, Examples: {len(dataset[split])}\")\n",
    "        logger.info(f\"  - Features: {dataset[split].features}\")\n",
    "        logger.info(f\"  - Columns: {dataset[split].column_names}\")\n",
    "\n",
    "    text_column = None\n",
    "    label_column = None\n",
    "\n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\", \"headline\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in text_candidates:\n",
    "            if candidate in columns:\n",
    "                text_column = candidate\n",
    "                break\n",
    "        if text_column:\n",
    "            break\n",
    "\n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in label_candidates:\n",
    "            if candidate in columns:\n",
    "                label_column = candidate\n",
    "                break\n",
    "        if label_column:\n",
    "            break\n",
    "\n",
    "    logger.info(f\"For {dataset_name}, using text_column={text_column}, label_column={label_column}\")\n",
    "\n",
    "    if text_column is None:\n",
    "        for split in dataset:\n",
    "            for col in dataset[split].column_names:\n",
    "                if isinstance(dataset[split][col][0], str):\n",
    "                    text_column = col\n",
    "                    logger.info(f\"Using '{col}' as text column based on string data\")\n",
    "                    break\n",
    "            if text_column:\n",
    "                break\n",
    "\n",
    "    if text_column is None:\n",
    "        logger.error(f\"Could not identify a text column for {dataset_name}\")\n",
    "        return None\n",
    "\n",
    "    if label_column is None:\n",
    "        logger.error(f\"Could not identify a label column for {dataset_name}\")\n",
    "        return None\n",
    "\n",
    "    required_splits = [\"train\", \"validation\", \"test\"]\n",
    "    missing_splits = [split for split in required_splits if split not in dataset]\n",
    "\n",
    "    if missing_splits:\n",
    "        logger.info(f\"Creating missing splits: {missing_splits} for {dataset_name}\")\n",
    "        if \"train\" in dataset:\n",
    "            train_valid_test = {}\n",
    "\n",
    "            for split in dataset:\n",
    "                if split in required_splits:\n",
    "                    train_valid_test[split] = dataset[split]\n",
    "\n",
    "            if \"train\" in dataset and (\"validation\" not in train_valid_test or \"test\" not in train_valid_test):\n",
    "                if \"validation\" not in train_valid_test:\n",
    "                    if \"test\" not in train_valid_test:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                        test_valid_split = split_datasets[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = test_valid_split[\"train\"]\n",
    "                        train_valid_test[\"test\"] = test_valid_split[\"test\"]\n",
    "                    else:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = split_datasets[\"test\"]\n",
    "                else:\n",
    "                    split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                    train_valid_test[\"test\"] = split_datasets[\"test\"]\n",
    "\n",
    "            dataset = DatasetDict(train_valid_test)\n",
    "        else:\n",
    "            logger.error(f\"Dataset {dataset_name} has no train split and cannot create splits\")\n",
    "            return None\n",
    "\n",
    "    label_mapping = None\n",
    "    for split in dataset:\n",
    "        if isinstance(dataset[split][label_column][0], str):\n",
    "            all_labels = set()\n",
    "            for example in dataset[split][label_column]:\n",
    "                all_labels.add(example)\n",
    "\n",
    "            label_mapping = {label: i for i, label in enumerate(sorted(all_labels))}\n",
    "            logger.info(f\"Created label mapping for {dataset_name}: {label_mapping}\")\n",
    "            break\n",
    "\n",
    "    processed_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in dataset.items():\n",
    "        texts = split_dataset[text_column]\n",
    "\n",
    "        if label_mapping:\n",
    "            labels = [label_mapping[label] for label in split_dataset[label_column]]\n",
    "        else:\n",
    "            labels = []\n",
    "            for label in split_dataset[label_column]:\n",
    "                if isinstance(label, (int, np.integer)):\n",
    "                    labels.append(int(label))\n",
    "                elif isinstance(label, str):\n",
    "                    try:\n",
    "                        labels.append(int(label))\n",
    "                    except ValueError:\n",
    "                        logger.warning(f\"Unexpected string label found in {split_name}: {label}\")\n",
    "                        labels.append(0)\n",
    "                else:\n",
    "                    logger.warning(f\"Unexpected label type in {split_name}: {type(label)}\")\n",
    "                    labels.append(0)\n",
    "\n",
    "        processed_dataset[split_name] = Dataset.from_dict({\n",
    "            \"text\": texts,\n",
    "            \"label\": labels\n",
    "        })\n",
    "\n",
    "        logger.info(f\"Processed {split_name} split: {len(processed_dataset[split_name])} examples\")\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "        )\n",
    "\n",
    "    tokenized_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in processed_dataset.items():\n",
    "        tokenized_split = split_dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "        tokenized_dataset[split_name] = tokenized_split\n",
    "\n",
    "        logger.info(f\"Tokenized {split_name} split: {len(tokenized_split)} examples\")\n",
    "        logger.info(f\"Columns after tokenization: {tokenized_split.column_names}\")\n",
    "\n",
    "        for required_col in [\"input_ids\", \"attention_mask\", \"label\"]:\n",
    "            if required_col not in tokenized_split.column_names:\n",
    "                logger.error(f\"Required column {required_col} missing after tokenization\")\n",
    "                return None\n",
    "\n",
    "    model_output_dir = f\"./tmp_model_dir_{dataset_name}\"\n",
    "    if os.path.exists(model_output_dir):\n",
    "        shutil.rmtree(model_output_dir)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_output_dir,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./tmp_logs\",\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"no\",\n",
    "        save_steps=1000000,\n",
    "        eval_steps=100,\n",
    "        do_eval=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Starting fine-tuning {dataset_name} with {len(tokenized_dataset['train'])} examples\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            train_output = trainer.train()\n",
    "\n",
    "            training_loss = None\n",
    "            try:\n",
    "                if hasattr(train_output, \"metrics\") and \"loss\" in train_output.metrics:\n",
    "                    training_loss = train_output.metrics[\"loss\"]\n",
    "                elif isinstance(train_output, dict) and \"loss\" in train_output:\n",
    "                    training_loss = train_output[\"loss\"]\n",
    "\n",
    "                if training_loss is None and hasattr(trainer, \"state\"):\n",
    "                    if hasattr(trainer.state, \"log_history\") and trainer.state.log_history:\n",
    "                        for log in reversed(trainer.state.log_history):\n",
    "                            if \"loss\" in log:\n",
    "                                training_loss = log[\"loss\"]\n",
    "                                break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not extract training loss: {e}\")\n",
    "        except RuntimeError as e:\n",
    "            if \"PytorchStreamWriter failed writing file\" in str(e):\n",
    "                logger.warning(\"Caught PyTorch serialization error during training. Will proceed with model saving.\")\n",
    "\n",
    "            else:\n",
    "\n",
    "                raise\n",
    "\n",
    "        try:\n",
    "            model_path = os.path.join(model_save_dir, \"model.pt\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            logger.info(f\"Model saved to {model_path}\")\n",
    "        except RuntimeError as e:\n",
    "            if \"PytorchStreamWriter failed writing file\" in str(e):\n",
    "                logger.warning(f\"PyTorch serialization error when saving model state dict. Trying alternative method.\")\n",
    "\n",
    "                try:\n",
    "\n",
    "                    with open(model_path, 'wb') as f:\n",
    "                        torch.save(model.state_dict(), f, _use_new_zipfile_serialization=False)\n",
    "                    logger.info(f\"Model saved to {model_path} using legacy serialization\")\n",
    "                except Exception as e2:\n",
    "                    logger.error(f\"Failed to save model with alternative method: {e2}\")\n",
    "            else:\n",
    "\n",
    "                raise\n",
    "\n",
    "        tokenizer.save_pretrained(model_save_dir)\n",
    "        logger.info(f\"Tokenizer saved to {model_save_dir}\")\n",
    "\n",
    "        if label_mapping:\n",
    "            label_mapping_path = os.path.join(model_save_dir, \"label_mapping.json\")\n",
    "            with open(label_mapping_path, \"w\") as f:\n",
    "\n",
    "                json_mapping = {str(k): int(v) for k, v in label_mapping.items()}\n",
    "                json.dump(json_mapping, f, indent=2)\n",
    "            logger.info(f\"Label mapping saved to {label_mapping_path}\")\n",
    "\n",
    "        model_config = {\n",
    "            \"base_model\": \"bert-base-multilingual-cased\",\n",
    "            \"num_labels\": num_labels,\n",
    "            \"text_column\": text_column,\n",
    "            \"label_column\": label_column,\n",
    "            \"max_length\": 128,\n",
    "\n",
    "            \"dataset_name\": dataset_name,\n",
    "        }\n",
    "\n",
    "        config_path = os.path.join(model_save_dir, \"config.json\")\n",
    "        with open(config_path, \"w\") as f:\n",
    "            json.dump(model_config, f, indent=2)\n",
    "        logger.info(f\"Model config saved to {config_path}\")\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        logger.info(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "        logger.info(f\"Evaluating on validation set with {len(tokenized_dataset['validation'])} examples\")\n",
    "        validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"validation\"])\n",
    "\n",
    "        logger.info(f\"Evaluating on test set with {len(tokenized_dataset['test'])} examples\")\n",
    "        test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "\n",
    "\n",
    "        processed_validation = {}\n",
    "        for k, v in validation_results.items():\n",
    "            if isinstance(v, (int, float, str, bool)) or v is None:\n",
    "                processed_validation[k] = v\n",
    "            else:\n",
    "                processed_validation[k] = float(v)\n",
    "\n",
    "        processed_test = {}\n",
    "        for k, v in test_results.items():\n",
    "            if isinstance(v, (int, float, str, bool)) or v is None:\n",
    "                processed_test[k] = v\n",
    "            else:\n",
    "                processed_test[k] = float(v)\n",
    "\n",
    "        metrics = {\n",
    "            \"training_time\": float(training_time),\n",
    "            \"training_loss\": float(training_loss) if training_loss is not None else None,\n",
    "            \"validation_results\": processed_validation,\n",
    "            \"test_results\": processed_test,\n",
    "        }\n",
    "\n",
    "        metrics_path = os.path.join(model_save_dir, \"metrics.json\")\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        logger.info(f\"Model metrics saved to {metrics_path}\")\n",
    "\n",
    "        logger.info(f\"============== RESULTS FOR {dataset_name} ==============\")\n",
    "        logger.info(f\"Training loss: {training_loss}\")\n",
    "        logger.info(f\"Validation results: {validation_results}\")\n",
    "        logger.info(f\"Test results: {test_results}\")\n",
    "\n",
    "        return {\n",
    "            \"dataset\": dataset_name,\n",
    "            \"training_time\": training_time,\n",
    "            \"training_loss\": training_loss,\n",
    "            \"validation_results\": validation_results,\n",
    "            \"test_results\": test_results,\n",
    "            \"model_path\": model_path,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fine-tuning failed for {dataset_name}: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "available_datasets = []\n",
    "if swa_dataset:\n",
    "    available_datasets.append((\"Swahili\", swa_dataset, 3))\n",
    "if por_dataset:\n",
    "    available_datasets.append((\"Portuguese\", por_dataset, 3))\n",
    "if sot_dataset:\n",
    "    available_datasets.append((\"Sesotho\", sot_dataset, 3))\n",
    "\n",
    "logger.info(f\"Available datasets: {[name for name, _, _ in available_datasets]}\")\n",
    "\n",
    "all_results = []\n",
    "for dataset_name, dataset, num_labels in available_datasets:\n",
    "    logger.info(f\"\\n==== FINE-TUNING ON {dataset_name.upper()} DATASET ====\")\n",
    "    try:\n",
    "        results = finetune_and_evaluate(dataset_name, dataset, num_labels)\n",
    "\n",
    "        if results:\n",
    "            all_results.append(results)\n",
    "        else:\n",
    "            logger.warning(f\"No results returned for {dataset_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error during fine-tuning {dataset_name}: {e}\", exc_info=True)\n",
    "\n",
    "logger.info(\"\\n==== FINE-TUNING COMPLETE ====\")\n",
    "\n",
    "print(f\"{'Dataset':<12} | {'Acc (val)':<10} | {'F1 (val)':<10} | {'Acc (test)':<10} | {'F1 (test)':<10} | {'Model Dir':<20}\")\n",
    "\n",
    "for result in all_results:\n",
    "    dataset = result[\"dataset\"]\n",
    "    val_acc = result[\"validation_results\"].get(\"eval_accuracy\", float('nan'))\n",
    "    val_f1 = result[\"validation_results\"].get(\"eval_f1\", float('nan'))\n",
    "    test_acc = result[\"test_results\"].get(\"eval_accuracy\", float('nan'))\n",
    "    test_f1 = result[\"test_results\"].get(\"eval_f1\", float('nan'))\n",
    "    model_dir = f\"./models/{dataset.lower()}\"\n",
    "\n",
    "    print(f\"{dataset:<12} | {val_acc:<10.4f} | {val_f1:<10.4f} | {test_acc:<10.4f} | {test_f1:<10.4f} | {model_dir}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "247e8797cc878f51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## XLM-RoBERTa\n",
    "### Baseline with [XLM-RoBERTa](https://huggingface.co/docs/transformers/en/model_doc/xlm-roberta)\n"
   ],
   "id": "362ce925a960b9f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861fc298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 14959.61 examples/s]\n",
      "Map:   0%|          | 0/453 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 15750.81 examples/s]\n",
      "Map:   0%|          | 0/748 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 16608.99 examples/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/tmp/ipykernel_9006/4293509063.py:220: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 17953.28 examples/s]\n",
      "Map:   0%|          | 0/767 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 16749.09 examples/s]\n",
      "Map:   0%|          | 0/3662 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 18354.72 examples/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='229' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [229/229 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1741/1741 [00:00<00:00, 20828.20 examples/s]\n",
      "Map:   0%|          | 0/218 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 12974.04 examples/s]\n",
      "Map:   0%|          | 0/218 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 15723.86 examples/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== BENCHMARKING COMPLETE ====\n",
      "\n",
      "Results Summary:\n",
      "      Dataset        Model      Loss  Accuracy        F1  Precision    Recall\n",
      "0     Swahili  XLM-RoBERTa  1.185747  0.106952  0.020667   0.011439  0.106952\n",
      "1  Portuguese  XLM-RoBERTa  1.232671  0.171491  0.050220   0.029417  0.171491\n",
      "2     Sesotho  XLM-RoBERTa  1.040040  0.247706  0.098354   0.061358  0.247706\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import time\n",
    "\n",
    "run_timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "os.makedirs(\"./benchmark_results\", exist_ok=True)\n",
    "\n",
    "output_csv = os.path.abspath(f\"./benchmark_results/xlmroberta_benchmark_results_{run_timestamp}.csv\")\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    \"Dataset\", \"Model\", \"Loss\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\"\n",
    "])\n",
    "\n",
    "try:\n",
    "    swa_dataset = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "except Exception as e:\n",
    "    swa_dataset = None\n",
    "\n",
    "try:\n",
    "    por_dataset = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "except Exception as e:\n",
    "    por_dataset = None\n",
    "\n",
    "try:\n",
    "    sot_dataset = load_dataset(\"csv\", data_files={\"train\": \"./datasets/sotho-news/sotho_news_dataset.csv\"})\n",
    "except Exception as e:\n",
    "    sot_dataset = None\n",
    "    \n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def get_benchmark_metrics(dataset_name, dataset, num_labels):\n",
    "    \n",
    "    if dataset is None:\n",
    "        return None\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"xlm-roberta-base\", \n",
    "        num_labels=num_labels\n",
    "    ).to(device)\n",
    "    \n",
    "    text_column = None\n",
    "    label_column = None\n",
    "    \n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in text_candidates:\n",
    "            if candidate in columns:\n",
    "                text_column = candidate\n",
    "                break\n",
    "        if text_column:\n",
    "            break\n",
    "    \n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in label_candidates:\n",
    "            if candidate in columns:\n",
    "                label_column = candidate\n",
    "                break\n",
    "        if label_column:\n",
    "            break\n",
    "    \n",
    "    if text_column is None:\n",
    "        for split in dataset:\n",
    "            for col in dataset[split].column_names:\n",
    "                if isinstance(dataset[split][col][0], str):\n",
    "                    text_column = col\n",
    "                    break\n",
    "            if text_column:\n",
    "                break\n",
    "    \n",
    "    if text_column is None:\n",
    "        return None\n",
    "    \n",
    "    if label_column is None:\n",
    "        return None\n",
    "    \n",
    "    required_splits = [\"train\", \"validation\", \"test\"]\n",
    "    missing_splits = [split for split in required_splits if split not in dataset]\n",
    "    \n",
    "    if missing_splits:\n",
    "        if \"train\" in dataset:\n",
    "            train_valid_test = {}\n",
    "            \n",
    "            for split in dataset:\n",
    "                if split in required_splits:\n",
    "                    train_valid_test[split] = dataset[split]\n",
    "            \n",
    "            if \"train\" in dataset and (\"validation\" not in train_valid_test or \"test\" not in train_valid_test):\n",
    "                if \"validation\" not in train_valid_test:\n",
    "                    if \"test\" not in train_valid_test:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                        test_valid_split = split_datasets[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = test_valid_split[\"train\"]\n",
    "                        train_valid_test[\"test\"] = test_valid_split[\"test\"]\n",
    "                    else:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = split_datasets[\"test\"]\n",
    "                else:\n",
    "                    split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                    train_valid_test[\"test\"] = split_datasets[\"test\"]\n",
    "            \n",
    "            dataset = DatasetDict(train_valid_test)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    label_mapping = None\n",
    "    for split in dataset:\n",
    "        if isinstance(dataset[split][label_column][0], str):\n",
    "            all_labels = set()\n",
    "            for example in dataset[split][label_column]:\n",
    "                all_labels.add(example)\n",
    "            \n",
    "            label_mapping = {label: i for i, label in enumerate(sorted(all_labels))}\n",
    "            break\n",
    "    \n",
    "    processed_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in dataset.items():\n",
    "        texts = split_dataset[text_column]\n",
    "        \n",
    "        if label_mapping:\n",
    "            labels = [label_mapping[label] for label in split_dataset[label_column]]\n",
    "        else:\n",
    "            labels = []\n",
    "            for label in split_dataset[label_column]:\n",
    "                if isinstance(label, (int, np.integer)):\n",
    "                    labels.append(int(label))\n",
    "                elif isinstance(label, str):\n",
    "                    try:\n",
    "                        labels.append(int(label))\n",
    "                    except ValueError:\n",
    "                        labels.append(0)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "        \n",
    "        processed_dataset[split_name] = Dataset.from_dict({\n",
    "            \"text\": texts,\n",
    "            \"label\": labels\n",
    "        })\n",
    "        \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in processed_dataset.items():\n",
    "        tokenized_split = split_dataset.map(\n",
    "            tokenize_function, \n",
    "            batched=True, \n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "        tokenized_dataset[split_name] = tokenized_split\n",
    "        \n",
    "        for required_col in [\"input_ids\", \"attention_mask\", \"label\"]:\n",
    "            if required_col not in tokenized_split.column_names:\n",
    "                return None\n",
    "    \n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=f\"./benchmark_results/{dataset_name}_{run_timestamp}\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        logging_dir=f\"./benchmark_results/{dataset_name}_{run_timestamp}/logs\",\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=True\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=eval_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        benchmark_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "        \n",
    "        return benchmark_results\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "available_datasets = []\n",
    "if swa_dataset:\n",
    "    available_datasets.append((\"Swahili\", swa_dataset, 3))\n",
    "if por_dataset:\n",
    "    available_datasets.append((\"Portuguese\", por_dataset, 3))\n",
    "if sot_dataset:\n",
    "    available_datasets.append((\"Sesotho\", sot_dataset, 3))\n",
    "\n",
    "all_results = []\n",
    "for dataset_name, dataset, num_labels in available_datasets:\n",
    "    try:\n",
    "        results = get_benchmark_metrics(dataset_name, dataset, num_labels)\n",
    "        \n",
    "        if results:\n",
    "            results_df = results_df._append({\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"Model\": \"XLM-RoBERTa\",\n",
    "                \"Loss\": results.get(\"eval_loss\"),\n",
    "                \"Accuracy\": results.get(\"eval_accuracy\"),\n",
    "                \"F1\": results.get(\"eval_f1\"),\n",
    "                \"Precision\": results.get(\"eval_precision\"),\n",
    "                \"Recall\": results.get(\"eval_recall\")\n",
    "            }, ignore_index=True)\n",
    "            \n",
    "            all_results.append({\"Dataset\": dataset_name, \"Results\": results})\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "except Exception as e:\n",
    "    emergency_path = f\"./emergency_results_{run_timestamp}.csv\"\n",
    "    results_df.to_csv(emergency_path, index=False)\n",
    "\n",
    "print(\"\\n==== BENCHMARKING COMPLETE ====\")\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b847f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:45,859 - INFO - Successfully loaded Swahili dataset from HuggingFace Hub\n",
      "2025-05-12 08:11:47,817 - INFO - Successfully loaded Portuguese dataset from HuggingFace Hub\n",
      "2025-05-12 08:11:48,086 - INFO - Successfully loaded Sesotho dataset from CSV\n",
      "2025-05-12 08:11:48,088 - INFO - Available datasets: ['Swahili', 'Portuguese', 'Sesotho']\n",
      "2025-05-12 08:11:48,088 - INFO - \n",
      "==== FINE-TUNING ON SWAHILI DATASET ====\n",
      "2025-05-12 08:11:48,089 - INFO - Starting fine-tuning for Swahili\n",
      "2025-05-12 08:11:48,209 - INFO - Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:50,147 - INFO - Dataset Swahili structure:\n",
      "2025-05-12 08:11:50,148 - INFO -   - Split: train, Examples: 1810\n",
      "2025-05-12 08:11:50,149 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-12 08:11:50,149 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-12 08:11:50,150 - INFO -   - Split: validation, Examples: 453\n",
      "2025-05-12 08:11:50,150 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-12 08:11:50,151 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-12 08:11:50,151 - INFO -   - Split: test, Examples: 748\n",
      "2025-05-12 08:11:50,151 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-12 08:11:50,152 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-12 08:11:50,152 - INFO - For Swahili, using text_column=tweet, label_column=label\n",
      "2025-05-12 08:11:50,156 - INFO - Created label mapping for Swahili: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-12 08:11:50,164 - INFO - Processed train split: 1810 examples\n",
      "2025-05-12 08:11:50,169 - INFO - Processed validation split: 453 examples\n",
      "2025-05-12 08:11:50,174 - INFO - Processed test split: 748 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 21445.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:50,285 - INFO - Tokenized train split: 1810 examples\n",
      "2025-05-12 08:11:50,285 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 21110.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:50,328 - INFO - Tokenized validation split: 453 examples\n",
      "2025-05-12 08:11:50,328 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 21557.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:50,383 - INFO - Tokenized test split: 748 examples\n",
      "2025-05-12 08:11:50,383 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:50,408 - INFO - Starting fine-tuning Swahili with 1810 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/342 : < :, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:51,406 - ERROR - Fine-tuning failed for Swahili: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 5.68 GiB of which 550.44 MiB is free. Including non-PyTorch memory, this process has 5.08 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 795.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_11049/2726313652.py\", line 254, in finetune_and_evaluate\n",
      "    train_output = trainer.train()\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2611, in _inner_training_loop\n",
      "    self.optimizer.step()\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/accelerate/optimizer.py\", line 178, in step\n",
      "    self.optimizer.step(closure)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py\", line 124, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 485, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 79, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 246, in step\n",
      "    adam(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 147, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 933, in adam\n",
      "    func(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 757, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 5.68 GiB of which 550.44 MiB is free. Including non-PyTorch memory, this process has 5.08 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 795.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-05-12 08:11:51,574 - WARNING - No results returned for Swahili\n",
      "2025-05-12 08:11:51,576 - INFO - \n",
      "==== FINE-TUNING ON PORTUGUESE DATASET ====\n",
      "2025-05-12 08:11:51,577 - INFO - Starting fine-tuning for Portuguese\n",
      "2025-05-12 08:11:51,578 - INFO - Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:53,200 - INFO - Dataset Portuguese structure:\n",
      "2025-05-12 08:11:53,201 - INFO -   - Split: train, Examples: 3063\n",
      "2025-05-12 08:11:53,201 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-12 08:11:53,202 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-12 08:11:53,202 - INFO -   - Split: validation, Examples: 767\n",
      "2025-05-12 08:11:53,202 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-12 08:11:53,203 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-12 08:11:53,203 - INFO -   - Split: test, Examples: 3662\n",
      "2025-05-12 08:11:53,203 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-12 08:11:53,203 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-12 08:11:53,204 - INFO - For Portuguese, using text_column=tweet, label_column=label\n",
      "2025-05-12 08:11:53,209 - INFO - Created label mapping for Portuguese: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-12 08:11:53,219 - INFO - Processed train split: 3063 examples\n",
      "2025-05-12 08:11:53,225 - INFO - Processed validation split: 767 examples\n",
      "2025-05-12 08:11:53,236 - INFO - Processed test split: 3662 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 21644.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:53,408 - INFO - Tokenized train split: 3063 examples\n",
      "2025-05-12 08:11:53,408 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 20834.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:53,469 - INFO - Tokenized validation split: 767 examples\n",
      "2025-05-12 08:11:53,470 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 22204.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:53,658 - INFO - Tokenized test split: 3662 examples\n",
      "2025-05-12 08:11:53,658 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:53,681 - INFO - Starting fine-tuning Portuguese with 3063 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/576 : < :, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:54,496 - ERROR - Fine-tuning failed for Portuguese: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 5.68 GiB of which 538.44 MiB is free. Including non-PyTorch memory, this process has 5.09 GiB memory in use. Of the allocated memory 4.17 GiB is allocated by PyTorch, and 806.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_11049/2726313652.py\", line 254, in finetune_and_evaluate\n",
      "    train_output = trainer.train()\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2611, in _inner_training_loop\n",
      "    self.optimizer.step()\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/accelerate/optimizer.py\", line 178, in step\n",
      "    self.optimizer.step(closure)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py\", line 124, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 485, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 79, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 246, in step\n",
      "    adam(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 147, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 933, in adam\n",
      "    func(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 757, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 5.68 GiB of which 538.44 MiB is free. Including non-PyTorch memory, this process has 5.09 GiB memory in use. Of the allocated memory 4.17 GiB is allocated by PyTorch, and 806.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-05-12 08:11:54,678 - WARNING - No results returned for Portuguese\n",
      "2025-05-12 08:11:54,679 - INFO - \n",
      "==== FINE-TUNING ON SESOTHO DATASET ====\n",
      "2025-05-12 08:11:54,680 - INFO - Starting fine-tuning for Sesotho\n",
      "2025-05-12 08:11:54,680 - INFO - Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:56,281 - INFO - Dataset Sesotho structure:\n",
      "2025-05-12 08:11:56,282 - INFO -   - Split: train, Examples: 2177\n",
      "2025-05-12 08:11:56,282 - INFO -   - Features: {'headline': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-12 08:11:56,283 - INFO -   - Columns: ['headline', 'label']\n",
      "2025-05-12 08:11:56,283 - INFO - For Sesotho, using text_column=headline, label_column=label\n",
      "2025-05-12 08:11:56,283 - INFO - Creating missing splits: ['validation', 'test'] for Sesotho\n",
      "2025-05-12 08:11:56,302 - INFO - Created label mapping for Sesotho: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-12 08:11:56,319 - INFO - Processed train split: 1741 examples\n",
      "2025-05-12 08:11:56,324 - INFO - Processed validation split: 218 examples\n",
      "2025-05-12 08:11:56,329 - INFO - Processed test split: 218 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1741/1741 [00:00<00:00, 25323.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:56,423 - INFO - Tokenized train split: 1741 examples\n",
      "2025-05-12 08:11:56,424 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 20183.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:56,458 - INFO - Tokenized validation split: 218 examples\n",
      "2025-05-12 08:11:56,459 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 19098.47 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:56,495 - INFO - Tokenized test split: 218 examples\n",
      "2025-05-12 08:11:56,496 - INFO - Columns after tokenization: ['label', 'input_ids', 'attention_mask']\n",
      "2025-05-12 08:11:56,520 - INFO - Starting fine-tuning Sesotho with 1741 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/327 : < :, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 08:11:57,338 - ERROR - Fine-tuning failed for Sesotho: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 5.68 GiB of which 494.44 MiB is free. Including non-PyTorch memory, this process has 5.13 GiB memory in use. Of the allocated memory 4.17 GiB is allocated by PyTorch, and 847.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_11049/2726313652.py\", line 254, in finetune_and_evaluate\n",
      "    train_output = trainer.train()\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2611, in _inner_training_loop\n",
      "    self.optimizer.step()\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/accelerate/optimizer.py\", line 178, in step\n",
      "    self.optimizer.step(closure)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py\", line 124, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 485, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 79, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 246, in step\n",
      "    adam(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 147, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 933, in adam\n",
      "    func(\n",
      "  File \"/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/torch/optim/adam.py\", line 757, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 5.68 GiB of which 494.44 MiB is free. Including non-PyTorch memory, this process has 5.13 GiB memory in use. Of the allocated memory 4.17 GiB is allocated by PyTorch, and 847.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-05-12 08:11:57,524 - WARNING - No results returned for Sesotho\n",
      "2025-05-12 08:11:57,528 - INFO - \n",
      "==== FINE-TUNING COMPLETE ====\n",
      "Dataset      | Acc (val)  | F1 (val)   | Acc (test) | F1 (test)  | Model Dir           \n"
     ]
    }
   ],
   "source": [
    "#run this on google colab, my gpu doesnt have enough vram - Troy\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    swa_dataset = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "    logger.info(\"Successfully loaded Swahili dataset from HuggingFace Hub\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Swahili dataset: {e}\")\n",
    "    swa_dataset = None\n",
    "\n",
    "try:\n",
    "    por_dataset = load_dataset(\"masakhane/afrisenti\", \"por\") \n",
    "    logger.info(\"Successfully loaded Portuguese dataset from HuggingFace Hub\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Portuguese dataset: {e}\")\n",
    "    por_dataset = None\n",
    "\n",
    "try:\n",
    "    sot_dataset = load_dataset(\"csv\", data_files={\"train\": \"./datasets/sotho-news/sotho_news_dataset.csv\"})\n",
    "    logger.info(\"Successfully loaded Sesotho dataset from CSV\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Sesotho dataset: {e}\")\n",
    "    sot_dataset = None\n",
    "    \n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def finetune_and_evaluate(dataset_name, dataset, num_labels):\n",
    "    logger.info(f\"Starting fine-tuning for {dataset_name}\")\n",
    "    \n",
    "    if dataset is None:\n",
    "        logger.error(f\"Dataset {dataset_name} is None, cannot proceed with fine-tuning\")\n",
    "        return None\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    \n",
    "    model_save_dir = f\"./models/{dataset_name.lower()}\"\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"xlm-roberta-base\", \n",
    "        num_labels=num_labels\n",
    "    ).to(device)\n",
    "    \n",
    "    logger.info(f\"Dataset {dataset_name} structure:\")\n",
    "    for split in dataset:\n",
    "        logger.info(f\"  - Split: {split}, Examples: {len(dataset[split])}\")\n",
    "        logger.info(f\"  - Features: {dataset[split].features}\")\n",
    "        logger.info(f\"  - Columns: {dataset[split].column_names}\")\n",
    "    \n",
    "    text_column = None\n",
    "    label_column = None\n",
    "    \n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\", \"headline\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in text_candidates:\n",
    "            if candidate in columns:\n",
    "                text_column = candidate\n",
    "                break\n",
    "        if text_column:\n",
    "            break\n",
    "    \n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in label_candidates:\n",
    "            if candidate in columns:\n",
    "                label_column = candidate\n",
    "                break\n",
    "        if label_column:\n",
    "            break\n",
    "    \n",
    "    logger.info(f\"For {dataset_name}, using text_column={text_column}, label_column={label_column}\")\n",
    "    \n",
    "    if text_column is None:\n",
    "        for split in dataset:\n",
    "            for col in dataset[split].column_names:\n",
    "                if isinstance(dataset[split][col][0], str):\n",
    "                    text_column = col\n",
    "                    logger.info(f\"Using '{col}' as text column based on string data\")\n",
    "                    break\n",
    "            if text_column:\n",
    "                break\n",
    "    \n",
    "    if text_column is None:\n",
    "        logger.error(f\"Could not identify a text column for {dataset_name}\")\n",
    "        return None\n",
    "    \n",
    "    if label_column is None:\n",
    "        logger.error(f\"Could not identify a label column for {dataset_name}\")\n",
    "        return None\n",
    "    \n",
    "    required_splits = [\"train\", \"validation\", \"test\"]\n",
    "    missing_splits = [split for split in required_splits if split not in dataset]\n",
    "    \n",
    "    if missing_splits:\n",
    "        logger.info(f\"Creating missing splits: {missing_splits} for {dataset_name}\")\n",
    "        if \"train\" in dataset:\n",
    "            train_valid_test = {}\n",
    "            \n",
    "            for split in dataset:\n",
    "                if split in required_splits:\n",
    "                    train_valid_test[split] = dataset[split]\n",
    "            \n",
    "            if \"train\" in dataset and (\"validation\" not in train_valid_test or \"test\" not in train_valid_test):\n",
    "                if \"validation\" not in train_valid_test:\n",
    "                    if \"test\" not in train_valid_test:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                        test_valid_split = split_datasets[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = test_valid_split[\"train\"]\n",
    "                        train_valid_test[\"test\"] = test_valid_split[\"test\"]\n",
    "                    else:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = split_datasets[\"test\"]\n",
    "                else:\n",
    "                    split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                    train_valid_test[\"test\"] = split_datasets[\"test\"]\n",
    "            \n",
    "            dataset = DatasetDict(train_valid_test)\n",
    "        else:\n",
    "            logger.error(f\"Dataset {dataset_name} has no train split and cannot create splits\")\n",
    "            return None\n",
    "    \n",
    "    label_mapping = None\n",
    "    for split in dataset:\n",
    "        if isinstance(dataset[split][label_column][0], str):\n",
    "            all_labels = set()\n",
    "            for example in dataset[split][label_column]:\n",
    "                all_labels.add(example)\n",
    "            \n",
    "            label_mapping = {label: i for i, label in enumerate(sorted(all_labels))}\n",
    "            logger.info(f\"Created label mapping for {dataset_name}: {label_mapping}\")\n",
    "            break\n",
    "    \n",
    "    processed_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in dataset.items():\n",
    "        texts = split_dataset[text_column]\n",
    "        \n",
    "        if label_mapping:\n",
    "            labels = [label_mapping[label] for label in split_dataset[label_column]]\n",
    "        else:\n",
    "            labels = []\n",
    "            for label in split_dataset[label_column]:\n",
    "                if isinstance(label, (int, np.integer)):\n",
    "                    labels.append(int(label))\n",
    "                elif isinstance(label, str):\n",
    "                    try:\n",
    "                        labels.append(int(label))\n",
    "                    except ValueError:\n",
    "                        logger.warning(f\"Unexpected string label found in {split_name}: {label}\")\n",
    "                        labels.append(0)\n",
    "                else:\n",
    "                    logger.warning(f\"Unexpected label type in {split_name}: {type(label)}\")\n",
    "                    labels.append(0)\n",
    "        \n",
    "        processed_dataset[split_name] = Dataset.from_dict({\n",
    "            \"text\": texts,\n",
    "            \"label\": labels\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"Processed {split_name} split: {len(processed_dataset[split_name])} examples\")\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=128,\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in processed_dataset.items():\n",
    "        tokenized_split = split_dataset.map(\n",
    "            tokenize_function, \n",
    "            batched=True, \n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "        tokenized_dataset[split_name] = tokenized_split\n",
    "        \n",
    "        logger.info(f\"Tokenized {split_name} split: {len(tokenized_split)} examples\")\n",
    "        logger.info(f\"Columns after tokenization: {tokenized_split.column_names}\")\n",
    "        \n",
    "        for required_col in [\"input_ids\", \"attention_mask\", \"label\"]:\n",
    "            if required_col not in tokenized_split.column_names:\n",
    "                logger.error(f\"Required column {required_col} missing after tokenization\")\n",
    "                return None\n",
    "    \n",
    "    model_output_dir = f\"./tmp_model_dir_{dataset_name}\"\n",
    "    if os.path.exists(model_output_dir):\n",
    "        shutil.rmtree(model_output_dir)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_output_dir,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./tmp_logs\",\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"no\",\n",
    "        save_steps=1000000,\n",
    "        eval_steps=100,\n",
    "        do_eval=True,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Starting fine-tuning {dataset_name} with {len(tokenized_dataset['train'])} examples\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        try:\n",
    "            train_output = trainer.train()\n",
    "            \n",
    "            training_loss = None\n",
    "            try:\n",
    "                if hasattr(train_output, \"metrics\") and \"loss\" in train_output.metrics:\n",
    "                    training_loss = train_output.metrics[\"loss\"]\n",
    "                elif isinstance(train_output, dict) and \"loss\" in train_output:\n",
    "                    training_loss = train_output[\"loss\"]\n",
    "                \n",
    "                if training_loss is None and hasattr(trainer, \"state\"):\n",
    "                    if hasattr(trainer.state, \"log_history\") and trainer.state.log_history:\n",
    "                        for log in reversed(trainer.state.log_history):\n",
    "                            if \"loss\" in log:\n",
    "                                training_loss = log[\"loss\"]\n",
    "                                break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not extract training loss: {e}\")\n",
    "        except RuntimeError as e:\n",
    "            if \"PytorchStreamWriter failed writing file\" in str(e):\n",
    "                logger.warning(\"Caught PyTorch serialization error during training. Will proceed with model saving.\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                raise\n",
    "        \n",
    "        try:\n",
    "            model_path = os.path.join(model_save_dir, \"model.pt\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            logger.info(f\"Model saved to {model_path}\")\n",
    "        except RuntimeError as e:\n",
    "            if \"PytorchStreamWriter failed writing file\" in str(e):\n",
    "                logger.warning(f\"PyTorch serialization error when saving model state dict. Trying alternative method.\")\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    with open(model_path, 'wb') as f:\n",
    "                        torch.save(model.state_dict(), f, _use_new_zipfile_serialization=False)\n",
    "                    logger.info(f\"Model saved to {model_path} using legacy serialization\")\n",
    "                except Exception as e2:\n",
    "                    logger.error(f\"Failed to save model with alternative method: {e2}\")\n",
    "            else:\n",
    "                \n",
    "                raise\n",
    "        \n",
    "        tokenizer.save_pretrained(model_save_dir)\n",
    "        logger.info(f\"Tokenizer saved to {model_save_dir}\")\n",
    "        \n",
    "        if label_mapping:\n",
    "            label_mapping_path = os.path.join(model_save_dir, \"label_mapping.json\")\n",
    "            with open(label_mapping_path, \"w\") as f:\n",
    "                \n",
    "                json_mapping = {str(k): int(v) for k, v in label_mapping.items()}\n",
    "                json.dump(json_mapping, f, indent=2)\n",
    "            logger.info(f\"Label mapping saved to {label_mapping_path}\")\n",
    "            \n",
    "        model_config = {\n",
    "            \"base_model\": \"xlm-roberta-base\",\n",
    "            \"num_labels\": num_labels,\n",
    "            \"text_column\": text_column,\n",
    "            \"label_column\": label_column,\n",
    "            \"max_length\": 128,\n",
    "            \n",
    "            \"dataset_name\": dataset_name,\n",
    "        }\n",
    "        \n",
    "        config_path = os.path.join(model_save_dir, \"config.json\")\n",
    "        with open(config_path, \"w\") as f:\n",
    "            json.dump(model_config, f, indent=2)\n",
    "        logger.info(f\"Model config saved to {config_path}\")\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        logger.info(f\"Training completed in {training_time:.2f} seconds\")\n",
    "        \n",
    "        logger.info(f\"Evaluating on validation set with {len(tokenized_dataset['validation'])} examples\")\n",
    "        validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"validation\"])\n",
    "        \n",
    "        logger.info(f\"Evaluating on test set with {len(tokenized_dataset['test'])} examples\")\n",
    "        test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "        \n",
    "        \n",
    "        processed_validation = {}\n",
    "        for k, v in validation_results.items():\n",
    "            if isinstance(v, (int, float, str, bool)) or v is None:\n",
    "                processed_validation[k] = v\n",
    "            else:\n",
    "                processed_validation[k] = float(v)\n",
    "                \n",
    "        processed_test = {}\n",
    "        for k, v in test_results.items():\n",
    "            if isinstance(v, (int, float, str, bool)) or v is None:\n",
    "                processed_test[k] = v\n",
    "            else:\n",
    "                processed_test[k] = float(v)\n",
    "        \n",
    "        metrics = {\n",
    "            \"training_time\": float(training_time),\n",
    "            \"training_loss\": float(training_loss) if training_loss is not None else None,\n",
    "            \"validation_results\": processed_validation,\n",
    "            \"test_results\": processed_test,\n",
    "        }\n",
    "        \n",
    "        metrics_path = os.path.join(model_save_dir, \"metrics.json\")\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        logger.info(f\"Model metrics saved to {metrics_path}\")\n",
    "        \n",
    "        logger.info(f\"============== RESULTS FOR {dataset_name} ==============\")\n",
    "        logger.info(f\"Training loss: {training_loss}\")\n",
    "        logger.info(f\"Validation results: {validation_results}\")\n",
    "        logger.info(f\"Test results: {test_results}\")\n",
    "        \n",
    "        return {\n",
    "            \"dataset\": dataset_name,\n",
    "            \"training_time\": training_time,\n",
    "            \"training_loss\": training_loss,\n",
    "            \"validation_results\": validation_results,\n",
    "            \"test_results\": test_results,\n",
    "            \"model_path\": model_path,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fine-tuning failed for {dataset_name}: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "available_datasets = []\n",
    "if swa_dataset:\n",
    "    available_datasets.append((\"Swahili\", swa_dataset, 3))\n",
    "if por_dataset:\n",
    "    available_datasets.append((\"Portuguese\", por_dataset, 3))\n",
    "if sot_dataset:\n",
    "    available_datasets.append((\"Sesotho\", sot_dataset, 3))\n",
    "\n",
    "logger.info(f\"Available datasets: {[name for name, _, _ in available_datasets]}\")\n",
    "\n",
    "all_results = []\n",
    "for dataset_name, dataset, num_labels in available_datasets:\n",
    "    logger.info(f\"\\n==== FINE-TUNING ON {dataset_name.upper()} DATASET ====\")a\n",
    "    try:\n",
    "        results = finetune_and_evaluate(dataset_name, dataset, num_labels)\n",
    "        \n",
    "        if results:\n",
    "            all_results.append(results)\n",
    "        else:\n",
    "            logger.warning(f\"No results returned for {dataset_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error during fine-tuning {dataset_name}: {e}\", exc_info=True)\n",
    "\n",
    "logger.info(\"\\n==== FINE-TUNING COMPLETE ====\")\n",
    "\n",
    "print(f\"{'Dataset':<12} | {'Acc (val)':<10} | {'F1 (val)':<10} | {'Acc (test)':<10} | {'F1 (test)':<10} | {'Model Dir':<20}\")\n",
    "\n",
    "for result in all_results:\n",
    "    dataset = result[\"dataset\"]\n",
    "    val_acc = result[\"validation_results\"].get(\"eval_accuracy\", float('nan'))\n",
    "    val_f1 = result[\"validation_results\"].get(\"eval_f1\", float('nan'))\n",
    "    test_acc = result[\"test_results\"].get(\"eval_accuracy\", float('nan'))\n",
    "    test_f1 = result[\"test_results\"].get(\"eval_f1\", float('nan'))\n",
    "    model_dir = f\"./models/{dataset.lower()}\"\n",
    "    \n",
    "    print(f\"{dataset:<12} | {val_acc:<10.4f} | {val_f1:<10.4f} | {test_acc:<10.4f} | {test_f1:<10.4f} | {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73b1e1",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5242ae",
   "metadata": {},
   "source": [
    "Firstly, we want to check the actual distribution of the classes for Mozambican Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f7e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Swahili (swa) dataset from disk...\n",
      "Swahili dataset loaded!\n",
      "Loading Portuguese (por) dataset from disk...\n",
      "Portuguese dataset loaded!\n",
      "Loading Sesotho (sot) dataset from disk...\n",
      "Sesotho dataset loaded!\n",
      "Portuguese dataset size: 3063 examples\n",
      "Dataset features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "\n",
      "Sample entry:\n",
      "{'tweet': 'Pedi uma resposta a Deus, ele deu me. Estou muito triste com ela. Mas mais tarde sei que vou entender.', 'label': 'negative'}\n",
      "\n",
      "Sentiment Distribution:\n",
      "Negative: 782 (25.53%)\n",
      "Neutral: 1600 (52.24%)\n",
      "Positive: 681 (22.23%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk, load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_sentiment_distribution(dataset, split='train'):\n",
    "    \"\"\"Analyze sentiment distribution in a dataset with string labels.\"\"\"\n",
    "    if dataset is None:\n",
    "        return\n",
    "    \n",
    "    # Count the occurrences of each sentiment label\n",
    "    label_counts = Counter(dataset[split]['label'])\n",
    "    \n",
    "    # Print the distribution\n",
    "    print(f\"\\nSentiment Distribution:\")\n",
    "    total = len(dataset[split])\n",
    "    \n",
    "    # Sort labels in a meaningful order: negative, neutral, positive\n",
    "    ordered_labels = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    for label in ordered_labels:\n",
    "        if label in label_counts:\n",
    "            count = label_counts[label]\n",
    "            percentage = (count / total) * 100\n",
    "            # Capitalize first letter for display\n",
    "            display_label = label.capitalize()\n",
    "            print(f\"{display_label}: {count} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Check for any other labels not in our expected list\n",
    "    for label, count in label_counts.items():\n",
    "        if label not in ordered_labels:\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"Other ({label}): {count} ({percentage:.2f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    swa, por, sot = load_local_datasets()\n",
    "\n",
    "    if por is not None:\n",
    "        print(f\"Portuguese dataset size: {len(por['train'])} examples\")\n",
    "        print(f\"Dataset features: {por['train'].features}\")\n",
    "        print(\"\\nSample entry:\")\n",
    "        print(por['train'][0])\n",
    "        analyze_sentiment_distribution(por)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60be43",
   "metadata": {},
   "source": [
    "### There is a clear imbalance in the classes and so data augmentation techniques will be used such as dropout and back-translation in order to create synthetic data for the minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243185bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Swahili (swa) dataset from disk...\n",
      "Swahili dataset loaded!\n",
      "Loading Portuguese (por) dataset from disk...\n",
      "Portuguese dataset loaded!\n",
      "Loading Sesotho (sot) dataset from disk...\n",
      "Sesotho dataset loaded!\n",
      "Original Portuguese dataset:\n",
      "\n",
      "Sentiment Distribution:\n",
      "Negative: 782 (25.53%)\n",
      "Neutral: 1600 (52.24%)\n",
      "Positive: 681 (22.23%)\n",
      "\n",
      "After balancing and augmentation:\n",
      "\n",
      "Sentiment Distribution:\n",
      "Negative: 1120 (33.33%)\n",
      "Neutral: 1120 (33.33%)\n",
      "Positive: 1120 (33.33%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 3360/3360 [00:00<00:00, 660056.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced and augmented dataset saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from datasets import load_from_disk, load_dataset, Dataset\n",
    "from collections import Counter\n",
    "\n",
    "def load_local_datasets():\n",
    "    swa_path = \"./datasets/afrisenti/swa\"\n",
    "    por_path = \"./datasets/afrisenti/por\"\n",
    "    sot_path = \"./datasets/news\"\n",
    "\n",
    "    if not all(os.path.exists(path) for path in [swa_path, por_path, sot_path]):\n",
    "        print(\"One or more dataset directories not found. Please check the paths.\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(\"Loading Swahili (swa) dataset from disk...\")\n",
    "    swa_dataset = load_from_disk(swa_path)\n",
    "    print(\"Swahili dataset loaded!\")\n",
    "\n",
    "    print(\"Loading Portuguese (por) dataset from disk...\")\n",
    "    por_dataset = load_from_disk(por_path)\n",
    "    print(\"Portuguese dataset loaded!\")\n",
    "\n",
    "    print(\"Loading Sesotho (sot) dataset from disk...\")\n",
    "    sot_dataset = load_dataset(\"csv\", data_files=\"datasets/sotho-news/sotho_news_dataset.csv\")\n",
    "    print(\"Sesotho dataset loaded!\")\n",
    "\n",
    "    return swa_dataset, por_dataset, sot_dataset\n",
    "\n",
    "def analyze_sentiment_distribution(dataset, split='train'):\n",
    "    \"\"\"Analyze sentiment distribution in a dataset with string labels.\"\"\"\n",
    "    if dataset is None:\n",
    "        return\n",
    "    \n",
    "    # Check if this is a Dataset object with splits or just a simple Dataset\n",
    "    if split in dataset:\n",
    "        # This is a dataset with splits\n",
    "        data = dataset[split]\n",
    "    else:\n",
    "        # This is a simple Dataset without splits\n",
    "        data = dataset\n",
    "    \n",
    "    # Count the occurrences of each sentiment label\n",
    "    label_counts = Counter(data['label'])\n",
    "    \n",
    "    # Print the distribution\n",
    "    print(f\"\\nSentiment Distribution:\")\n",
    "    total = len(data)\n",
    "    \n",
    "    # Sort labels in a meaningful order: negative, neutral, positive\n",
    "    ordered_labels = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    for label in ordered_labels:\n",
    "        if label in label_counts:\n",
    "            count = label_counts[label]\n",
    "            percentage = (count / total) * 100\n",
    "            # Capitalize first letter for display\n",
    "            display_label = label.capitalize()\n",
    "            print(f\"{display_label}: {count} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Check for any other labels not in our expected list\n",
    "    for label, count in label_counts.items():\n",
    "        if label not in ordered_labels:\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"Other ({label}): {count} ({percentage:.2f}%)\")\n",
    "\n",
    "def simple_augment_text(text):\n",
    "    \"\"\"Simple text augmentation without relying on translation models\"\"\"\n",
    "    augmentation_techniques = [\n",
    "        lambda t: word_deletion(t, p=0.1),\n",
    "        lambda t: word_swap(t, p=0.1),\n",
    "        lambda t: add_punctuation(t)\n",
    "    ]\n",
    "    \n",
    "    # Randomly select an augmentation technique\n",
    "    technique = random.choice(augmentation_techniques)\n",
    "    return technique(text)\n",
    "\n",
    "def word_deletion(text, p=0.1):\n",
    "    \"\"\"Randomly delete words with probability p\"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) <= 3:  # Don't delete from very short texts\n",
    "        return text\n",
    "        \n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if random.random() > p:  # Keep the word with probability (1-p)\n",
    "            new_words.append(word)\n",
    "    \n",
    "    # Ensure we don't delete all words\n",
    "    if not new_words:\n",
    "        return random.choice(words)\n",
    "        \n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def word_swap(text, p=0.1):\n",
    "    \"\"\"Randomly swap adjacent words with probability p\"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) <= 1:\n",
    "        return text\n",
    "        \n",
    "    for i in range(len(words) - 1):\n",
    "        if random.random() < p:\n",
    "            words[i], words[i+1] = words[i+1], words[i]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "def add_punctuation(text):\n",
    "    \"\"\"Add or modify punctuation without changing meaning\"\"\"\n",
    "    # Add emphasis for positive/negative texts\n",
    "    if text[-1] not in '!?.':\n",
    "        if random.random() < 0.5:\n",
    "            text += '!'\n",
    "        else:\n",
    "            text += '.'\n",
    "    elif text[-1] == '.' and random.random() < 0.3:\n",
    "        text = text[:-1] + '!'\n",
    "    \n",
    "    return text\n",
    "\n",
    "def balance_and_augment_dataset(dataset, target_neutral_ratio=0.7, split='train'):\n",
    "    \"\"\"\n",
    "    Balance and augment dataset:\n",
    "    1. Undersample neutral class\n",
    "    2. Augment negative and positive classes using simple techniques\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each label\n",
    "    label_counts = {}\n",
    "    for label in ['negative', 'neutral', 'positive']:\n",
    "        label_counts[label] = sum(1 for l in dataset[split]['label'] if l == label)\n",
    "    \n",
    "    # Separate data by label\n",
    "    data_by_label = {\n",
    "        'negative': [],\n",
    "        'neutral': [],\n",
    "        'positive': []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(dataset[split])):\n",
    "        label = dataset[split][i]['label']\n",
    "        data_by_label[label].append({\n",
    "            'tweet': dataset[split][i]['tweet'],\n",
    "            'label': label\n",
    "        })\n",
    "    \n",
    "    # Undersample neutral class\n",
    "    neutral_target_size = int(label_counts['neutral'] * target_neutral_ratio)\n",
    "    sampled_neutral = random.sample(data_by_label['neutral'], neutral_target_size)\n",
    "    \n",
    "    # Prepare balanced data with originals\n",
    "    balanced_data = data_by_label['negative'] + sampled_neutral + data_by_label['positive']\n",
    "    \n",
    "    # Augment minority classes\n",
    "    augmented_data = balanced_data.copy()\n",
    "    \n",
    "    # Target count for each class after balancing\n",
    "    target_count = max(len(data_by_label['negative']), len(data_by_label['positive']), neutral_target_size)\n",
    "    \n",
    "    # Augment negative class\n",
    "    negative_to_add = target_count - len(data_by_label['negative'])\n",
    "    if negative_to_add > 0:\n",
    "        # Select samples to augment (can select the same sample multiple times)\n",
    "        for _ in range(negative_to_add):\n",
    "            sample = random.choice(data_by_label['negative'])\n",
    "            augmented_tweet = simple_augment_text(sample['tweet'])\n",
    "            augmented_data.append({'tweet': augmented_tweet, 'label': 'negative'})\n",
    "    \n",
    "    # Augment positive class\n",
    "    positive_to_add = target_count - len(data_by_label['positive'])\n",
    "    if positive_to_add > 0:\n",
    "        for _ in range(positive_to_add):\n",
    "            sample = random.choice(data_by_label['positive'])\n",
    "            augmented_tweet = simple_augment_text(sample['tweet'])\n",
    "            augmented_data.append({'tweet': augmented_tweet, 'label': 'positive'})\n",
    "    \n",
    "    # Shuffle the augmented data\n",
    "    random.shuffle(augmented_data)\n",
    "    \n",
    "    # Return the augmented data directly (not as a Dataset object)\n",
    "    return augmented_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    swa, por, sot = load_local_datasets()\n",
    "    \n",
    "    if por is not None:\n",
    "        print(\"Original Portuguese dataset:\")\n",
    "        analyze_sentiment_distribution(por)\n",
    "        \n",
    "        # Balance and augment dataset\n",
    "        augmented_data = balance_and_augment_dataset(por)\n",
    "        \n",
    "        # Create a new dataset from the augmented data\n",
    "        augmented_dataset = Dataset.from_dict({\n",
    "            'tweet': [item['tweet'] for item in augmented_data],\n",
    "            'label': [item['label'] for item in augmented_data]\n",
    "        })\n",
    "        \n",
    "        print(\"\\nAfter balancing and augmentation:\")\n",
    "        analyze_sentiment_distribution(augmented_dataset)  # Now analyzing the dataset directly\n",
    "        \n",
    "        # Create a dataset with splits for saving\n",
    "        full_dataset_with_splits = {\"train\": augmented_dataset}\n",
    "        full_dataset = Dataset.from_dict({\n",
    "            'train': augmented_dataset\n",
    "        })\n",
    "        \n",
    "        # Save the balanced and augmented dataset\n",
    "        full_dataset.save_to_disk(\"./datasets/afrisenti/por_balanced_augmented\")\n",
    "        print(\"\\nBalanced and augmented dataset saved!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcb0dc",
   "metadata": {},
   "source": [
    "These text augmentation techniques (word deletion, word swap, punctuation changes) are more appropriate for Mozambican Portuguese since they don't rely on external translation models that might not understand the dialect. They preserve the unique characteristics of Mozambican Portuguese while still creating useful variations of the original text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70a400",
   "metadata": {},
   "source": [
    "Now let's see if there is any improvement when training the best performing BERT model on the Mozambican Portuguese data which was Afro-XLMR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U transformers datasets peft evaluate plotly sentencepiece --quiet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from datasets import load_dataset\n",
    "# import torch_optimizer as optim\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(language):\n",
    "    try:\n",
    "        aug_por_path = \"./datasets/afrisenti/por_balanced_augmented\"\n",
    "\n",
    "        if language=='por':\n",
    "            chosen_dataset=load_from_disk(aug_por_path)\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        for ds in [chosen_dataset]: # Change to all three later\n",
    "            for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "                if ds[lbl].column_names[0]== \"tweet\":\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "                else:\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "\n",
    "        train_df  = chosen_dataset[\"train\"].to_pandas()\n",
    "        val_df  = chosen_dataset[\"validation\"].to_pandas()\n",
    "        test_df  = chosen_dataset[\"test\"].to_pandas()\n",
    "        logger.info(f\"Data loaded successfully: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test examples\")\n",
    "        return train_df, val_df, test_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Function to create DataLoaders\n",
    "def create_data_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, text_column='text', label_column='label'):\n",
    "    train_dataset = SentimentDataset(\n",
    "        texts=train_df[text_column].tolist(),\n",
    "        labels=train_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        texts=val_df[text_column].tolist(),\n",
    "        labels=val_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        texts=test_df[text_column].tolist(),\n",
    "        labels=test_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Tuple of (loss, accuracy, precision, recall, f1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, class_names):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_afro_xlmr_for_lang(language):\n",
    "    config = {\n",
    "        'model_name': 'Davlan/afro-xlmr-base',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    logger.info(f\"Loading model: {config['model_name']}...\")\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['model_name'])\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=config['num_labels']\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{language}')\n",
    "\n",
    "    # Create data loaders\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column']\n",
    "    )\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=config['warmup_steps'],\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    logger.info(\"Starting training...\")\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        logger.info(f\"Epoch {epoch + 1}/{config['epochs']}\")\n",
    "\n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_loader,optimizer,scheduler, device) # train_epoch(model, train_loader, scheduler, device)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1} results:\")\n",
    "        logger.info(f\"Train Loss: {train_loss:.4f}, Time: {train_time:.2f}s\")\n",
    "        logger.info(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            logger.info(f\"New best model with F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Load best model for testing\n",
    "    if best_model_state:\n",
    "        logger.info(\"Loading best model for testing...\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Test evaluation\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{language}_augmented.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Save model\n",
    "    logger.info(\"Saving model...\")\n",
    "    model_save_path = f'./xmlr_sentiment_model_{language}_augmented'\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    logger.info(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# evaluate_afro_xlmr()\n",
    "langs = ['por']\n",
    "\n",
    "for l in langs:\n",
    "    evaluate_afro_xlmr_for_lang(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e22688a4e23ce",
   "metadata": {},
   "source": [
    "## Next, we evaluate the use of Adapters to perform cross-lingual transfer\n",
    "This section will explore the effect of Adapters on model performance when doing cross-lingual transfer. This evaluation will use the Afroxlmr model, because it had the highest accuracy when analysing the Swahili data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cd40eb40cd09c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T10:05:06.755465Z",
     "start_time": "2025-05-24T09:24:53.790890Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "2025-05-24 11:24:58,280 - INFO - Loading model: ./xmlr_sentiment_model_swa...\n",
      "2025-05-24 11:24:59,952 - INFO - Adding head 'default' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}, 'use_pooler': False, 'bias': True, 'dropout_prob': None}.\n",
      "Some weights of XLMRobertaAdapterModel were not initialized from the model checkpoint at ./xmlr_sentiment_model_swa and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-24 11:25:00,018 - INFO - Successfully loaded as AutoAdapterModel\n",
      "2025-05-24 11:25:00,019 - INFO - Adding adapter 'lang_swa'.\n",
      "2025-05-24 11:25:00,084 - INFO - Added source language adapter: lang_swa\n",
      "2025-05-24 11:25:00,085 - INFO - Adding adapter 'lang_sot'.\n",
      "2025-05-24 11:25:00,149 - INFO - Added target language adapter: lang_sot\n",
      "2025-05-24 11:25:00,150 - INFO - Adding adapter 'sentiment_task'.\n",
      "2025-05-24 11:25:00,169 - INFO - Adding head 'sentiment_task' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'negative': 0, 'neutral': 1, 'positive': 2}, 'use_pooler': False, 'bias': True, 'dropout_prob': None}.\n",
      "2025-05-24 11:25:00,170 - INFO - Loading source data...\n",
      "2025-05-24 11:25:01,903 - INFO - Data loaded successfully: 1810 training, 453 validation, 748 test examples\n",
      "2025-05-24 11:25:01,904 - INFO - Creating data loaders...\n",
      "2025-05-24 11:25:01,906 - INFO - Loading target data...\n",
      "2025-05-24 11:25:07,261 - INFO - Data loaded successfully: 1740 training, 349 validation, 349 test examples\n",
      "2025-05-24 11:25:07,262 - INFO - Creating data loaders...\n",
      "2025-05-24 11:25:07,266 - INFO - Phase 1: Training source language + task adapters...\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\adapters\\composition.py:243: FutureWarning: Passing list objects for adapter activation is deprecated. Please use Stack or Fuse explicitly.\n",
      "  warnings.warn(\n",
      "2025-05-24 11:25:07,267 - WARNING - There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequential cross-lingual training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Source Epoch 1/3: 100%|██████████| 114/114 [06:17<00:00,  3.31s/it, loss=0.468]\n",
      "2025-05-24 11:31:24,699 - INFO - Source Epoch 1: Average Loss = 0.7073\n",
      "2025-05-24 11:31:50,179 - INFO - Source Epoch 1: Validation Accuracy = 0.0172\n",
      "Source Epoch 2/3: 100%|██████████| 114/114 [06:24<00:00,  3.38s/it, loss=0.235]\n",
      "2025-05-24 11:38:15,134 - INFO - Source Epoch 2: Average Loss = 0.6068\n",
      "2025-05-24 11:38:40,638 - INFO - Source Epoch 2: Validation Accuracy = 0.0172\n",
      "Source Epoch 3/3: 100%|██████████| 114/114 [06:26<00:00,  3.39s/it, loss=0.882]\n",
      "2025-05-24 11:45:07,466 - INFO - Source Epoch 3: Average Loss = 0.5808\n",
      "2025-05-24 11:45:33,192 - INFO - Source Epoch 3: Validation Accuracy = 0.0172\n",
      "2025-05-24 11:45:33,194 - INFO - Phase 2: Training target language adapter...\n",
      "Target Epoch 1/3: 100%|██████████| 109/109 [06:00<00:00,  3.31s/it, loss=1.5]  \n",
      "2025-05-24 11:51:33,690 - INFO - Target Epoch 1: Average Loss = 1.3688\n",
      "2025-05-24 11:51:58,532 - INFO - Target Epoch 1: Validation Accuracy = 0.7106\n",
      "Target Epoch 2/3: 100%|██████████| 109/109 [05:56<00:00,  3.27s/it, loss=0.46] \n",
      "2025-05-24 11:57:55,021 - INFO - Target Epoch 2: Average Loss = 0.8729\n",
      "2025-05-24 11:58:19,691 - INFO - Target Epoch 2: Validation Accuracy = 0.7135\n",
      "Target Epoch 3/3: 100%|██████████| 109/109 [05:51<00:00,  3.22s/it, loss=0.62] \n",
      "2025-05-24 12:04:11,213 - INFO - Target Epoch 3: Average Loss = 0.7649\n",
      "2025-05-24 12:04:36,205 - INFO - Target Epoch 3: Validation Accuracy = 0.7135\n",
      "2025-05-24 12:04:36,208 - INFO - Attempting to save model and tokenizer\n",
      "2025-05-24 12:04:36,660 - INFO - Failed to save model and tokenizer\n",
      "2025-05-24 12:04:36,662 - INFO - Evaluating on test set...\n",
      "Evaluating: 100%|██████████| 22/22 [00:28<00:00,  1.31s/it]\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-24 12:05:05,444 - INFO - Test Results:\n",
      "2025-05-24 12:05:05,445 - INFO - Loss: 0.7165\n",
      "2025-05-24 12:05:05,446 - INFO - Accuracy: 0.7364\n",
      "2025-05-24 12:05:05,446 - INFO - Precision: 0.5459\n",
      "2025-05-24 12:05:05,447 - INFO - Recall: 0.7364\n",
      "2025-05-24 12:05:05,448 - INFO - F1 Score: 0.6270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to afroxlmr_results_sot_adapters.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './adapters/lang_swa'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 478\u001B[39m\n\u001B[32m    474\u001B[39m     model.save_adapter(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m./adapters/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtgt_adapter\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m, tgt_adapter)\n\u001B[32m    475\u001B[39m     model.save_adapter(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m./adapters/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask_adapter\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m, task_adapter)\n\u001B[32m--> \u001B[39m\u001B[32m478\u001B[39m \u001B[43mtrain_afro_xlmr_adapter\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mswa\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43msot\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 473\u001B[39m, in \u001B[36mtrain_afro_xlmr_adapter\u001B[39m\u001B[34m(source_language, target_language)\u001B[39m\n\u001B[32m    470\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mResults saved to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    472\u001B[39m \u001B[38;5;66;03m# Save individual adapters\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m473\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_adapter\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m./adapters/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43msrc_adapter\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc_adapter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    474\u001B[39m model.save_adapter(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m./adapters/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtgt_adapter\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m, tgt_adapter)\n\u001B[32m    475\u001B[39m model.save_adapter(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m./adapters/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask_adapter\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m, task_adapter)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\adapters\\model_mixin.py:2338\u001B[39m, in \u001B[36mModelWithHeadsAdaptersMixin.save_adapter\u001B[39m\u001B[34m(self, save_directory, adapter_name, with_head, meta_dict, custom_weights_loaders, use_safetensors)\u001B[39m\n\u001B[32m   2330\u001B[39m         custom_weights_loaders = []\n\u001B[32m   2331\u001B[39m     custom_weights_loaders.append(\n\u001B[32m   2332\u001B[39m         PredictionHeadLoader(\n\u001B[32m   2333\u001B[39m             \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2336\u001B[39m         )\n\u001B[32m   2337\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m2338\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_adapter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2339\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2340\u001B[39m \u001B[43m    \u001B[49m\u001B[43madapter_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2341\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmeta_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmeta_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2342\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcustom_weights_loaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcustom_weights_loaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2343\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2344\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\adapters\\model_mixin.py:1011\u001B[39m, in \u001B[36mModelAdaptersMixin.save_adapter\u001B[39m\u001B[34m(self, save_directory, adapter_name, meta_dict, custom_weights_loaders, use_safetensors, **kwargs)\u001B[39m\n\u001B[32m    998\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    999\u001B[39m \u001B[33;03mSaves an adapter and its configuration file to a directory so that it can be shared or reloaded using\u001B[39;00m\n\u001B[32m   1000\u001B[39m \u001B[33;03m`load_adapter()`.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1008\u001B[39m \u001B[33;03m    ValueError: If the given adapter name is invalid.\u001B[39;00m\n\u001B[32m   1009\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1010\u001B[39m loader = AdapterLoader(\u001B[38;5;28mself\u001B[39m, use_safetensors=use_safetensors)\n\u001B[32m-> \u001B[39m\u001B[32m1011\u001B[39m \u001B[43mloader\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_directory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madapter_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeta_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1012\u001B[39m \u001B[38;5;66;03m# save additional custom weights\u001B[39;00m\n\u001B[32m   1013\u001B[39m \n\u001B[32m   1014\u001B[39m \u001B[38;5;66;03m# save interface in case it is a custom model\u001B[39;00m\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m interface := \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.base_model, \u001B[33m\"\u001B[39m\u001B[33madapter_interface\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\adapters\\loading.py:507\u001B[39m, in \u001B[36mAdapterLoader.save\u001B[39m\u001B[34m(self, save_directory, name, meta_dict)\u001B[39m\n\u001B[32m    498\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    499\u001B[39m \u001B[33;03mSaves an adapter and its configuration file to a directory, so that it can be reloaded using the `load()`\u001B[39;00m\n\u001B[32m    500\u001B[39m \u001B[33;03mmethod.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    504\u001B[39m \u001B[33;03m    task_name (str): the name of the adapter to be saved\u001B[39;00m\n\u001B[32m    505\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    506\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exists(save_directory):\n\u001B[32m--> \u001B[39m\u001B[32m507\u001B[39m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_directory\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    508\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    509\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m isdir(\n\u001B[32m    510\u001B[39m         save_directory\n\u001B[32m    511\u001B[39m     ), \u001B[33m\"\u001B[39m\u001B[33mSaving path should be a directory where adapter and configuration can be saved.\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [WinError 3] The system cannot find the path specified: './adapters/lang_swa'"
     ]
    }
   ],
   "source": [
    "# !pip install -U transformers datasets peft evaluate plotly sentencepiece adapters adapter-transformers --quiet\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "from adapters import AutoAdapterModel,AdapterConfig\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128, lang=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.lang = lang\n",
    "        if self.lang=='sot':\n",
    "            self.label_mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}  # Label conversion\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        if self.lang=='sot':\n",
    "            label = self.label_mapping[self.labels[idx]]\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(language):\n",
    "    try:\n",
    "        if language=='por':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"por\",trust_remote_code=True)\n",
    "        elif language=='swa':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"swa\",trust_remote_code=True)\n",
    "        elif language=='sot':\n",
    "            chosen_dataset=load_dataset(\"hamza-student-123/nlp-assignment-news-data\",'sot')\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        for ds in [chosen_dataset]: # Change to all three later\n",
    "            for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "                if ds[lbl].column_names[0]== \"tweet\":\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "                else:\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "\n",
    "        train_df  = chosen_dataset[\"train\"].to_pandas()\n",
    "        val_df  = chosen_dataset[\"validation\"].to_pandas()\n",
    "        test_df  = chosen_dataset[\"test\"].to_pandas()\n",
    "        logger.info(f\"Data loaded successfully: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test examples\")\n",
    "        return train_df, val_df, test_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def create_data_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, text_column='text', label_column='label', lang=None):\n",
    "    train_dataset = SentimentDataset(\n",
    "        texts=train_df[text_column].tolist(),\n",
    "        labels=train_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        lang=lang\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        texts=val_df[text_column].tolist(),\n",
    "        labels=val_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        lang=lang\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        texts=test_df[text_column].tolist(),\n",
    "        labels=test_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        lang=lang\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "def setup_crosslingual_adapters(config, source_language, target_language):\n",
    "\n",
    "    logger.info(f\"Loading model: {config['model_name']}...\")\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['extern_model_name'])\n",
    "    model = AutoAdapterModel.from_pretrained(config['model_name'], num_labels=config['num_labels'])\n",
    "    logger.info(\"Successfully loaded as AutoAdapterModel\")\n",
    "\n",
    "    lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "\n",
    "    source_adapter_name = f\"lang_{source_language}\"\n",
    "    model.add_adapter(source_adapter_name, config=lang_adapter_config)\n",
    "    logger.info(f\"Added source language adapter: {source_adapter_name}\")\n",
    "\n",
    "    target_adapter_name = f\"lang_{target_language}\"\n",
    "    model.add_adapter(target_adapter_name, config=lang_adapter_config)\n",
    "    logger.info(f\"Added target language adapter: {target_adapter_name}\")\n",
    "\n",
    "    task_adapter_name = \"sentiment_task\"\n",
    "    task_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=16)\n",
    "    model.add_adapter(task_adapter_name, config=task_adapter_config)\n",
    "\n",
    "    model.add_classification_head(\n",
    "        task_adapter_name,\n",
    "        num_labels=config['num_labels'],\n",
    "        id2label={i: label for i, label in enumerate(config['class_names'])}\n",
    "    )\n",
    "\n",
    "    return model, tokenizer, source_adapter_name, target_adapter_name, task_adapter_name\n",
    "\n",
    "def setup_madx_adapter(config, source_language, target_language):\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['extern_model_name'])\n",
    "    model = AutoAdapterModel.from_pretrained(config['model_name'], num_labels=config['num_labels'])\n",
    "\n",
    "    # I chose to use a MAD-X style configuration (using standard AdapterConfig)\n",
    "    # reason being, it typically uses smaller reduction factors for language adapters\n",
    "    lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "    task_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=16)\n",
    "\n",
    "    model.add_adapter(f\"lang_{source_language}\", config=lang_adapter_config)\n",
    "    model.add_adapter(f\"lang_{target_language}\", config=lang_adapter_config)\n",
    "\n",
    "    model.add_adapter(\"sentiment\", config=task_adapter_config)\n",
    "    model.add_classification_head(\"sentiment\", num_labels=config['num_labels'])\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def train_cross_lingual_transfer(model, source_train_loader, target_train_loader,\n",
    "                               val_loader, config, source_adapter, target_adapter, task_adapter):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    logger.info(\"Phase 1: Training source language + task adapters...\")\n",
    "\n",
    "    model.set_active_adapters([source_adapter, task_adapter])\n",
    "    model.train_adapter([source_adapter, task_adapter])\n",
    "\n",
    "    trainable_params = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params.append(param)\n",
    "\n",
    "    optimizer_source = torch.optim.AdamW(trainable_params, lr=config['learning_rate'])\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        progress_bar = tqdm(source_train_loader, desc=f\"Source Epoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer_source.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(trainable_params, config['max_grad_norm'])\n",
    "            optimizer_source.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        avg_loss = total_loss / len(source_train_loader)\n",
    "        logger.info(f\"Source Epoch {epoch+1}: Average Loss = {avg_loss:.4f}\")\n",
    "\n",
    "        val_accuracy = validate_model(model, val_loader, device)\n",
    "        logger.info(f\"Source Epoch {epoch+1}: Validation Accuracy = {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    logger.info(\"Phase 2: Training target language adapter...\")\n",
    "\n",
    "\n",
    "    model.set_active_adapters([target_adapter, task_adapter])\n",
    "    model.train_adapter([target_adapter])\n",
    "\n",
    "    target_params = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and target_adapter in name:\n",
    "            target_params.append(param)\n",
    "\n",
    "\n",
    "    optimizer_target = torch.optim.AdamW(target_params, lr=config['learning_rate'] * 0.1)\n",
    "\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        progress_bar = tqdm(target_train_loader, desc=f\"Target Epoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer_target.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(target_params, config['max_grad_norm'])\n",
    "            optimizer_target.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        avg_loss = total_loss / len(target_train_loader)\n",
    "        logger.info(f\"Target Epoch {epoch+1}: Average Loss = {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation on target language\n",
    "        val_accuracy = validate_model(model, val_loader, device)\n",
    "        logger.info(f\"Target Epoch {epoch+1}: Validation Accuracy = {val_accuracy:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predicted = torch.max(outputs.logits.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def load_pretrained_lang_adapters(model, source_language, target_language):\n",
    "    try:\n",
    "        model.load_adapter(f\"lang/{source_language}\", source=\"hf\", load_as=f\"lang_{source_language}\")\n",
    "        logger.info(f\"Loaded pretrained {source_language} adapter\")\n",
    "    except:\n",
    "        logger.warning(f\"No pretrained adapter found for {source_language}, using random initialization\")\n",
    "\n",
    "    try:\n",
    "        model.load_adapter(f\"lang/{target_language}\", source=\"hf\", load_as=f\"lang_{target_language}\")\n",
    "        logger.info(f\"Loaded pretrained {target_language} adapter\")\n",
    "    except:\n",
    "        logger.warning(f\"No pretrained adapter found for {target_language}, using random initialization\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_afro_xlmr_adapter(source_language, target_language='sot'):\n",
    "    config = {\n",
    "        'extern_model_name': f'Davlan/afro-xlmr-base',\n",
    "        'model_name': f'./xmlr_sentiment_model_{source_language}',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    model, tokenizer, src_adapter, tgt_adapter, task_adapter = setup_crosslingual_adapters(\n",
    "    config, source_language, target_language)\n",
    "\n",
    "    logger.info(\"Loading source data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{source_language}')\n",
    "\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    source_train_loader, source_val_loader, source_test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column'],\n",
    "        lang=source_language\n",
    "    )\n",
    "\n",
    "    logger.info(\"Loading target data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{target_language}')\n",
    "\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    target_train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column'],\n",
    "        lang=target_language\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Starting sequential cross-lingual training...\")\n",
    "    model = train_cross_lingual_transfer(\n",
    "        model, source_train_loader, target_train_loader, val_loader,\n",
    "        config, src_adapter, tgt_adapter, task_adapter\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        logger.info(\"Attempting to save model and tokenizer\")\n",
    "        model.save_pretrained(f\"./cross_lingual_model_{source_language}_{target_language}\")\n",
    "        tokenizer.save_pretrained(f\"./cross_lingual_model_{source_language}_{target_language}\")\n",
    "    except:\n",
    "        logger.info(\"Failed to save model and tokenizer\")\n",
    "\n",
    "    # Test evaluation: Showing results after training and adapters\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{target_language}_adapters.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Saving the adapters\n",
    "    model.save_adapter(f\"./adapters/{src_adapter}\", src_adapter)\n",
    "    model.save_adapter(f\"./adapters/{tgt_adapter}\", tgt_adapter)\n",
    "    model.save_adapter(f\"./adapters/{task_adapter}\", task_adapter)\n",
    "\n",
    "\n",
    "train_afro_xlmr_adapter('swa','sot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8590b126ea01cb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:17:17.032929Z",
     "start_time": "2025-05-24T08:16:49.399333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 10:16:50,951 - INFO - Adding head 'default' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}, 'use_pooler': False, 'bias': True, 'dropout_prob': None}.\n",
      "2025-05-24 10:16:50,953 - INFO - Adding head 'sentiment_task' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'negative': 0, 'neutral': 1, 'positive': 2}, 'use_pooler': False, 'bias': True, 'dropout_prob': None}.\n",
      "2025-05-24 10:16:51,088 - INFO - Successfully loaded as AutoAdapterModel\n",
      "2025-05-24 10:16:51,088 - INFO - Loading target data...\n",
      "2025-05-24 10:16:55,320 - INFO - Data loaded successfully: 1740 training, 349 validation, 349 test examples\n",
      "2025-05-24 10:16:55,321 - INFO - Creating data loaders...\n",
      "2025-05-24 10:16:55,322 - INFO - Evaluating on test set...\n",
      "Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]2025-05-24 10:16:55,329 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:   5%|▍         | 1/22 [00:01<00:21,  1.04s/it]2025-05-24 10:16:56,373 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:   9%|▉         | 2/22 [00:02<00:20,  1.02s/it]2025-05-24 10:16:57,385 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  14%|█▎        | 3/22 [00:03<00:19,  1.01s/it]2025-05-24 10:16:58,383 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  18%|█▊        | 4/22 [00:04<00:18,  1.01s/it]2025-05-24 10:16:59,399 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  23%|██▎       | 5/22 [00:05<00:17,  1.01s/it]2025-05-24 10:17:00,392 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  27%|██▋       | 6/22 [00:06<00:16,  1.00s/it]2025-05-24 10:17:01,391 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  32%|███▏      | 7/22 [00:07<00:15,  1.01s/it]2025-05-24 10:17:02,404 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  36%|███▋      | 8/22 [00:08<00:14,  1.00s/it]2025-05-24 10:17:03,398 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  41%|████      | 9/22 [00:09<00:13,  1.00s/it]2025-05-24 10:17:04,404 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  45%|████▌     | 10/22 [00:10<00:11,  1.00it/s]2025-05-24 10:17:05,382 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  50%|█████     | 11/22 [00:11<00:10,  1.01it/s]2025-05-24 10:17:06,372 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  55%|█████▍    | 12/22 [00:12<00:09,  1.01it/s]2025-05-24 10:17:07,348 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  59%|█████▉    | 13/22 [00:13<00:08,  1.01it/s]2025-05-24 10:17:08,334 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  64%|██████▎   | 14/22 [00:14<00:07,  1.01it/s]2025-05-24 10:17:09,330 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  68%|██████▊   | 15/22 [00:14<00:06,  1.01it/s]2025-05-24 10:17:10,306 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  73%|███████▎  | 16/22 [00:15<00:05,  1.01it/s]2025-05-24 10:17:11,296 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  77%|███████▋  | 17/22 [00:16<00:04,  1.01it/s]2025-05-24 10:17:12,292 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  82%|████████▏ | 18/22 [00:17<00:03,  1.01it/s]2025-05-24 10:17:13,283 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  86%|████████▋ | 19/22 [00:18<00:02,  1.01it/s]2025-05-24 10:17:14,263 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  91%|█████████ | 20/22 [00:19<00:01,  1.02it/s]2025-05-24 10:17:15,220 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  95%|█████████▌| 21/22 [00:20<00:00,  1.03it/s]2025-05-24 10:17:16,184 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating: 100%|██████████| 22/22 [00:21<00:00,  1.02it/s]\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-24 10:17:16,995 - INFO - Test Results:\n",
      "2025-05-24 10:17:16,995 - INFO - Loss: 1.8235\n",
      "2025-05-24 10:17:16,996 - INFO - Accuracy: 0.0544\n",
      "2025-05-24 10:17:16,997 - INFO - Precision: 0.0030\n",
      "2025-05-24 10:17:16,997 - INFO - Recall: 0.0544\n",
      "2025-05-24 10:17:16,998 - INFO - F1 Score: 0.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to afroxlmr_results_sot_adapters.csv\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "\n",
    "def evaluate_afro_xlmr_adapter(source_language,target_language):\n",
    "    config = {\n",
    "        'extern_model_name': f'Davlan/afro-xlmr-base',\n",
    "        'model_name': f'./xmlr_sentiment_model_{source_language}',\n",
    "        'adapter_model_name': f'./cross_lingual_model_{source_language}_{target_language}',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['extern_model_name'])\n",
    "\n",
    "    try:\n",
    "        model = AutoAdapterModel.from_pretrained(config['adapter_model_name'], num_labels=config['num_labels'])\n",
    "        logger.info(\"Successfully loaded as AutoAdapterModel\")\n",
    "    except:\n",
    "        exit(9)\n",
    "\n",
    "    logger.info(\"Loading target data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{target_language}')\n",
    "\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    target_train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column'],\n",
    "        lang=target_language\n",
    "    )\n",
    "    # Test evaluation: Showing results after training and adapters\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{target_language}_adapters.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Saving the individual adapters\n",
    "    # model.save_adapter(f\"./adapters/{src_adapter}\", src_adapter)\n",
    "    # model.save_adapter(f\"./adapters/{tgt_adapter}\", tgt_adapter)\n",
    "    # model.save_adapter(f\"./adapters/{task_adapter}\", task_adapter)\n",
    "\n",
    "evaluate_afro_xlmr_adapter('swa','sot')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
