{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86a8f0e",
   "metadata": {},
   "source": [
    "# COS 760 Research Project: Analysing Sentiments for Low-resource African Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a3c357-1a7b-4731-bfb1-c3db6af9d407",
   "metadata": {
    "id": "b3a3c357-1a7b-4731-bfb1-c3db6af9d407"
   },
   "source": [
    "## Group Members: Mihir Arjun, Troy Clark, Hamza Mokiwa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566879365751e0a2",
   "metadata": {
    "id": "566879365751e0a2"
   },
   "source": [
    "### Establishing Baselines with Monolingual Long Short-Term Memory networks(LSTMs) and pre-trained Multilingual transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d058d144-ec71-42a2-ba89-92e7d9062a0d",
   "metadata": {
    "id": "d058d144-ec71-42a2-ba89-92e7d9062a0d"
   },
   "source": [
    "#### First we need to install the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "054dd69e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T14:09:51.019371Z",
     "start_time": "2025-04-30T14:09:49.433052Z"
    },
    "id": "054dd69e",
    "outputId": "9881dfc4-84c9-4e9a-e130-9b364095b515"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Mihir - University\\2025\\COS 760\\Project\\nlp-research\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Swahili (swa) dataset from disk...\n",
      "Swahili dataset loaded!\n",
      "Loading Portuguese (por) dataset from disk...\n",
      "Portuguese dataset loaded!\n",
      "Loading Sesotho (sot) dataset from disk...\n",
      "Sesotho dataset loaded!\n",
      "Swahili dataset size: 1810 examples\n",
      "Portuguese dataset size: 3063 examples\n",
      "Sesotho dataset size: 2177 examples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "def load_local_datasets():\n",
    "    swa_path = \"./datasets/afrisenti/swa\"\n",
    "    por_path = \"./datasets/afrisenti/por\"\n",
    "    sot_path = \"./datasets/news\"\n",
    "\n",
    "    if not all(os.path.exists(path) for path in [swa_path, por_path,sot_path]):\n",
    "        print(\"One or more dataset directories not found. Please check the paths.\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(\"Loading Swahili (swa) dataset from disk...\")\n",
    "    swa_dataset = load_from_disk(swa_path)\n",
    "    print(\"Swahili dataset loaded!\")\n",
    "\n",
    "    print(\"Loading Portuguese (por) dataset from disk...\")\n",
    "    por_dataset = load_from_disk(por_path)\n",
    "    print(\"Portuguese dataset loaded!\")\n",
    "\n",
    "    print(\"Loading Sesotho (sot) dataset from disk...\")\n",
    "    sot_dataset = load_dataset(\"csv\",  data_files=\"datasets/sotho-news/sotho_news_dataset.csv\")\n",
    "    print(\"Sesotho dataset loaded!\")\n",
    "\n",
    "    return swa_dataset, por_dataset, sot_dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    swa, por, sot = load_local_datasets()\n",
    "\n",
    "    if swa is not None:\n",
    "        print(f\"Swahili dataset size: {len(swa['train'])} examples\")\n",
    "    if por is not None:\n",
    "        print(f\"Portuguese dataset size: {len(por['train'])} examples\")\n",
    "    if sot is not None:\n",
    "        print(f\"Sesotho dataset size: {len(sot['train'])} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9822d",
   "metadata": {
    "id": "0bf9822d"
   },
   "source": [
    "## Now that the datasets have been loaded, we can start creating our LSTM baseline models below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2a9bc",
   "metadata": {
    "id": "7cc2a9bc"
   },
   "source": [
    "### First we will build an LSTM model for Swahili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28f49b",
   "metadata": {
    "id": "3d28f49b",
    "outputId": "ccf43988-a21b-45df-cbf1-d8297d13f708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Swahili dataset loaded successfully!\n",
      "Available columns in train split: ['tweet', 'label']\n",
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 1810\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 453\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 748\n",
      "    })\n",
      "})\n",
      "Train set size: 1810\n",
      "Test set size: 748\n",
      "Validation set size: 453\n",
      "Label mapping: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "Vocabulary size: 3055\n",
      "Model architecture:\n",
      "LSTMSentiment(\n",
      "  (embedding): Embedding(3055, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.55it/s]\n",
      "Epoch 1/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 36.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 0.9255\n",
      "  Val Loss: 0.8964, Val Accuracy: 0.5872, Val F1: 0.4377\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.84it/s]\n",
      "Epoch 2/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 42.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 0.8834\n",
      "  Val Loss: 0.9085, Val Accuracy: 0.5872, Val F1: 0.4720\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.59it/s]\n",
      "Epoch 3/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 32.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 0.8355\n",
      "  Val Loss: 0.9070, Val Accuracy: 0.5960, Val F1: 0.5168\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.93it/s]\n",
      "Epoch 4/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 32.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 0.7643\n",
      "  Val Loss: 0.9697, Val Accuracy: 0.5762, Val F1: 0.4923\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.20it/s]\n",
      "Epoch 5/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 0.6388\n",
      "  Val Loss: 1.0302, Val Accuracy: 0.5497, Val F1: 0.5318\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.23it/s]\n",
      "Epoch 6/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 0.5488\n",
      "  Val Loss: 1.2454, Val Accuracy: 0.5055, Val F1: 0.5120\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.92it/s]\n",
      "Epoch 7/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 28.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 0.4460\n",
      "  Val Loss: 1.2486, Val Accuracy: 0.5585, Val F1: 0.5315\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.64it/s]\n",
      "Epoch 8/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 26.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 0.3874\n",
      "  Val Loss: 1.5211, Val Accuracy: 0.4857, Val F1: 0.4953\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|██████████| 57/57 [00:07<00:00,  7.96it/s]\n",
      "Epoch 9/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 32.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 0.2739\n",
      "  Val Loss: 1.5772, Val Accuracy: 0.5055, Val F1: 0.5088\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|██████████| 57/57 [00:06<00:00,  8.60it/s]\n",
      "Epoch 10/10 - Validation: 100%|██████████| 15/15 [00:00<00:00, 35.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 0.2220\n",
      "  Val Loss: 1.5910, Val Accuracy: 0.5541, Val F1: 0.5337\n",
      "------------------------------------------------------------\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:00<00:00, 27.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8965\n",
      "Test Accuracy: 0.5936\n",
      "Test F1 Score: 0.4446\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        80\n",
      "     neutral       0.59      1.00      0.74       444\n",
      "    positive       0.50      0.00      0.01       224\n",
      "\n",
      "    accuracy                           0.59       748\n",
      "   macro avg       0.36      0.33      0.25       748\n",
      "weighted avg       0.50      0.59      0.44       748\n",
      "\n",
      "Results saved to swahili_lstm_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Mihir - University\\2025\\COS 760\\Project\\nlp-research\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Mihir - University\\2025\\COS 760\\Project\\nlp-research\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Mihir - University\\2025\\COS 760\\Project\\nlp-research\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "class SwahiliSentimentDataset(Dataset):\n",
    "    def __init__(self, tweets, labels, vocab, label_map):\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.tweets[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "\n",
    "        tokenized = [self.vocab.get(word, self.vocab['<UNK>']) for word in tweet.split()]\n",
    "        return torch.tensor(tokenized, dtype=torch.long), torch.tensor(self.label_map[label], dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tweets, labels = zip(*batch)\n",
    "\n",
    "    tweets_padded = pad_sequence(tweets, batch_first=True, padding_value=0)\n",
    "    return tweets_padded, torch.stack(labels)\n",
    "\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "                           bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "\n",
    "\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for tweets, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            outputs = model(tweets)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for tweets, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
    "                tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(tweets)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_swahili_lstm_model.pt\")\n",
    "            print(\"  Saved new best model!\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, label_list):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tweets, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(tweets)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "    class_names = [label_list[i] for i in range(len(label_list))]\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return test_loss, test_accuracy, test_f1\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        swa_dataset = load_from_disk(\"./datasets/afrisenti/swa\")\n",
    "        print(\"Swahili dataset loaded successfully!\")\n",
    "\n",
    "        print(f\"Available columns in train split: {swa_dataset['train'].column_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Dataset structure: {swa_dataset}\")\n",
    "    print(f\"Train set size: {len(swa_dataset['train'])}\")\n",
    "    print(f\"Test set size: {len(swa_dataset['test'])}\")\n",
    "    print(f\"Validation set size: {len(swa_dataset['validation'])}\")\n",
    "\n",
    "    train_tweets = swa_dataset['train']['tweet']\n",
    "    train_labels = swa_dataset['train']['label']\n",
    "    val_tweets = swa_dataset['validation']['tweet']\n",
    "    val_labels = swa_dataset['validation']['label']\n",
    "    test_tweets = swa_dataset['test']['tweet']\n",
    "    test_labels = swa_dataset['test']['label']\n",
    "\n",
    "    unique_labels = set(train_labels + val_labels + test_labels)\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "    print(f\"Label mapping: {label_to_idx}\")\n",
    "\n",
    "    word_counts = Counter()\n",
    "    for tweet in train_tweets:\n",
    "        word_counts.update(tweet.split())\n",
    "\n",
    "    min_freq = 2\n",
    "    vocabulary = {'<PAD>': 0, '<UNK>': 1}\n",
    "    vocab_idx = 2\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocabulary[word] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "\n",
    "    print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "    train_dataset = SwahiliSentimentDataset(train_tweets, train_labels, vocabulary, label_to_idx)\n",
    "    val_dataset = SwahiliSentimentDataset(val_tweets, val_labels, vocabulary, label_to_idx)\n",
    "    test_dataset = SwahiliSentimentDataset(test_tweets, test_labels, vocabulary, label_to_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    model = LSTMSentiment(\n",
    "        vocab_size=len(vocabulary),\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=len(unique_labels),\n",
    "        n_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=vocabulary['<PAD>']\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"Model architecture:\\n{model}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_swahili_lstm_model.pt\"))\n",
    "\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_f1 = evaluate_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        label_list=list(idx_to_label.values())\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"num_layers\": NUM_LAYERS,\n",
    "        \"dropout\": DROPOUT,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"vocab_size\": len(vocabulary)\n",
    "    }\n",
    "\n",
    "\n",
    "    pd.DataFrame([results]).to_csv(\"swahili_lstm_results.csv\", index=False)\n",
    "    print(f\"Results saved to swahili_lstm_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e693c96",
   "metadata": {
    "id": "5e693c96"
   },
   "source": [
    "### Next, we build an LSTM model for Mozambican Portuguese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e04f9",
   "metadata": {
    "id": "d62e04f9",
    "outputId": "bdcd025b-048b-42a1-acf7-7381b7015aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Mozambican Portuguese dataset loaded successfully!\n",
      "Available columns in train split: ['tweet', 'label']\n",
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 3063\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 767\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 3662\n",
      "    })\n",
      "})\n",
      "Train set size: 3063\n",
      "Test set size: 3662\n",
      "Validation set size: 767\n",
      "Label mapping: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "Vocabulary size: 4075\n",
      "Model architecture:\n",
      "LSTMSentiment(\n",
      "  (embedding): Embedding(4075, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 96/96 [00:12<00:00,  7.80it/s]\n",
      "Epoch 1/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 19.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 1.0226\n",
      "  Val Loss: 0.9994, Val Accuracy: 0.5215, Val F1: 0.3575\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|██████████| 96/96 [00:15<00:00,  6.37it/s]\n",
      "Epoch 2/10 - Validation: 100%|██████████| 24/24 [00:00<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 0.9703\n",
      "  Val Loss: 0.9651, Val Accuracy: 0.5450, Val F1: 0.4652\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  6.98it/s]\n",
      "Epoch 3/10 - Validation: 100%|██████████| 24/24 [00:00<00:00, 24.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 0.8965\n",
      "  Val Loss: 0.9932, Val Accuracy: 0.5567, Val F1: 0.4923\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  6.95it/s]\n",
      "Epoch 4/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 20.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 0.7983\n",
      "  Val Loss: 0.9902, Val Accuracy: 0.5606, Val F1: 0.5459\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|██████████| 96/96 [00:14<00:00,  6.67it/s]\n",
      "Epoch 5/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 0.6935\n",
      "  Val Loss: 1.0411, Val Accuracy: 0.5528, Val F1: 0.5396\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  6.92it/s]\n",
      "Epoch 6/10 - Validation: 100%|██████████| 24/24 [00:00<00:00, 25.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 0.5816\n",
      "  Val Loss: 1.1400, Val Accuracy: 0.5424, Val F1: 0.5358\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  7.09it/s]\n",
      "Epoch 7/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 21.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 0.4691\n",
      "  Val Loss: 1.2334, Val Accuracy: 0.5593, Val F1: 0.5388\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|██████████| 96/96 [00:14<00:00,  6.71it/s]\n",
      "Epoch 8/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 0.3591\n",
      "  Val Loss: 1.4979, Val Accuracy: 0.5332, Val F1: 0.5243\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  7.02it/s]\n",
      "Epoch 9/10 - Validation: 100%|██████████| 24/24 [00:00<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 0.3022\n",
      "  Val Loss: 1.4727, Val Accuracy: 0.5111, Val F1: 0.5080\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|██████████| 96/96 [00:13<00:00,  6.88it/s]\n",
      "Epoch 10/10 - Validation: 100%|██████████| 24/24 [00:01<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 0.2282\n",
      "  Val Loss: 1.6321, Val Accuracy: 0.5332, Val F1: 0.5234\n",
      "------------------------------------------------------------\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 115/115 [00:04<00:00, 25.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8757\n",
      "Test Accuracy: 0.6393\n",
      "Test F1 Score: 0.5655\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.15      0.21       655\n",
      "     neutral       0.67      0.92      0.78      2379\n",
      "    positive       0.62      0.08      0.14       628\n",
      "\n",
      "    accuracy                           0.64      3662\n",
      "   macro avg       0.54      0.38      0.37      3662\n",
      "weighted avg       0.60      0.64      0.57      3662\n",
      "\n",
      "Results saved to portuguese_lstm_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "class PorSentimentDataset(Dataset):\n",
    "    def __init__(self, tweets, labels, vocab, label_map):\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.tweets[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        tokenized = [self.vocab.get(word, self.vocab['<UNK>']) for word in tweet.split()]\n",
    "        return torch.tensor(tokenized, dtype=torch.long), torch.tensor(self.label_map[label], dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tweets, labels = zip(*batch)\n",
    "    tweets_padded = pad_sequence(tweets, batch_first=True, padding_value=0)\n",
    "    return tweets_padded, torch.stack(labels)\n",
    "\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "                           bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for tweets, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(tweets)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for tweets, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
    "                tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(tweets)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_portuguese_lstm_model.pt\")\n",
    "            print(\"  Saved new best model!\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, label_list):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tweets, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            tweets, labels = tweets.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(tweets)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    class_names = [label_list[i] for i in range(len(label_list))]\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return test_loss, test_accuracy, test_f1\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    try:\n",
    "        por_dataset = load_from_disk(\"./datasets/afrisenti/por\")\n",
    "        print(\"Mozambican Portuguese dataset loaded successfully!\")\n",
    "\n",
    "        print(f\"Available columns in train split: {por_dataset['train'].column_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Dataset structure: {por_dataset}\")\n",
    "    print(f\"Train set size: {len(por_dataset['train'])}\")\n",
    "    print(f\"Test set size: {len(por_dataset['test'])}\")\n",
    "    print(f\"Validation set size: {len(por_dataset['validation'])}\")\n",
    "\n",
    "    train_tweets = por_dataset['train']['tweet']\n",
    "    train_labels = por_dataset['train']['label']\n",
    "    val_tweets = por_dataset['validation']['tweet']\n",
    "    val_labels = por_dataset['validation']['label']\n",
    "    test_tweets = por_dataset['test']['tweet']\n",
    "    test_labels = por_dataset['test']['label']\n",
    "\n",
    "    unique_labels = set(train_labels + val_labels + test_labels)\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "    print(f\"Label mapping: {label_to_idx}\")\n",
    "\n",
    "    word_counts = Counter()\n",
    "    for tweet in train_tweets:\n",
    "        word_counts.update(tweet.split())\n",
    "\n",
    "    min_freq = 2\n",
    "    vocabulary = {'<PAD>': 0, '<UNK>': 1}\n",
    "    vocab_idx = 2\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocabulary[word] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "\n",
    "    print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "    train_dataset = PorSentimentDataset(train_tweets, train_labels, vocabulary, label_to_idx)\n",
    "    val_dataset = PorSentimentDataset(val_tweets, val_labels, vocabulary, label_to_idx)\n",
    "    test_dataset = PorSentimentDataset(test_tweets, test_labels, vocabulary, label_to_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    model = LSTMSentiment(\n",
    "        vocab_size=len(vocabulary),\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=len(unique_labels),\n",
    "        n_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=vocabulary['<PAD>']\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"Model architecture:\\n{model}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_portuguese_lstm_model.pt\"))\n",
    "\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_f1 = evaluate_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        label_list=list(idx_to_label.values())\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"num_layers\": NUM_LAYERS,\n",
    "        \"dropout\": DROPOUT,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"vocab_size\": len(vocabulary)\n",
    "    }\n",
    "\n",
    "\n",
    "    pd.DataFrame([results]).to_csv(\"portuguese_lstm_results.csv\", index=False)\n",
    "    print(f\"Results saved to portuguese_lstm_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b24b1c44eb59b2",
   "metadata": {
    "id": "23b24b1c44eb59b2"
   },
   "source": [
    "### Lastly, we build an LSTM model for Sesotho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed05fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:44:06.391800Z",
     "start_time": "2025-05-03T07:43:58.107727Z"
    },
    "id": "0ed05fc8",
    "outputId": "895e8856-7a7a-4670-fb05-5811f6f236fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Sesotho dataset loaded successfully!\n",
      "Available columns in train split: ['headline', 'label', '__index_level_0__']\n",
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['headline', 'label', '__index_level_0__'],\n",
      "        num_rows: 1305\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['headline', 'label', '__index_level_0__'],\n",
      "        num_rows: 436\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['headline', 'label', '__index_level_0__'],\n",
      "        num_rows: 436\n",
      "    })\n",
      "})\n",
      "Train set size: 1305\n",
      "Test set size: 436\n",
      "Validation set size: 436\n",
      "Label mapping: {'neutral': 0, 'negative': 1, 'positive': 2}\n",
      "Vocabulary size: 876\n",
      "Model architecture:\n",
      "LSTMSentiment(\n",
      "  (embedding): Embedding(876, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 50.00it/s]\n",
      "Epoch 1/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 212.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 0.7751\n",
      "  Val Loss: 0.7289, Val Accuracy: 0.6950, Val F1: 0.5699\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 51.51it/s]\n",
      "Epoch 2/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 202.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 0.6275\n",
      "  Val Loss: 0.7368, Val Accuracy: 0.7179, Val F1: 0.6419\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 52.90it/s]\n",
      "Epoch 3/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 215.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 0.5516\n",
      "  Val Loss: 0.7012, Val Accuracy: 0.7317, Val F1: 0.6920\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 56.79it/s]\n",
      "Epoch 4/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 200.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 0.5039\n",
      "  Val Loss: 0.7370, Val Accuracy: 0.7385, Val F1: 0.6711\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 57.91it/s]\n",
      "Epoch 5/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 212.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 0.4261\n",
      "  Val Loss: 0.7007, Val Accuracy: 0.7271, Val F1: 0.7154\n",
      "  Saved new best model!\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 55.86it/s]\n",
      "Epoch 6/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 215.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 0.3852\n",
      "  Val Loss: 0.7299, Val Accuracy: 0.7638, Val F1: 0.7379\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 59.33it/s]\n",
      "Epoch 7/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 218.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 0.2882\n",
      "  Val Loss: 0.7523, Val Accuracy: 0.7454, Val F1: 0.7287\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 58.32it/s]\n",
      "Epoch 8/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 218.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 0.2573\n",
      "  Val Loss: 0.7572, Val Accuracy: 0.7156, Val F1: 0.7123\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 57.66it/s]\n",
      "Epoch 9/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 199.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 0.1974\n",
      "  Val Loss: 0.8882, Val Accuracy: 0.7271, Val F1: 0.7143\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|██████████| 41/41 [00:00<00:00, 53.81it/s]\n",
      "Epoch 10/10 - Validation: 100%|██████████| 14/14 [00:00<00:00, 222.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 0.1676\n",
      "  Val Loss: 0.9858, Val Accuracy: 0.7385, Val F1: 0.7134\n",
      "------------------------------------------------------------\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 14/14 [00:00<00:00, 237.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9303\n",
      "Test Accuracy: 0.7202\n",
      "Test F1 Score: 0.7024\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.83      0.25      0.38        20\n",
      "    negative       0.77      0.87      0.82       308\n",
      "    positive       0.49      0.38      0.43       108\n",
      "\n",
      "    accuracy                           0.72       436\n",
      "   macro avg       0.70      0.50      0.54       436\n",
      "weighted avg       0.71      0.72      0.70       436\n",
      "\n",
      "Results saved to sesotho_lstm_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "class SotSentimentDataset(Dataset):\n",
    "    def __init__(self, headlines, labels, vocab, label_map):\n",
    "        self.headlines = headlines\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.headlines[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "\n",
    "        tokenized = [self.vocab.get(word, self.vocab['<UNK>']) for word in tweet.split()]\n",
    "        return torch.tensor(tokenized, dtype=torch.long), torch.tensor(self.label_map[label], dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    headlines, labels = zip(*batch)\n",
    "\n",
    "    headlines_padded = pad_sequence(headlines, batch_first=True, padding_value=0)\n",
    "    return headlines_padded, torch.stack(labels)\n",
    "\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "                           bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "\n",
    "\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for headlines, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            headlines, labels = headlines.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            outputs = model(headlines)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for headlines, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
    "                headlines, labels = headlines.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(headlines)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_portuguese_lstm_model.pt\")\n",
    "            print(\"  Saved new best model!\")\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, label_list):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for headlines, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            headlines, labels = headlines.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(headlines)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "    class_names = [label_list[i] for i in range(len(label_list))]\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return test_loss, test_accuracy, test_f1\n",
    "\n",
    "def main():\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        sot_dataset = load_from_disk(\"./datasets/sesotho_news_dataset\")\n",
    "        print(\"Sesotho dataset loaded successfully!\")\n",
    "\n",
    "\n",
    "        print(f\"Available columns in train split: {sot_dataset['train'].column_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    print(f\"Dataset structure: {sot_dataset}\")\n",
    "    print(f\"Train set size: {len(sot_dataset['train'])}\")\n",
    "    print(f\"Test set size: {len(sot_dataset['test'])}\")\n",
    "    print(f\"Validation set size: {len(sot_dataset['validation'])}\")\n",
    "\n",
    "\n",
    "    train_headlines = sot_dataset['train']['headline']\n",
    "    train_labels = sot_dataset['train']['label']\n",
    "    val_headlines = sot_dataset['validation']['headline']\n",
    "    val_labels = sot_dataset['validation']['label']\n",
    "    test_headlines = sot_dataset['test']['headline']\n",
    "    test_labels = sot_dataset['test']['label']\n",
    "\n",
    "\n",
    "\n",
    "    unique_labels = set(train_labels + val_labels + test_labels)\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "    print(f\"Label mapping: {label_to_idx}\")\n",
    "\n",
    "\n",
    "    word_counts = Counter()\n",
    "    for headline in train_headlines:\n",
    "        word_counts.update(headline.split())\n",
    "\n",
    "\n",
    "    min_freq = 2\n",
    "    vocabulary = {'<PAD>': 0, '<UNK>': 1}\n",
    "    vocab_idx = 2\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocabulary[word] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "\n",
    "    print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "\n",
    "    train_dataset = SotSentimentDataset(train_headlines, train_labels, vocabulary, label_to_idx)\n",
    "    val_dataset = SotSentimentDataset(val_headlines, val_labels, vocabulary, label_to_idx)\n",
    "    test_dataset = SotSentimentDataset(test_headlines, test_labels, vocabulary, label_to_idx)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "    model = LSTMSentiment(\n",
    "        vocab_size=len(vocabulary),\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=len(unique_labels),\n",
    "        n_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=vocabulary['<PAD>']\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "    print(f\"Model architecture:\\n{model}\")\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), \"best_sesotho_lstm_model.pt\");\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_sesotho_lstm_model.pt\"))\n",
    "\n",
    "\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_f1 = evaluate_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        label_list=list(idx_to_label.values())\n",
    "    )\n",
    "\n",
    "\n",
    "    results = {\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"num_layers\": NUM_LAYERS,\n",
    "        \"dropout\": DROPOUT,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"vocab_size\": len(vocabulary)\n",
    "    }\n",
    "\n",
    "\n",
    "    pd.DataFrame([results]).to_csv(\"sesotho_lstm_results.csv\", index=False)\n",
    "    print(f\"Results saved to sesotho_lstm_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb7afbfe25ad22",
   "metadata": {
    "id": "5bbb7afbfe25ad22"
   },
   "source": [
    "# We now create Baselines with pre-trained Multilingual transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288861ae8072fb15",
   "metadata": {},
   "source": [
    "## AfroXLMR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaab94162e258de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T10:23:51.886403Z",
     "start_time": "2025-05-17T10:23:43.459518Z"
    },
    "id": "2aaab94162e258de",
    "outputId": "1e65fc6d-a6e0-4a6a-8434-edb89d881d27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets peft evaluate plotly --quiet\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# por_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"pt-MZ\")\n",
    "# swa_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"swa\")\n",
    "# sot_dataset=load_dataset(\"hamza-student-123/nlp-assignment-news-data\",'sot')\n",
    "#\n",
    "# for ds in [por_dataset,swa_dataset,sot_dataset]: # Change to all three later\n",
    "#     for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "#         if ds[lbl].column_names[0]== \"tweet\":\n",
    "#             ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "#         else:\n",
    "#             ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "#\n",
    "# por_df = por_dataset[\"train\"].to_pandas()\n",
    "# swa_df = swa_dataset[\"train\"].to_pandas()\n",
    "# sot_df = sot_dataset[\"train\"].to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febee723e76e99d",
   "metadata": {},
   "source": [
    "#### Baseline with [AfroXLMR](https://huggingface.co/Davlan/afro-xlmr-large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd162b829f304976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:01:45.747002Z",
     "start_time": "2025-06-18T19:26:08.801187Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 6539283,
     "status": "error",
     "timestamp": 1747593813857,
     "user": {
      "displayName": "Hamza Mokiwa",
      "userId": "01797446784641706967"
     },
     "user_tz": -120
    },
    "id": "bd162b829f304976",
    "outputId": "bd393c51-1f99-4a82-9bf0-8d4ae2b385c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "adapters 1.2.0 requires transformers~=4.51.3, but you have transformers 4.52.4 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "2025-06-18 21:27:43,149 - INFO - Using device: cpu\n",
      "2025-06-18 21:27:43,150 - INFO - Loading model: Davlan/afro-xlmr-base...\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-06-18 21:27:45,602 - INFO - Loading data...\n",
      "2025-06-18 21:27:47,429 - INFO - Data loaded successfully: 3063 training, 767 validation, 3662 test examples\n",
      "2025-06-18 21:27:47,430 - INFO - Creating data loaders...\n",
      "2025-06-18 21:27:47,435 - INFO - Starting training...\n",
      "2025-06-18 21:27:47,436 - INFO - Epoch 1/3\n",
      "Training: 100%|██████████| 192/192 [18:57<00:00,  5.92s/it, loss=1.2733]\n",
      "Evaluating: 100%|██████████| 48/48 [00:52<00:00,  1.09s/it]\n",
      "2025-06-18 21:47:37,166 - INFO - Epoch 1 results:\n",
      "2025-06-18 21:47:37,167 - INFO - Train Loss: 0.9370, Time: 1137.54s\n",
      "2025-06-18 21:47:37,168 - INFO - Val Loss: 0.8448, Accuracy: 0.5815, Precision: 0.6487, Recall: 0.5815, F1: 0.5840\n",
      "2025-06-18 21:47:37,170 - INFO - New best model with F1: 0.5840\n",
      "2025-06-18 21:47:37,171 - INFO - Epoch 2/3\n",
      "Training: 100%|██████████| 192/192 [17:34<00:00,  5.49s/it, loss=0.7318]\n",
      "Evaluating: 100%|██████████| 48/48 [00:49<00:00,  1.04s/it]\n",
      "2025-06-18 22:06:01,224 - INFO - Epoch 2 results:\n",
      "2025-06-18 22:06:01,224 - INFO - Train Loss: 0.7437, Time: 1054.37s\n",
      "2025-06-18 22:06:01,225 - INFO - Val Loss: 0.7608, Accuracy: 0.6558, Precision: 0.6562, Recall: 0.6558, F1: 0.6549\n",
      "2025-06-18 22:06:01,227 - INFO - New best model with F1: 0.6549\n",
      "2025-06-18 22:06:01,228 - INFO - Epoch 3/3\n",
      "Training: 100%|██████████| 192/192 [17:33<00:00,  5.49s/it, loss=1.0845]\n",
      "Evaluating: 100%|██████████| 48/48 [00:51<00:00,  1.07s/it]\n",
      "2025-06-18 22:24:26,296 - INFO - Epoch 3 results:\n",
      "2025-06-18 22:24:26,297 - INFO - Train Loss: 0.6387, Time: 1053.53s\n",
      "2025-06-18 22:24:26,298 - INFO - Val Loss: 0.7829, Accuracy: 0.6519, Precision: 0.6633, Recall: 0.6519, F1: 0.6542\n",
      "2025-06-18 22:24:26,299 - INFO - Loading best model for testing...\n",
      "2025-06-18 22:24:26,305 - INFO - Evaluating on test set...\n",
      "Evaluating: 100%|██████████| 229/229 [04:06<00:00,  1.08s/it]\n",
      "2025-06-18 22:28:32,713 - INFO - Test Results:\n",
      "2025-06-18 22:28:32,714 - INFO - Loss: 0.8431\n",
      "2025-06-18 22:28:32,715 - INFO - Accuracy: 0.6204\n",
      "2025-06-18 22:28:32,716 - INFO - Precision: 0.6849\n",
      "2025-06-18 22:28:32,716 - INFO - Recall: 0.6204\n",
      "2025-06-18 22:28:32,717 - INFO - F1 Score: 0.6344\n",
      "2025-06-18 22:28:32,750 - INFO - Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to afroxlmr_results_por.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 22:28:35,284 - INFO - Model saved to ./xmlr_sentiment_model_por\n",
      "2025-06-18 22:28:35,408 - INFO - Using device: cpu\n",
      "2025-06-18 22:28:35,409 - INFO - Loading model: Davlan/afro-xlmr-base...\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-06-18 22:28:39,879 - INFO - Loading data...\n",
      "2025-06-18 22:28:41,839 - INFO - Data loaded successfully: 1810 training, 453 validation, 748 test examples\n",
      "2025-06-18 22:28:41,841 - INFO - Creating data loaders...\n",
      "2025-06-18 22:28:41,844 - INFO - Starting training...\n",
      "2025-06-18 22:28:41,844 - INFO - Epoch 1/3\n",
      "Training: 100%|██████████| 114/114 [10:44<00:00,  5.65s/it, loss=0.9162]\n",
      "Evaluating: 100%|██████████| 29/29 [00:28<00:00,  1.03it/s]\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-06-18 22:39:54,457 - INFO - Epoch 1 results:\n",
      "2025-06-18 22:39:54,457 - INFO - Train Loss: 0.9006, Time: 644.41s\n",
      "2025-06-18 22:39:54,458 - INFO - Val Loss: 0.8233, Accuracy: 0.6159, Precision: 0.5370, Recall: 0.6159, F1: 0.5384\n",
      "2025-06-18 22:39:54,460 - INFO - New best model with F1: 0.5384\n",
      "2025-06-18 22:39:54,461 - INFO - Epoch 2/3\n",
      "Training: 100%|██████████| 114/114 [10:06<00:00,  5.32s/it, loss=1.3276]\n",
      "Evaluating: 100%|██████████| 29/29 [00:28<00:00,  1.02it/s]\n",
      "2025-06-18 22:50:28,948 - INFO - Epoch 2 results:\n",
      "2025-06-18 22:50:28,949 - INFO - Train Loss: 0.7686, Time: 606.08s\n",
      "2025-06-18 22:50:28,949 - INFO - Val Loss: 0.8090, Accuracy: 0.6358, Precision: 0.6214, Recall: 0.6358, F1: 0.5990\n",
      "2025-06-18 22:50:28,951 - INFO - New best model with F1: 0.5990\n",
      "2025-06-18 22:50:28,952 - INFO - Epoch 3/3\n",
      "Training: 100%|██████████| 114/114 [10:01<00:00,  5.28s/it, loss=0.4912]\n",
      "Evaluating: 100%|██████████| 29/29 [00:28<00:00,  1.03it/s]\n",
      "2025-06-18 23:00:58,961 - INFO - Epoch 3 results:\n",
      "2025-06-18 23:00:58,962 - INFO - Train Loss: 0.6525, Time: 601.92s\n",
      "2025-06-18 23:00:58,963 - INFO - Val Loss: 0.8072, Accuracy: 0.6291, Precision: 0.6127, Recall: 0.6291, F1: 0.6135\n",
      "2025-06-18 23:00:58,965 - INFO - New best model with F1: 0.6135\n",
      "2025-06-18 23:00:58,965 - INFO - Loading best model for testing...\n",
      "2025-06-18 23:00:58,970 - INFO - Evaluating on test set...\n",
      "Evaluating: 100%|██████████| 47/47 [00:45<00:00,  1.03it/s]\n",
      "2025-06-18 23:01:44,687 - INFO - Test Results:\n",
      "2025-06-18 23:01:44,688 - INFO - Loss: 0.7794\n",
      "2025-06-18 23:01:44,689 - INFO - Accuracy: 0.6350\n",
      "2025-06-18 23:01:44,689 - INFO - Precision: 0.6228\n",
      "2025-06-18 23:01:44,690 - INFO - Recall: 0.6350\n",
      "2025-06-18 23:01:44,691 - INFO - F1 Score: 0.6227\n",
      "2025-06-18 23:01:44,695 - INFO - Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to afroxlmr_results_swa.csv\n"
     ]
    },
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"The requested operation cannot be performed on a file with a user-mapped section open.\" })",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSafetensorError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 298\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# langs = ['sot']\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m langs:\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     \u001b[43mevaluate_afro_xlmr_for_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 290\u001b[39m, in \u001b[36mevaluate_afro_xlmr_for_lang\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m    288\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mSaving model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    289\u001b[39m model_save_path = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./xmlr_sentiment_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m tokenizer.save_pretrained(model_save_path)\n\u001b[32m    292\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_save_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\transformers\\modeling_utils.py:3564\u001b[39m, in \u001b[36msave_pretrained\u001b[39m\u001b[34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[39m\n\u001b[32m   3560\u001b[39m if self._tp_size is not None:\n\u001b[32m   3561\u001b[39m     state_dict = replace_state_dict_local_with_dtensor(state_dict, self._tp_plan, self._device_mesh)\n\u001b[32m   3563\u001b[39m if safe_serialization:\n\u001b[32m-> \u001b[39m\u001b[32m3564\u001b[39m     # TODO: fix safe_serialization for tied weights\n\u001b[32m   3565\u001b[39m     # Safetensors does not allow tensor aliasing.\n\u001b[32m   3566\u001b[39m     # We're going to remove aliases before saving\n\u001b[32m   3567\u001b[39m     ptrs = collections.defaultdict(list)\n\u001b[32m   3568\u001b[39m     for name, tensor in state_dict.items():\n\u001b[32m   3569\u001b[39m         # Sometimes in the state_dict we have non-tensor objects.\n\u001b[32m   3570\u001b[39m         # e.g. in bitsandbytes we have some `str` objects in the state_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\safetensors\\torch.py:286\u001b[39m, in \u001b[36msave_file\u001b[39m\u001b[34m(tensors, filename, metadata)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_file\u001b[39m(\n\u001b[32m    256\u001b[39m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor],\n\u001b[32m    257\u001b[39m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    258\u001b[39m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    259\u001b[39m ):\n\u001b[32m    260\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[33;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[32m    262\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[43mserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mSafetensorError\u001b[39m: Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"The requested operation cannot be performed on a file with a user-mapped section open.\" })"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets peft evaluate plotly sentencepiece --quiet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from datasets import load_dataset\n",
    "# import torch_optimizer as optim\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(language):\n",
    "    try:\n",
    "        if language=='por':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"por\",trust_remote_code=True)\n",
    "        elif language=='swa':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"swa\",trust_remote_code=True)\n",
    "        elif language=='sot':\n",
    "            chosen_dataset=load_dataset(\"hamza-student-123/nlp-assignment-news-data\",'sot')\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        for ds in [chosen_dataset]: # Change to all three later\n",
    "            for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "                if ds[lbl].column_names[0]== \"tweet\":\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "                else:\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "\n",
    "        train_df  = chosen_dataset[\"train\"].to_pandas()\n",
    "        val_df  = chosen_dataset[\"validation\"].to_pandas()\n",
    "        test_df  = chosen_dataset[\"test\"].to_pandas()\n",
    "        logger.info(f\"Data loaded successfully: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test examples\")\n",
    "        return train_df, val_df, test_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Function to create DataLoaders\n",
    "def create_data_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, text_column='text', label_column='label'):\n",
    "    train_dataset = SentimentDataset(\n",
    "        texts=train_df[text_column].tolist(),\n",
    "        labels=train_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        texts=val_df[text_column].tolist(),\n",
    "        labels=val_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        texts=test_df[text_column].tolist(),\n",
    "        labels=test_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Tuple of (loss, accuracy, precision, recall, f1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, class_names):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_afro_xlmr_for_lang(language):\n",
    "    config = {\n",
    "        'model_name': 'Davlan/afro-xlmr-base',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    logger.info(f\"Loading model: {config['model_name']}...\")\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['model_name'])\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=config['num_labels']\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{language}')\n",
    "\n",
    "    # Create data loaders\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column']\n",
    "    )\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=config['warmup_steps'],\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    logger.info(\"Starting training...\")\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        logger.info(f\"Epoch {epoch + 1}/{config['epochs']}\")\n",
    "\n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_loader,optimizer,scheduler, device) # train_epoch(model, train_loader, scheduler, device)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1} results:\")\n",
    "        logger.info(f\"Train Loss: {train_loss:.4f}, Time: {train_time:.2f}s\")\n",
    "        logger.info(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            logger.info(f\"New best model with F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Load best model for testing\n",
    "    if best_model_state:\n",
    "        logger.info(\"Loading best model for testing...\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Test evaluation\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{language}.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Save model\n",
    "    logger.info(\"Saving model...\")\n",
    "    model_save_path = f'./xmlr_sentiment_model_{language}'\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    logger.info(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# evaluate_afro_xlmr()\n",
    "langs = ['por','swa']\n",
    "# langs = ['sot']\n",
    "for l in langs:\n",
    "    evaluate_afro_xlmr_for_lang(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70660a07aec178",
   "metadata": {},
   "source": [
    "##### Evaluation for Sesotho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139b49723ff4d98",
   "metadata": {
    "id": "4139b49723ff4d98"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers datasets peft evaluate plotly sentencepiece --quiet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from datasets import load_dataset\n",
    "# import torch_optimizer as optim\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.label_mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}  # Label conversion\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.label_mapping[self.labels[idx]]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(language):\n",
    "    try:\n",
    "        if language=='por':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"por\",trust_remote_code=True)\n",
    "        elif language=='swa':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"swa\",trust_remote_code=True)\n",
    "        elif language=='sot':\n",
    "            chosen_dataset=load_dataset(\"hamza-student-123/nlp-assignment-news-data\",'sot')\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        for ds in [chosen_dataset]: # Change to all three later\n",
    "            for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "                if ds[lbl].column_names[0]== \"tweet\":\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "                else:\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "\n",
    "        train_df  = chosen_dataset[\"train\"].to_pandas()\n",
    "        val_df  = chosen_dataset[\"validation\"].to_pandas()\n",
    "        test_df  = chosen_dataset[\"test\"].to_pandas()\n",
    "        logger.info(f\"Data loaded successfully: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test examples\")\n",
    "        return train_df, val_df, test_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Function to create DataLoaders\n",
    "def create_data_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, text_column='text', label_column='label'):\n",
    "    train_dataset = SentimentDataset(\n",
    "        texts=train_df[text_column].tolist(),\n",
    "        labels=train_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        texts=val_df[text_column].tolist(),\n",
    "        labels=val_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        texts=test_df[text_column].tolist(),\n",
    "        labels=test_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Tuple of (loss, accuracy, precision, recall, f1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, class_names):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_afro_xlmr_for_lang(language):\n",
    "    config = {\n",
    "        'model_name': 'Davlan/afro-xlmr-base',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    logger.info(f\"Loading model: {config['model_name']}...\")\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['model_name'])\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=config['num_labels']\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{language}')\n",
    "\n",
    "    # Create data loaders\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column']\n",
    "    )\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=config['warmup_steps'],\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    logger.info(\"Starting training...\")\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        logger.info(f\"Epoch {epoch + 1}/{config['epochs']}\")\n",
    "\n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_loader,optimizer,scheduler, device) # train_epoch(model, train_loader, scheduler, device)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1} results:\")\n",
    "        logger.info(f\"Train Loss: {train_loss:.4f}, Time: {train_time:.2f}s\")\n",
    "        logger.info(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            logger.info(f\"New best model with F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Load best model for testing\n",
    "    if best_model_state:\n",
    "        logger.info(\"Loading best model for testing...\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Test evaluation\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{language}.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Save model\n",
    "    logger.info(\"Saving model...\")\n",
    "    model_save_path = f'./xmlr_sentiment_model_{language}'\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    logger.info(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "langs = ['sot']\n",
    "for l in langs:\n",
    "    evaluate_afro_xlmr_for_lang(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81947d17b90728",
   "metadata": {},
   "source": [
    "## mBERT\n",
    "\n",
    "### Baseline with [mBERT](https://huggingface.co/google-bert/bert-base-multilingual-cased)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6175a1aa9caa92",
   "metadata": {
    "id": "9a6175a1aa9caa92",
    "outputId": "995ff0b7-014c-4eff-afb4-bd26904a36a8",
    "tags": [
     "mbert"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting benchmarking with LIME explanations...\n",
      "\n",
      "Processing Swahili dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 14853.57 examples/s]\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 12564.27 examples/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 13980.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating LIME explanations for Swahili...\n",
      "  Generated explanation 1/10 for sample 654\n",
      "  Generated explanation 2/10 for sample 114\n",
      "  Generated explanation 3/10 for sample 25\n",
      "  Generated explanation 4/10 for sample 281\n",
      "  Generated explanation 5/10 for sample 250\n",
      "  Generated explanation 6/10 for sample 228\n",
      "  Generated explanation 7/10 for sample 142\n",
      "  Generated explanation 8/10 for sample 104\n",
      "  Generated explanation 9/10 for sample 692\n",
      "  Generated explanation 10/10 for sample 558\n",
      "\n",
      "Processing Portuguese dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10175/2280496632.py:343: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 14149.98 examples/s]\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 12529.87 examples/s]\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 14905.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='229' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [229/229 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating LIME explanations for Portuguese...\n",
      "  Generated explanation 1/10 for sample 2619\n",
      "  Generated explanation 2/10 for sample 456\n",
      "  Generated explanation 3/10 for sample 102\n",
      "  Generated explanation 4/10 for sample 3037\n",
      "  Generated explanation 5/10 for sample 1126\n",
      "  Generated explanation 6/10 for sample 1003\n",
      "  Generated explanation 7/10 for sample 914\n",
      "  Generated explanation 8/10 for sample 571\n",
      "  Generated explanation 9/10 for sample 3016\n",
      "  Generated explanation 10/10 for sample 419\n",
      "\n",
      "Processing Sesotho dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1741/1741 [00:00<00:00, 8214.19 examples/s]\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 12935.68 examples/s]\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 13669.38 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating LIME explanations for Sesotho...\n",
      "  Generated explanation 1/10 for sample 163\n",
      "  Generated explanation 2/10 for sample 28\n",
      "  Generated explanation 3/10 for sample 6\n",
      "  Generated explanation 4/10 for sample 189\n",
      "  Generated explanation 5/10 for sample 70\n",
      "  Generated explanation 6/10 for sample 62\n",
      "  Generated explanation 7/10 for sample 57\n",
      "  Generated explanation 8/10 for sample 35\n",
      "  Generated explanation 9/10 for sample 188\n",
      "  Generated explanation 10/10 for sample 26\n",
      "\n",
      "Results saved to: /home/troy/Documents/nlp-research/benchmark_results/mbert_benchmark_results_20250612_225610.csv\n",
      "LIME explanations summary saved to: /home/troy/Documents/nlp-research/lime_explanations/explanations_20250612_225610/explanations_summary.json\n",
      "\n",
      "==== BENCHMARKING WITH LIME EXPLANATIONS COMPLETE ====\n",
      "\n",
      "Results Summary:\n",
      "      Dataset  Model      Loss  Accuracy        F1  Precision    Recall\n",
      "0     Swahili  mBERT  1.035671  0.582888  0.440901   0.373173  0.582888\n",
      "1  Portuguese  mBERT  1.078578  0.176952  0.079557   0.350615  0.176952\n",
      "2     Sesotho  mBERT  1.198339  0.178899  0.093481   0.064011  0.178899\n",
      "\n",
      "LIME Explanations saved in: /home/troy/Documents/nlp-research/lime_explanations/explanations_20250612_225610\n",
      "Files generated:\n",
      "- Individual HTML explanations for each sample\n",
      "- JSON files with detailed explanation data\n",
      "- Summary statistics of feature importance\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "run_timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "os.makedirs(\"./benchmark_results\", exist_ok=True)\n",
    "os.makedirs(\"./lime_explanations\", exist_ok=True)\n",
    "\n",
    "output_csv = os.path.abspath(f\"./benchmark_results/mbert_benchmark_results_{run_timestamp}.csv\")\n",
    "explanations_dir = os.path.abspath(f\"./lime_explanations/explanations_{run_timestamp}\")\n",
    "os.makedirs(explanations_dir, exist_ok=True)\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    \"Dataset\", \"Model\", \"Loss\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\"\n",
    "])\n",
    "\n",
    "try:\n",
    "    swa_dataset = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "except Exception as e:\n",
    "    swa_dataset = None\n",
    "\n",
    "try:\n",
    "    por_dataset = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "except Exception as e:\n",
    "    por_dataset = None\n",
    "\n",
    "try:\n",
    "    sot_dataset = load_dataset(\"csv\", data_files={\"train\": \"./datasets/sotho-news/sotho_news_dataset.csv\"})\n",
    "except Exception as e:\n",
    "    sot_dataset = None\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "class ModelPredictor:\n",
    "    \"\"\"Wrapper class for LIME explanations\"\"\"\n",
    "    def __init__(self, model, tokenizer, device, num_labels):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.num_labels = num_labels\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict_proba(self, texts):\n",
    "        \"\"\"Predict probabilities for LIME\"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probas = F.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        return probas.cpu().numpy()\n",
    "\n",
    "def generate_lime_explanations(model_predictor, test_texts, test_labels, dataset_name, \n",
    "                              label_names=None, num_samples=10):\n",
    "    \"\"\"Generate LIME explanations for sample predictions\"\"\"\n",
    "    \n",
    "    explainer = LimeTextExplainer(class_names=label_names or [f\"Class_{i}\" for i in range(3)])\n",
    "    \n",
    "    sample_indices = random.sample(range(len(test_texts)), min(num_samples, len(test_texts)))\n",
    "    explanations_data = []\n",
    "    \n",
    "    print(f\"\\nGenerating LIME explanations for {dataset_name}...\")\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        try:\n",
    "            text = test_texts[idx]\n",
    "            true_label = test_labels[idx]\n",
    "            \n",
    "            pred_proba = model_predictor.predict_proba([text])[0]\n",
    "            pred_label = np.argmax(pred_proba)\n",
    "            \n",
    "            exp = explainer.explain_instance(\n",
    "                text, \n",
    "                model_predictor.predict_proba, \n",
    "                num_features=10,\n",
    "                num_samples=1000\n",
    "            )\n",
    "            \n",
    "            explanation_data = {\n",
    "                'sample_id': idx,\n",
    "                'text': text,\n",
    "                'true_label': int(true_label),\n",
    "                'predicted_label': int(pred_label),\n",
    "                'prediction_probability': float(pred_proba[pred_label]),\n",
    "                'all_probabilities': pred_proba.tolist(),\n",
    "                'lime_explanation': []\n",
    "            }\n",
    "            \n",
    "            for feature, importance in exp.as_list():\n",
    "                explanation_data['lime_explanation'].append({\n",
    "                    'feature': feature,\n",
    "                    'importance': float(importance)\n",
    "                })\n",
    "            \n",
    "            explanations_data.append(explanation_data)\n",
    "            \n",
    "            html_file = os.path.join(explanations_dir, f\"{dataset_name}_sample_{idx}_explanation.html\")\n",
    "            exp.save_to_file(html_file)\n",
    "            \n",
    "            print(f\"  Generated explanation {i+1}/{len(sample_indices)} for sample {idx}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating explanation for sample {idx}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Save explanations as JSON\n",
    "    json_file = os.path.join(explanations_dir, f\"{dataset_name}_lime_explanations.json\")\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(explanations_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return explanations_data\n",
    "\n",
    "def get_benchmark_metrics(dataset_name, dataset, num_labels):\n",
    "\n",
    "    if dataset is None:\n",
    "        return None, None\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        num_labels=num_labels\n",
    "    ).to(device)\n",
    "\n",
    "    text_column = None\n",
    "    label_column = None\n",
    "\n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in text_candidates:\n",
    "            if candidate in columns:\n",
    "                text_column = candidate\n",
    "                break\n",
    "        if text_column:\n",
    "            break\n",
    "\n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in label_candidates:\n",
    "            if candidate in columns:\n",
    "                label_column = candidate\n",
    "                break\n",
    "        if label_column:\n",
    "            break\n",
    "\n",
    "    if text_column is None:\n",
    "        for split in dataset:\n",
    "            for col in dataset[split].column_names:\n",
    "                if isinstance(dataset[split][col][0], str):\n",
    "                    text_column = col\n",
    "                    break\n",
    "            if text_column:\n",
    "                break\n",
    "\n",
    "    if text_column is None:\n",
    "        return None, None\n",
    "\n",
    "    if label_column is None:\n",
    "        return None, None\n",
    "\n",
    "    required_splits = [\"train\", \"validation\", \"test\"]\n",
    "    missing_splits = [split for split in required_splits if split not in dataset]\n",
    "\n",
    "    if missing_splits:\n",
    "        if \"train\" in dataset:\n",
    "            train_valid_test = {}\n",
    "\n",
    "            for split in dataset:\n",
    "                if split in required_splits:\n",
    "                    train_valid_test[split] = dataset[split]\n",
    "\n",
    "            if \"train\" in dataset and (\"validation\" not in train_valid_test or \"test\" not in train_valid_test):\n",
    "                if \"validation\" not in train_valid_test:\n",
    "                    if \"test\" not in train_valid_test:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                        test_valid_split = split_datasets[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = test_valid_split[\"train\"]\n",
    "                        train_valid_test[\"test\"] = test_valid_split[\"test\"]\n",
    "                    else:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = split_datasets[\"test\"]\n",
    "                else:\n",
    "                    split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                    train_valid_test[\"test\"] = split_datasets[\"test\"]\n",
    "\n",
    "            dataset = DatasetDict(train_valid_test)\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    label_mapping = None\n",
    "    label_names = None\n",
    "    for split in dataset:\n",
    "        if isinstance(dataset[split][label_column][0], str):\n",
    "            all_labels = set()\n",
    "            for example in dataset[split][label_column]:\n",
    "                all_labels.add(example)\n",
    "\n",
    "            sorted_labels = sorted(all_labels)\n",
    "            label_mapping = {label: i for i, label in enumerate(sorted_labels)}\n",
    "            label_names = sorted_labels\n",
    "            break\n",
    "\n",
    "    processed_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in dataset.items():\n",
    "        texts = split_dataset[text_column]\n",
    "\n",
    "        if label_mapping:\n",
    "            labels = [label_mapping[label] for label in split_dataset[label_column]]\n",
    "        else:\n",
    "            labels = []\n",
    "            for label in split_dataset[label_column]:\n",
    "                if isinstance(label, (int, np.integer)):\n",
    "                    labels.append(int(label))\n",
    "                elif isinstance(label, str):\n",
    "                    try:\n",
    "                        labels.append(int(label))\n",
    "                    except ValueError:\n",
    "                        labels.append(0)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "\n",
    "        processed_dataset[split_name] = Dataset.from_dict({\n",
    "            \"text\": texts,\n",
    "            \"label\": labels\n",
    "        })\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    tokenized_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in processed_dataset.items():\n",
    "        tokenized_split = split_dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "        tokenized_dataset[split_name] = tokenized_split\n",
    "\n",
    "        for required_col in [\"input_ids\", \"attention_mask\", \"label\"]:\n",
    "            if required_col not in tokenized_split.column_names:\n",
    "                return None, None\n",
    "\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=f\"./benchmark_results/{dataset_name}_{run_timestamp}\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        logging_dir=f\"./benchmark_results/{dataset_name}_{run_timestamp}/logs\",\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=eval_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        benchmark_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "        \n",
    "        model_predictor = ModelPredictor(model, tokenizer, device, num_labels)\n",
    "        test_texts = processed_dataset[\"test\"][\"text\"]\n",
    "        test_labels = processed_dataset[\"test\"][\"label\"]\n",
    "        \n",
    "        lime_explanations = generate_lime_explanations(\n",
    "            model_predictor, test_texts, test_labels, dataset_name, \n",
    "            label_names=label_names, num_samples=10\n",
    "        )\n",
    "\n",
    "        return benchmark_results, lime_explanations\n",
    "    except Exception as e:\n",
    "        print(f\"Error in benchmarking {dataset_name}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "available_datasets = []\n",
    "if swa_dataset:\n",
    "    available_datasets.append((\"Swahili\", swa_dataset, 3))\n",
    "if por_dataset:\n",
    "    available_datasets.append((\"Portuguese\", por_dataset, 3))\n",
    "if sot_dataset:\n",
    "    available_datasets.append((\"Sesotho\", sot_dataset, 3))\n",
    "\n",
    "all_results = []\n",
    "all_explanations = {}\n",
    "\n",
    "print(\"Starting benchmarking with LIME explanations...\")\n",
    "\n",
    "for dataset_name, dataset, num_labels in available_datasets:\n",
    "    try:\n",
    "        print(f\"\\nProcessing {dataset_name} dataset...\")\n",
    "        results, explanations = get_benchmark_metrics(dataset_name, dataset, num_labels)\n",
    "\n",
    "        if results:\n",
    "            results_df = results_df._append({\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"Model\": \"mBERT\",\n",
    "                \"Loss\": results.get(\"eval_loss\"),\n",
    "                \"Accuracy\": results.get(\"eval_accuracy\"),\n",
    "                \"F1\": results.get(\"eval_f1\"),\n",
    "                \"Precision\": results.get(\"eval_precision\"),\n",
    "                \"Recall\": results.get(\"eval_recall\")\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            all_results.append({\"Dataset\": dataset_name, \"Results\": results})\n",
    "            if explanations:\n",
    "                all_explanations[dataset_name] = explanations\n",
    "        else:\n",
    "            print(f\"Failed to process {dataset_name} dataset\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dataset_name}: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nResults saved to: {output_csv}\")\n",
    "except Exception as e:\n",
    "    emergency_path = f\"./emergency_results_{run_timestamp}.csv\"\n",
    "    results_df.to_csv(emergency_path, index=False)\n",
    "    print(f\"\\nEmergency results saved to: {emergency_path}\")\n",
    "\n",
    "if all_explanations:\n",
    "    summary_file = os.path.join(explanations_dir, \"explanations_summary.json\")\n",
    "    explanation_summary = {}\n",
    "    \n",
    "    for dataset_name, explanations in all_explanations.items():\n",
    "        summary_stats = {\n",
    "            'total_explanations': len(explanations),\n",
    "            'average_prediction_confidence': np.mean([exp['prediction_probability'] for exp in explanations]),\n",
    "            'correct_predictions': sum(1 for exp in explanations if exp['true_label'] == exp['predicted_label']),\n",
    "            'top_important_features': {}\n",
    "        }\n",
    "        \n",
    "        feature_importance = {}\n",
    "        for exp in explanations:\n",
    "            for feature_data in exp['lime_explanation']:\n",
    "                feature = feature_data['feature']\n",
    "                importance = abs(feature_data['importance'])\n",
    "                if feature in feature_importance:\n",
    "                    feature_importance[feature].append(importance)\n",
    "                else:\n",
    "                    feature_importance[feature] = [importance]\n",
    "        \n",
    "        avg_feature_importance = {\n",
    "            feature: np.mean(importances) \n",
    "            for feature, importances in feature_importance.items()\n",
    "        }\n",
    "        \n",
    "        sorted_features = sorted(avg_feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "        summary_stats['top_important_features'] = dict(sorted_features[:10])\n",
    "        \n",
    "        explanation_summary[dataset_name] = summary_stats\n",
    "    \n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(explanation_summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cde647348a8cd0",
   "metadata": {},
   "source": [
    "### Fine-Tuning BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eaa462",
   "metadata": {
    "id": "37eaa462",
    "outputId": "b581ac85-7100-4eea-ce39-57cd01cd6f91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:40:55,321 - INFO - Successfully loaded Swahili dataset from HuggingFace Hub\n",
      "2025-05-10 00:40:57,013 - INFO - Successfully loaded Portuguese dataset from HuggingFace Hub\n",
      "2025-05-10 00:40:57,013 - INFO - Successfully loaded Portuguese dataset from HuggingFace Hub\n",
      "2025-05-10 00:40:57,269 - INFO - Successfully loaded Sesotho dataset from CSV\n",
      "2025-05-10 00:40:57,271 - INFO - Available datasets: ['Swahili', 'Portuguese', 'Sesotho']\n",
      "2025-05-10 00:40:57,272 - INFO - \n",
      "==== FINE-TUNING ON SWAHILI DATASET ====\n",
      "2025-05-10 00:40:57,272 - INFO - Starting fine-tuning for Swahili\n",
      "2025-05-10 00:40:57,273 - INFO - Using device: cuda\n",
      "2025-05-10 00:40:57,269 - INFO - Successfully loaded Sesotho dataset from CSV\n",
      "2025-05-10 00:40:57,271 - INFO - Available datasets: ['Swahili', 'Portuguese', 'Sesotho']\n",
      "2025-05-10 00:40:57,272 - INFO - \n",
      "==== FINE-TUNING ON SWAHILI DATASET ====\n",
      "2025-05-10 00:40:57,272 - INFO - Starting fine-tuning for Swahili\n",
      "2025-05-10 00:40:57,273 - INFO - Using device: cuda\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-10 00:40:58,304 - INFO - Dataset Swahili structure:\n",
      "2025-05-10 00:40:58,305 - INFO -   - Split: train, Examples: 1810\n",
      "2025-05-10 00:40:58,306 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,306 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,306 - INFO -   - Split: validation, Examples: 453\n",
      "2025-05-10 00:40:58,306 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,307 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,307 - INFO -   - Split: test, Examples: 748\n",
      "2025-05-10 00:40:58,307 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,307 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,308 - INFO - For Swahili, using text_column=tweet, label_column=label\n",
      "2025-05-10 00:40:58,310 - INFO - Created label mapping for Swahili: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:40:58,304 - INFO - Dataset Swahili structure:\n",
      "2025-05-10 00:40:58,305 - INFO -   - Split: train, Examples: 1810\n",
      "2025-05-10 00:40:58,306 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,306 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,306 - INFO -   - Split: validation, Examples: 453\n",
      "2025-05-10 00:40:58,306 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,307 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,307 - INFO -   - Split: test, Examples: 748\n",
      "2025-05-10 00:40:58,307 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:40:58,307 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:40:58,308 - INFO - For Swahili, using text_column=tweet, label_column=label\n",
      "2025-05-10 00:40:58,310 - INFO - Created label mapping for Swahili: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:40:58,317 - INFO - Processed train split: 1810 examples\n",
      "2025-05-10 00:40:58,322 - INFO - Processed validation split: 453 examples\n",
      "2025-05-10 00:40:58,327 - INFO - Processed test split: 748 examples\n",
      "2025-05-10 00:40:58,317 - INFO - Processed train split: 1810 examples\n",
      "2025-05-10 00:40:58,322 - INFO - Processed validation split: 453 examples\n",
      "2025-05-10 00:40:58,327 - INFO - Processed test split: 748 examples\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 17231.17 examples/s]\n",
      "2025-05-10 00:40:58,456 - INFO - Tokenized train split: 1810 examples\n",
      "2025-05-10 00:40:58,457 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 17231.17 examples/s]\n",
      "2025-05-10 00:40:58,456 - INFO - Tokenized train split: 1810 examples\n",
      "2025-05-10 00:40:58,457 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 16432.89 examples/s]\n",
      "2025-05-10 00:40:58,511 - INFO - Tokenized validation split: 453 examples\n",
      "2025-05-10 00:40:58,511 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 16432.89 examples/s]\n",
      "2025-05-10 00:40:58,511 - INFO - Tokenized validation split: 453 examples\n",
      "2025-05-10 00:40:58,511 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 17553.81 examples/s]\n",
      "2025-05-10 00:40:58,579 - INFO - Tokenized test split: 748 examples\n",
      "2025-05-10 00:40:58,579 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 17553.81 examples/s]\n",
      "2025-05-10 00:40:58,579 - INFO - Tokenized test split: 748 examples\n",
      "2025-05-10 00:40:58,579 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "2025-05-10 00:40:58,601 - INFO - Starting fine-tuning Swahili with 1810 examples\n",
      "2025-05-10 00:40:58,601 - INFO - Starting fine-tuning Swahili with 1810 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [342/342 01:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.840700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.909700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.954400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.925500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.864900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.838700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.889400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.896900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.890300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.918200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.838300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.826100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.864500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.787600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.773600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.747900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.816300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.783100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.744800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.855600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:42:41,517 - INFO - Model saved to ./models/swahili/model.pt\n",
      "2025-05-10 00:42:41,567 - INFO - Tokenizer saved to ./models/swahili\n",
      "2025-05-10 00:42:41,567 - INFO - Label mapping saved to ./models/swahili/label_mapping.json\n",
      "2025-05-10 00:42:41,568 - INFO - Model config saved to ./models/swahili/config.json\n",
      "2025-05-10 00:42:41,568 - INFO - Training completed in 102.97 seconds\n",
      "2025-05-10 00:42:41,569 - INFO - Evaluating on validation set with 453 examples\n",
      "2025-05-10 00:42:41,567 - INFO - Tokenizer saved to ./models/swahili\n",
      "2025-05-10 00:42:41,567 - INFO - Label mapping saved to ./models/swahili/label_mapping.json\n",
      "2025-05-10 00:42:41,568 - INFO - Model config saved to ./models/swahili/config.json\n",
      "2025-05-10 00:42:41,568 - INFO - Training completed in 102.97 seconds\n",
      "2025-05-10 00:42:41,569 - INFO - Evaluating on validation set with 453 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-10 00:42:44,114 - INFO - Evaluating on test set with 748 examples\n",
      "2025-05-10 00:42:48,308 - INFO - Model metrics saved to ./models/swahili/metrics.json\n",
      "2025-05-10 00:42:48,309 - INFO - ============== RESULTS FOR Swahili ==============\n",
      "2025-05-10 00:42:48,309 - INFO - Training loss: 0.8556\n",
      "2025-05-10 00:42:48,310 - INFO - Validation results: {'eval_loss': 0.9941654205322266, 'eval_accuracy': 0.5209713024282561, 'eval_f1': 0.48724343479019466, 'eval_precision': 0.458357269134707, 'eval_recall': 0.5209713024282561, 'eval_runtime': 2.5441, 'eval_samples_per_second': 178.059, 'eval_steps_per_second': 11.399, 'epoch': 3.0}\n",
      "2025-05-10 00:42:48,310 - INFO - Test results: {'eval_loss': 0.9500337243080139, 'eval_accuracy': 0.5347593582887701, 'eval_f1': 0.504784295364511, 'eval_precision': 0.5145401534051629, 'eval_recall': 0.5347593582887701, 'eval_runtime': 4.1913, 'eval_samples_per_second': 178.465, 'eval_steps_per_second': 11.214, 'epoch': 3.0}\n",
      "2025-05-10 00:42:48,308 - INFO - Model metrics saved to ./models/swahili/metrics.json\n",
      "2025-05-10 00:42:48,309 - INFO - ============== RESULTS FOR Swahili ==============\n",
      "2025-05-10 00:42:48,309 - INFO - Training loss: 0.8556\n",
      "2025-05-10 00:42:48,310 - INFO - Validation results: {'eval_loss': 0.9941654205322266, 'eval_accuracy': 0.5209713024282561, 'eval_f1': 0.48724343479019466, 'eval_precision': 0.458357269134707, 'eval_recall': 0.5209713024282561, 'eval_runtime': 2.5441, 'eval_samples_per_second': 178.059, 'eval_steps_per_second': 11.399, 'epoch': 3.0}\n",
      "2025-05-10 00:42:48,310 - INFO - Test results: {'eval_loss': 0.9500337243080139, 'eval_accuracy': 0.5347593582887701, 'eval_f1': 0.504784295364511, 'eval_precision': 0.5145401534051629, 'eval_recall': 0.5347593582887701, 'eval_runtime': 4.1913, 'eval_samples_per_second': 178.465, 'eval_steps_per_second': 11.214, 'epoch': 3.0}\n",
      "2025-05-10 00:42:48,328 - INFO - \n",
      "==== FINE-TUNING ON PORTUGUESE DATASET ====\n",
      "2025-05-10 00:42:48,329 - INFO - Starting fine-tuning for Portuguese\n",
      "2025-05-10 00:42:48,330 - INFO - Using device: cuda\n",
      "2025-05-10 00:42:48,328 - INFO - \n",
      "==== FINE-TUNING ON PORTUGUESE DATASET ====\n",
      "2025-05-10 00:42:48,329 - INFO - Starting fine-tuning for Portuguese\n",
      "2025-05-10 00:42:48,330 - INFO - Using device: cuda\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-10 00:42:49,284 - INFO - Dataset Portuguese structure:\n",
      "2025-05-10 00:42:49,285 - INFO -   - Split: train, Examples: 3063\n",
      "2025-05-10 00:42:49,287 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,287 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,288 - INFO -   - Split: validation, Examples: 767\n",
      "2025-05-10 00:42:49,288 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,288 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,289 - INFO -   - Split: test, Examples: 3662\n",
      "2025-05-10 00:42:49,289 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,289 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,289 - INFO - For Portuguese, using text_column=tweet, label_column=label\n",
      "2025-05-10 00:42:49,284 - INFO - Dataset Portuguese structure:\n",
      "2025-05-10 00:42:49,285 - INFO -   - Split: train, Examples: 3063\n",
      "2025-05-10 00:42:49,287 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,287 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,288 - INFO -   - Split: validation, Examples: 767\n",
      "2025-05-10 00:42:49,288 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,288 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,289 - INFO -   - Split: test, Examples: 3662\n",
      "2025-05-10 00:42:49,289 - INFO -   - Features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:42:49,289 - INFO -   - Columns: ['tweet', 'label']\n",
      "2025-05-10 00:42:49,289 - INFO - For Portuguese, using text_column=tweet, label_column=label\n",
      "2025-05-10 00:42:49,294 - INFO - Created label mapping for Portuguese: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:42:49,306 - INFO - Processed train split: 3063 examples\n",
      "2025-05-10 00:42:49,294 - INFO - Created label mapping for Portuguese: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:42:49,306 - INFO - Processed train split: 3063 examples\n",
      "2025-05-10 00:42:49,312 - INFO - Processed validation split: 767 examples\n",
      "2025-05-10 00:42:49,324 - INFO - Processed test split: 3662 examples\n",
      "2025-05-10 00:42:49,312 - INFO - Processed validation split: 767 examples\n",
      "2025-05-10 00:42:49,324 - INFO - Processed test split: 3662 examples\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 18815.56 examples/s]\n",
      "2025-05-10 00:42:49,509 - INFO - Tokenized train split: 3063 examples\n",
      "2025-05-10 00:42:49,510 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 18815.56 examples/s]\n",
      "2025-05-10 00:42:49,509 - INFO - Tokenized train split: 3063 examples\n",
      "2025-05-10 00:42:49,510 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 17370.86 examples/s]\n",
      "2025-05-10 00:42:49,576 - INFO - Tokenized validation split: 767 examples\n",
      "2025-05-10 00:42:49,576 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 17370.86 examples/s]\n",
      "2025-05-10 00:42:49,576 - INFO - Tokenized validation split: 767 examples\n",
      "2025-05-10 00:42:49,576 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 19218.93 examples/s]\n",
      "2025-05-10 00:42:49,789 - INFO - Tokenized test split: 3662 examples\n",
      "2025-05-10 00:42:49,789 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 19218.93 examples/s]\n",
      "2025-05-10 00:42:49,789 - INFO - Tokenized test split: 3662 examples\n",
      "2025-05-10 00:42:49,789 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "2025-05-10 00:42:49,811 - INFO - Starting fine-tuning Portuguese with 3063 examples\n",
      "2025-05-10 00:42:49,811 - INFO - Starting fine-tuning Portuguese with 3063 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='576' max='576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [576/576 02:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.069100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.973400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.888400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.893400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.962300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.925500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.918400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.874500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.784100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.745700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.832900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.697100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.778600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.812300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.632300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.789300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.487700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.651900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.661000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.619700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.650300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.530500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.646300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.580200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.500300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:45:48,836 - INFO - Model saved to ./models/portuguese/model.pt\n",
      "2025-05-10 00:45:48,903 - INFO - Tokenizer saved to ./models/portuguese\n",
      "2025-05-10 00:45:48,904 - INFO - Label mapping saved to ./models/portuguese/label_mapping.json\n",
      "2025-05-10 00:45:48,905 - INFO - Model config saved to ./models/portuguese/config.json\n",
      "2025-05-10 00:45:48,905 - INFO - Training completed in 179.09 seconds\n",
      "2025-05-10 00:45:48,906 - INFO - Evaluating on validation set with 767 examples\n",
      "2025-05-10 00:45:48,903 - INFO - Tokenizer saved to ./models/portuguese\n",
      "2025-05-10 00:45:48,904 - INFO - Label mapping saved to ./models/portuguese/label_mapping.json\n",
      "2025-05-10 00:45:48,905 - INFO - Model config saved to ./models/portuguese/config.json\n",
      "2025-05-10 00:45:48,905 - INFO - Training completed in 179.09 seconds\n",
      "2025-05-10 00:45:48,906 - INFO - Evaluating on validation set with 767 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='277' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:45:53,405 - INFO - Evaluating on test set with 3662 examples\n",
      "2025-05-10 00:46:15,012 - INFO - Model metrics saved to ./models/portuguese/metrics.json\n",
      "2025-05-10 00:46:15,013 - INFO - ============== RESULTS FOR Portuguese ==============\n",
      "2025-05-10 00:46:15,014 - INFO - Training loss: 0.5003\n",
      "2025-05-10 00:46:15,014 - INFO - Validation results: {'eval_loss': 0.8650572299957275, 'eval_accuracy': 0.6192959582790091, 'eval_f1': 0.6183814552471274, 'eval_precision': 0.6188338690391852, 'eval_recall': 0.6192959582790091, 'eval_runtime': 4.4974, 'eval_samples_per_second': 170.542, 'eval_steps_per_second': 10.673, 'epoch': 3.0}\n",
      "2025-05-10 00:46:15,014 - INFO - Test results: {'eval_loss': 0.8389994502067566, 'eval_accuracy': 0.6318951392681594, 'eval_f1': 0.6440944722079657, 'eval_precision': 0.668456862074707, 'eval_recall': 0.6318951392681594, 'eval_runtime': 21.6037, 'eval_samples_per_second': 169.508, 'eval_steps_per_second': 10.6, 'epoch': 3.0}\n",
      "2025-05-10 00:46:15,012 - INFO - Model metrics saved to ./models/portuguese/metrics.json\n",
      "2025-05-10 00:46:15,013 - INFO - ============== RESULTS FOR Portuguese ==============\n",
      "2025-05-10 00:46:15,014 - INFO - Training loss: 0.5003\n",
      "2025-05-10 00:46:15,014 - INFO - Validation results: {'eval_loss': 0.8650572299957275, 'eval_accuracy': 0.6192959582790091, 'eval_f1': 0.6183814552471274, 'eval_precision': 0.6188338690391852, 'eval_recall': 0.6192959582790091, 'eval_runtime': 4.4974, 'eval_samples_per_second': 170.542, 'eval_steps_per_second': 10.673, 'epoch': 3.0}\n",
      "2025-05-10 00:46:15,014 - INFO - Test results: {'eval_loss': 0.8389994502067566, 'eval_accuracy': 0.6318951392681594, 'eval_f1': 0.6440944722079657, 'eval_precision': 0.668456862074707, 'eval_recall': 0.6318951392681594, 'eval_runtime': 21.6037, 'eval_samples_per_second': 169.508, 'eval_steps_per_second': 10.6, 'epoch': 3.0}\n",
      "2025-05-10 00:46:15,044 - INFO - \n",
      "==== FINE-TUNING ON SESOTHO DATASET ====\n",
      "2025-05-10 00:46:15,046 - INFO - Starting fine-tuning for Sesotho\n",
      "2025-05-10 00:46:15,046 - INFO - Using device: cuda\n",
      "2025-05-10 00:46:15,044 - INFO - \n",
      "==== FINE-TUNING ON SESOTHO DATASET ====\n",
      "2025-05-10 00:46:15,046 - INFO - Starting fine-tuning for Sesotho\n",
      "2025-05-10 00:46:15,046 - INFO - Using device: cuda\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-10 00:46:16,263 - INFO - Dataset Sesotho structure:\n",
      "2025-05-10 00:46:16,264 - INFO -   - Split: train, Examples: 2177\n",
      "2025-05-10 00:46:16,264 - INFO -   - Features: {'headline': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:46:16,264 - INFO -   - Columns: ['headline', 'label']\n",
      "2025-05-10 00:46:16,265 - INFO - For Sesotho, using text_column=headline, label_column=label\n",
      "2025-05-10 00:46:16,265 - INFO - Creating missing splits: ['validation', 'test'] for Sesotho\n",
      "2025-05-10 00:46:16,263 - INFO - Dataset Sesotho structure:\n",
      "2025-05-10 00:46:16,264 - INFO -   - Split: train, Examples: 2177\n",
      "2025-05-10 00:46:16,264 - INFO -   - Features: {'headline': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "2025-05-10 00:46:16,264 - INFO -   - Columns: ['headline', 'label']\n",
      "2025-05-10 00:46:16,265 - INFO - For Sesotho, using text_column=headline, label_column=label\n",
      "2025-05-10 00:46:16,265 - INFO - Creating missing splits: ['validation', 'test'] for Sesotho\n",
      "2025-05-10 00:46:16,286 - INFO - Created label mapping for Sesotho: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:46:16,286 - INFO - Created label mapping for Sesotho: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "2025-05-10 00:46:16,309 - INFO - Processed train split: 1741 examples\n",
      "2025-05-10 00:46:16,319 - INFO - Processed validation split: 218 examples\n",
      "2025-05-10 00:46:16,309 - INFO - Processed train split: 1741 examples\n",
      "2025-05-10 00:46:16,319 - INFO - Processed validation split: 218 examples\n",
      "2025-05-10 00:46:16,325 - INFO - Processed test split: 218 examples\n",
      "2025-05-10 00:46:16,325 - INFO - Processed test split: 218 examples\n",
      "Map: 100%|██████████| 1741/1741 [00:00<00:00, 16136.04 examples/s]\n",
      "2025-05-10 00:46:16,469 - INFO - Tokenized train split: 1741 examples\n",
      "2025-05-10 00:46:16,469 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 1741/1741 [00:00<00:00, 16136.04 examples/s]\n",
      "2025-05-10 00:46:16,469 - INFO - Tokenized train split: 1741 examples\n",
      "2025-05-10 00:46:16,469 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 12709.48 examples/s]\n",
      "2025-05-10 00:46:16,523 - INFO - Tokenized validation split: 218 examples\n",
      "2025-05-10 00:46:16,524 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 12709.48 examples/s]\n",
      "2025-05-10 00:46:16,523 - INFO - Tokenized validation split: 218 examples\n",
      "2025-05-10 00:46:16,524 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 13070.29 examples/s]\n",
      "2025-05-10 00:46:16,577 - INFO - Tokenized test split: 218 examples\n",
      "2025-05-10 00:46:16,578 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 13070.29 examples/s]\n",
      "2025-05-10 00:46:16,577 - INFO - Tokenized test split: 218 examples\n",
      "2025-05-10 00:46:16,578 - INFO - Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "2025-05-10 00:46:16,603 - INFO - Starting fine-tuning Sesotho with 1741 examples\n",
      "2025-05-10 00:46:16,603 - INFO - Starting fine-tuning Sesotho with 1741 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [327/327 01:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.859900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.623600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.704200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.757600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.780200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.715400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.678900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.700500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.627700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.718200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.605400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.637100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.664300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.513500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.642300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.656700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.554300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:48:00,473 - INFO - Model saved to ./models/sesotho/model.pt\n",
      "2025-05-10 00:48:00,544 - INFO - Tokenizer saved to ./models/sesotho\n",
      "2025-05-10 00:48:00,545 - INFO - Label mapping saved to ./models/sesotho/label_mapping.json\n",
      "2025-05-10 00:48:00,546 - INFO - Model config saved to ./models/sesotho/config.json\n",
      "2025-05-10 00:48:00,546 - INFO - Training completed in 103.94 seconds\n",
      "2025-05-10 00:48:00,547 - INFO - Evaluating on validation set with 218 examples\n",
      "2025-05-10 00:48:00,544 - INFO - Tokenizer saved to ./models/sesotho\n",
      "2025-05-10 00:48:00,545 - INFO - Label mapping saved to ./models/sesotho/label_mapping.json\n",
      "2025-05-10 00:48:00,546 - INFO - Model config saved to ./models/sesotho/config.json\n",
      "2025-05-10 00:48:00,546 - INFO - Training completed in 103.94 seconds\n",
      "2025-05-10 00:48:00,547 - INFO - Evaluating on validation set with 218 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-10 00:48:01,850 - INFO - Evaluating on test set with 218 examples\n",
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-10 00:48:03,137 - INFO - Model metrics saved to ./models/sesotho/metrics.json\n",
      "2025-05-10 00:48:03,138 - INFO - ============== RESULTS FOR Sesotho ==============\n",
      "2025-05-10 00:48:03,139 - INFO - Training loss: 0.5543\n",
      "2025-05-10 00:48:03,139 - INFO - Validation results: {'eval_loss': 0.5815077424049377, 'eval_accuracy': 0.7706422018348624, 'eval_f1': 0.758784555256037, 'eval_precision': 0.7473307497627334, 'eval_recall': 0.7706422018348624, 'eval_runtime': 1.3009, 'eval_samples_per_second': 167.578, 'eval_steps_per_second': 10.762, 'epoch': 3.0}\n",
      "2025-05-10 00:48:03,139 - INFO - Test results: {'eval_loss': 0.6644694209098816, 'eval_accuracy': 0.7064220183486238, 'eval_f1': 0.6912700646963953, 'eval_precision': 0.6767571962526091, 'eval_recall': 0.7064220183486238, 'eval_runtime': 1.2845, 'eval_samples_per_second': 169.71, 'eval_steps_per_second': 10.899, 'epoch': 3.0}\n",
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-10 00:48:03,137 - INFO - Model metrics saved to ./models/sesotho/metrics.json\n",
      "2025-05-10 00:48:03,138 - INFO - ============== RESULTS FOR Sesotho ==============\n",
      "2025-05-10 00:48:03,139 - INFO - Training loss: 0.5543\n",
      "2025-05-10 00:48:03,139 - INFO - Validation results: {'eval_loss': 0.5815077424049377, 'eval_accuracy': 0.7706422018348624, 'eval_f1': 0.758784555256037, 'eval_precision': 0.7473307497627334, 'eval_recall': 0.7706422018348624, 'eval_runtime': 1.3009, 'eval_samples_per_second': 167.578, 'eval_steps_per_second': 10.762, 'epoch': 3.0}\n",
      "2025-05-10 00:48:03,139 - INFO - Test results: {'eval_loss': 0.6644694209098816, 'eval_accuracy': 0.7064220183486238, 'eval_f1': 0.6912700646963953, 'eval_precision': 0.6767571962526091, 'eval_recall': 0.7064220183486238, 'eval_runtime': 1.2845, 'eval_samples_per_second': 169.71, 'eval_steps_per_second': 10.899, 'epoch': 3.0}\n",
      "2025-05-10 00:48:03,167 - INFO - \n",
      "==== FINE-TUNING COMPLETE ====\n",
      "2025-05-10 00:48:03,167 - INFO - \n",
      "==== FINE-TUNING COMPLETE ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset      | Acc (val)  | F1 (val)   | Acc (test) | F1 (test)  | Model Dir           \n",
      "Swahili      | 0.5210     | 0.4872     | 0.5348     | 0.5048     | ./models/swahili\n",
      "Portuguese   | 0.6193     | 0.6184     | 0.6319     | 0.6441     | ./models/portuguese\n",
      "Sesotho      | 0.7706     | 0.7588     | 0.7064     | 0.6913     | ./models/sesotho\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    swa_dataset = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "    logger.info(\"Successfully loaded Swahili dataset from HuggingFace Hub\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Swahili dataset: {e}\")\n",
    "    swa_dataset = None\n",
    "\n",
    "try:\n",
    "    por_dataset = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "    logger.info(\"Successfully loaded Portuguese dataset from HuggingFace Hub\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Portuguese dataset: {e}\")\n",
    "    por_dataset = None\n",
    "\n",
    "try:\n",
    "    sot_dataset = load_dataset(\"csv\", data_files={\"train\": \"./datasets/sotho-news/sotho_news_dataset.csv\"})\n",
    "    logger.info(\"Successfully loaded Sesotho dataset from CSV\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load Sesotho dataset: {e}\")\n",
    "    sot_dataset = None\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def finetune_and_evaluate(dataset_name, dataset, num_labels):\n",
    "    logger.info(f\"Starting fine-tuning for {dataset_name}\")\n",
    "\n",
    "    if dataset is None:\n",
    "        logger.error(f\"Dataset {dataset_name} is None, cannot proceed with fine-tuning\")\n",
    "        return None\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    model_save_dir = f\"./models/{dataset_name.lower()}\"\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        num_labels=num_labels\n",
    "    ).to(device)\n",
    "\n",
    "    logger.info(f\"Dataset {dataset_name} structure:\")\n",
    "    for split in dataset:\n",
    "        logger.info(f\"  - Split: {split}, Examples: {len(dataset[split])}\")\n",
    "        logger.info(f\"  - Features: {dataset[split].features}\")\n",
    "        logger.info(f\"  - Columns: {dataset[split].column_names}\")\n",
    "\n",
    "    text_column = None\n",
    "    label_column = None\n",
    "\n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\", \"headline\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in text_candidates:\n",
    "            if candidate in columns:\n",
    "                text_column = candidate\n",
    "                break\n",
    "        if text_column:\n",
    "            break\n",
    "\n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in label_candidates:\n",
    "            if candidate in columns:\n",
    "                label_column = candidate\n",
    "                break\n",
    "        if label_column:\n",
    "            break\n",
    "\n",
    "    logger.info(f\"For {dataset_name}, using text_column={text_column}, label_column={label_column}\")\n",
    "\n",
    "    if text_column is None:\n",
    "        for split in dataset:\n",
    "            for col in dataset[split].column_names:\n",
    "                if isinstance(dataset[split][col][0], str):\n",
    "                    text_column = col\n",
    "                    logger.info(f\"Using '{col}' as text column based on string data\")\n",
    "                    break\n",
    "            if text_column:\n",
    "                break\n",
    "\n",
    "    if text_column is None:\n",
    "        logger.error(f\"Could not identify a text column for {dataset_name}\")\n",
    "        return None\n",
    "\n",
    "    if label_column is None:\n",
    "        logger.error(f\"Could not identify a label column for {dataset_name}\")\n",
    "        return None\n",
    "\n",
    "    required_splits = [\"train\", \"validation\", \"test\"]\n",
    "    missing_splits = [split for split in required_splits if split not in dataset]\n",
    "\n",
    "    if missing_splits:\n",
    "        logger.info(f\"Creating missing splits: {missing_splits} for {dataset_name}\")\n",
    "        if \"train\" in dataset:\n",
    "            train_valid_test = {}\n",
    "\n",
    "            for split in dataset:\n",
    "                if split in required_splits:\n",
    "                    train_valid_test[split] = dataset[split]\n",
    "\n",
    "            if \"train\" in dataset and (\"validation\" not in train_valid_test or \"test\" not in train_valid_test):\n",
    "                if \"validation\" not in train_valid_test:\n",
    "                    if \"test\" not in train_valid_test:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                        test_valid_split = split_datasets[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = test_valid_split[\"train\"]\n",
    "                        train_valid_test[\"test\"] = test_valid_split[\"test\"]\n",
    "                    else:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = split_datasets[\"test\"]\n",
    "                else:\n",
    "                    split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                    train_valid_test[\"test\"] = split_datasets[\"test\"]\n",
    "\n",
    "            dataset = DatasetDict(train_valid_test)\n",
    "        else:\n",
    "            logger.error(f\"Dataset {dataset_name} has no train split and cannot create splits\")\n",
    "            return None\n",
    "\n",
    "    label_mapping = None\n",
    "    for split in dataset:\n",
    "        if isinstance(dataset[split][label_column][0], str):\n",
    "            all_labels = set()\n",
    "            for example in dataset[split][label_column]:\n",
    "                all_labels.add(example)\n",
    "\n",
    "            label_mapping = {label: i for i, label in enumerate(sorted(all_labels))}\n",
    "            logger.info(f\"Created label mapping for {dataset_name}: {label_mapping}\")\n",
    "            break\n",
    "\n",
    "    processed_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in dataset.items():\n",
    "        texts = split_dataset[text_column]\n",
    "\n",
    "        if label_mapping:\n",
    "            labels = [label_mapping[label] for label in split_dataset[label_column]]\n",
    "        else:\n",
    "            labels = []\n",
    "            for label in split_dataset[label_column]:\n",
    "                if isinstance(label, (int, np.integer)):\n",
    "                    labels.append(int(label))\n",
    "                elif isinstance(label, str):\n",
    "                    try:\n",
    "                        labels.append(int(label))\n",
    "                    except ValueError:\n",
    "                        logger.warning(f\"Unexpected string label found in {split_name}: {label}\")\n",
    "                        labels.append(0)\n",
    "                else:\n",
    "                    logger.warning(f\"Unexpected label type in {split_name}: {type(label)}\")\n",
    "                    labels.append(0)\n",
    "\n",
    "        processed_dataset[split_name] = Dataset.from_dict({\n",
    "            \"text\": texts,\n",
    "            \"label\": labels\n",
    "        })\n",
    "\n",
    "        logger.info(f\"Processed {split_name} split: {len(processed_dataset[split_name])} examples\")\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "        )\n",
    "\n",
    "    tokenized_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in processed_dataset.items():\n",
    "        tokenized_split = split_dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "        tokenized_dataset[split_name] = tokenized_split\n",
    "\n",
    "        logger.info(f\"Tokenized {split_name} split: {len(tokenized_split)} examples\")\n",
    "        logger.info(f\"Columns after tokenization: {tokenized_split.column_names}\")\n",
    "\n",
    "        for required_col in [\"input_ids\", \"attention_mask\", \"label\"]:\n",
    "            if required_col not in tokenized_split.column_names:\n",
    "                logger.error(f\"Required column {required_col} missing after tokenization\")\n",
    "                return None\n",
    "\n",
    "    model_output_dir = f\"./tmp_model_dir_{dataset_name}\"\n",
    "    if os.path.exists(model_output_dir):\n",
    "        shutil.rmtree(model_output_dir)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_output_dir,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./tmp_logs\",\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"no\",\n",
    "        save_steps=1000000,\n",
    "        eval_steps=100,\n",
    "        do_eval=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Starting fine-tuning {dataset_name} with {len(tokenized_dataset['train'])} examples\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            train_output = trainer.train()\n",
    "\n",
    "            training_loss = None\n",
    "            try:\n",
    "                if hasattr(train_output, \"metrics\") and \"loss\" in train_output.metrics:\n",
    "                    training_loss = train_output.metrics[\"loss\"]\n",
    "                elif isinstance(train_output, dict) and \"loss\" in train_output:\n",
    "                    training_loss = train_output[\"loss\"]\n",
    "\n",
    "                if training_loss is None and hasattr(trainer, \"state\"):\n",
    "                    if hasattr(trainer.state, \"log_history\") and trainer.state.log_history:\n",
    "                        for log in reversed(trainer.state.log_history):\n",
    "                            if \"loss\" in log:\n",
    "                                training_loss = log[\"loss\"]\n",
    "                                break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not extract training loss: {e}\")\n",
    "        except RuntimeError as e:\n",
    "            if \"PytorchStreamWriter failed writing file\" in str(e):\n",
    "                logger.warning(\"Caught PyTorch serialization error during training. Will proceed with model saving.\")\n",
    "\n",
    "            else:\n",
    "\n",
    "                raise\n",
    "\n",
    "        try:\n",
    "            model_path = os.path.join(model_save_dir, \"model.pt\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            logger.info(f\"Model saved to {model_path}\")\n",
    "        except RuntimeError as e:\n",
    "            if \"PytorchStreamWriter failed writing file\" in str(e):\n",
    "                logger.warning(f\"PyTorch serialization error when saving model state dict. Trying alternative method.\")\n",
    "\n",
    "                try:\n",
    "\n",
    "                    with open(model_path, 'wb') as f:\n",
    "                        torch.save(model.state_dict(), f, _use_new_zipfile_serialization=False)\n",
    "                    logger.info(f\"Model saved to {model_path} using legacy serialization\")\n",
    "                except Exception as e2:\n",
    "                    logger.error(f\"Failed to save model with alternative method: {e2}\")\n",
    "            else:\n",
    "\n",
    "                raise\n",
    "\n",
    "        tokenizer.save_pretrained(model_save_dir)\n",
    "        logger.info(f\"Tokenizer saved to {model_save_dir}\")\n",
    "\n",
    "        if label_mapping:\n",
    "            label_mapping_path = os.path.join(model_save_dir, \"label_mapping.json\")\n",
    "            with open(label_mapping_path, \"w\") as f:\n",
    "\n",
    "                json_mapping = {str(k): int(v) for k, v in label_mapping.items()}\n",
    "                json.dump(json_mapping, f, indent=2)\n",
    "            logger.info(f\"Label mapping saved to {label_mapping_path}\")\n",
    "\n",
    "        model_config = {\n",
    "            \"base_model\": \"bert-base-multilingual-cased\",\n",
    "            \"num_labels\": num_labels,\n",
    "            \"text_column\": text_column,\n",
    "            \"label_column\": label_column,\n",
    "            \"max_length\": 128,\n",
    "\n",
    "            \"dataset_name\": dataset_name,\n",
    "        }\n",
    "\n",
    "        config_path = os.path.join(model_save_dir, \"config.json\")\n",
    "        with open(config_path, \"w\") as f:\n",
    "            json.dump(model_config, f, indent=2)\n",
    "        logger.info(f\"Model config saved to {config_path}\")\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        logger.info(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "        logger.info(f\"Evaluating on validation set with {len(tokenized_dataset['validation'])} examples\")\n",
    "        validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"validation\"])\n",
    "\n",
    "        logger.info(f\"Evaluating on test set with {len(tokenized_dataset['test'])} examples\")\n",
    "        test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "\n",
    "\n",
    "        processed_validation = {}\n",
    "        for k, v in validation_results.items():\n",
    "            if isinstance(v, (int, float, str, bool)) or v is None:\n",
    "                processed_validation[k] = v\n",
    "            else:\n",
    "                processed_validation[k] = float(v)\n",
    "\n",
    "        processed_test = {}\n",
    "        for k, v in test_results.items():\n",
    "            if isinstance(v, (int, float, str, bool)) or v is None:\n",
    "                processed_test[k] = v\n",
    "            else:\n",
    "                processed_test[k] = float(v)\n",
    "\n",
    "        metrics = {\n",
    "            \"training_time\": float(training_time),\n",
    "            \"training_loss\": float(training_loss) if training_loss is not None else None,\n",
    "            \"validation_results\": processed_validation,\n",
    "            \"test_results\": processed_test,\n",
    "        }\n",
    "\n",
    "        metrics_path = os.path.join(model_save_dir, \"metrics.json\")\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        logger.info(f\"Model metrics saved to {metrics_path}\")\n",
    "\n",
    "        logger.info(f\"============== RESULTS FOR {dataset_name} ==============\")\n",
    "        logger.info(f\"Training loss: {training_loss}\")\n",
    "        logger.info(f\"Validation results: {validation_results}\")\n",
    "        logger.info(f\"Test results: {test_results}\")\n",
    "\n",
    "        return {\n",
    "            \"dataset\": dataset_name,\n",
    "            \"training_time\": training_time,\n",
    "            \"training_loss\": training_loss,\n",
    "            \"validation_results\": validation_results,\n",
    "            \"test_results\": test_results,\n",
    "            \"model_path\": model_path,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fine-tuning failed for {dataset_name}: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "available_datasets = []\n",
    "if swa_dataset:\n",
    "    available_datasets.append((\"Swahili\", swa_dataset, 3))\n",
    "if por_dataset:\n",
    "    available_datasets.append((\"Portuguese\", por_dataset, 3))\n",
    "if sot_dataset:\n",
    "    available_datasets.append((\"Sesotho\", sot_dataset, 3))\n",
    "\n",
    "logger.info(f\"Available datasets: {[name for name, _, _ in available_datasets]}\")\n",
    "\n",
    "all_results = []\n",
    "for dataset_name, dataset, num_labels in available_datasets:\n",
    "    logger.info(f\"\\n==== FINE-TUNING ON {dataset_name.upper()} DATASET ====\")\n",
    "    try:\n",
    "        results = finetune_and_evaluate(dataset_name, dataset, num_labels)\n",
    "\n",
    "        if results:\n",
    "            all_results.append(results)\n",
    "        else:\n",
    "            logger.warning(f\"No results returned for {dataset_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error during fine-tuning {dataset_name}: {e}\", exc_info=True)\n",
    "\n",
    "logger.info(\"\\n==== FINE-TUNING COMPLETE ====\")\n",
    "\n",
    "print(f\"{'Dataset':<12} | {'Acc (val)':<10} | {'F1 (val)':<10} | {'Acc (test)':<10} | {'F1 (test)':<10} | {'Model Dir':<20}\")\n",
    "\n",
    "for result in all_results:\n",
    "    dataset = result[\"dataset\"]\n",
    "    val_acc = result[\"validation_results\"].get(\"eval_accuracy\", float('nan'))\n",
    "    val_f1 = result[\"validation_results\"].get(\"eval_f1\", float('nan'))\n",
    "    test_acc = result[\"test_results\"].get(\"eval_accuracy\", float('nan'))\n",
    "    test_f1 = result[\"test_results\"].get(\"eval_f1\", float('nan'))\n",
    "    model_dir = f\"./models/{dataset.lower()}\"\n",
    "\n",
    "    print(f\"{dataset:<12} | {val_acc:<10.4f} | {val_f1:<10.4f} | {test_acc:<10.4f} | {test_f1:<10.4f} | {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ce925a960b9f",
   "metadata": {},
   "source": [
    "## XLM-RoBERTa\n",
    "### Baseline with [XLM-RoBERTa](https://huggingface.co/docs/transformers/en/model_doc/xlm-roberta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861fc298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 17392.59 examples/s]\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 16354.10 examples/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 17777.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/Documents/nlp-research/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/tmp/ipykernel_9357/4293509063.py:220: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 16823.59 examples/s]\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 16317.10 examples/s]\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 18763.37 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6/229 00:00 < 00:17, 12.97 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 217\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, dataset, num_labels \u001b[38;5;129;01min\u001b[39;00m available_datasets:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mget_benchmark_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[1;32m    220\u001b[0m             results_df \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39m_append({\n\u001b[1;32m    221\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset_name,\n\u001b[1;32m    222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLM-RoBERTa\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: results\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_recall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m             }, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 200\u001b[0m, in \u001b[0;36mget_benchmark_metrics\u001b[0;34m(dataset_name, dataset, num_labels)\u001b[0m\n\u001b[1;32m    193\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    194\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    195\u001b[0m     args\u001b[38;5;241m=\u001b[39meval_args,\n\u001b[1;32m    196\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m    197\u001b[0m )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     benchmark_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m benchmark_results\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/transformers/trainer.py:4173\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4170\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4172\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4173\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4174\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   4177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   4178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4181\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4183\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/transformers/trainer.py:4390\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4388\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   4389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4390\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4392\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:2813\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2781\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2782\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:403\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    405\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:673\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    670\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:126\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:653\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    650\u001b[0m     dim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    654\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gather(size)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import time\n",
    "\n",
    "run_timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "os.makedirs(\"./benchmark_results\", exist_ok=True)\n",
    "\n",
    "output_csv = os.path.abspath(f\"./benchmark_results/xlmroberta_benchmark_results_{run_timestamp}.csv\")\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    \"Dataset\", \"Model\", \"Loss\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\"\n",
    "])\n",
    "\n",
    "try:\n",
    "    swa_dataset = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "except Exception as e:\n",
    "    swa_dataset = None\n",
    "\n",
    "try:\n",
    "    por_dataset = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "except Exception as e:\n",
    "    por_dataset = None\n",
    "\n",
    "try:\n",
    "    sot_dataset = load_dataset(\"csv\", data_files={\"train\": \"./datasets/sotho-news/sotho_news_dataset.csv\"})\n",
    "except Exception as e:\n",
    "    sot_dataset = None\n",
    "    \n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def get_benchmark_metrics(dataset_name, dataset, num_labels):\n",
    "    \n",
    "    if dataset is None:\n",
    "        return None\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"xlm-roberta-base\", \n",
    "        num_labels=num_labels\n",
    "    ).to(device)\n",
    "    \n",
    "    text_column = None\n",
    "    label_column = None\n",
    "    \n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in text_candidates:\n",
    "            if candidate in columns:\n",
    "                text_column = candidate\n",
    "                break\n",
    "        if text_column:\n",
    "            break\n",
    "    \n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for split in dataset:\n",
    "        columns = dataset[split].column_names\n",
    "        for candidate in label_candidates:\n",
    "            if candidate in columns:\n",
    "                label_column = candidate\n",
    "                break\n",
    "        if label_column:\n",
    "            break\n",
    "    \n",
    "    if text_column is None:\n",
    "        for split in dataset:\n",
    "            for col in dataset[split].column_names:\n",
    "                if isinstance(dataset[split][col][0], str):\n",
    "                    text_column = col\n",
    "                    break\n",
    "            if text_column:\n",
    "                break\n",
    "    \n",
    "    if text_column is None:\n",
    "        return None\n",
    "    \n",
    "    if label_column is None:\n",
    "        return None\n",
    "    \n",
    "    required_splits = [\"train\", \"validation\", \"test\"]\n",
    "    missing_splits = [split for split in required_splits if split not in dataset]\n",
    "    \n",
    "    if missing_splits:\n",
    "        if \"train\" in dataset:\n",
    "            train_valid_test = {}\n",
    "            \n",
    "            for split in dataset:\n",
    "                if split in required_splits:\n",
    "                    train_valid_test[split] = dataset[split]\n",
    "            \n",
    "            if \"train\" in dataset and (\"validation\" not in train_valid_test or \"test\" not in train_valid_test):\n",
    "                if \"validation\" not in train_valid_test:\n",
    "                    if \"test\" not in train_valid_test:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                        test_valid_split = split_datasets[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = test_valid_split[\"train\"]\n",
    "                        train_valid_test[\"test\"] = test_valid_split[\"test\"]\n",
    "                    else:\n",
    "                        split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                        train_valid_test[\"train\"] = split_datasets[\"train\"]\n",
    "                        train_valid_test[\"validation\"] = split_datasets[\"test\"]\n",
    "                else:\n",
    "                    split_datasets = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "                    train_valid_test[\"test\"] = split_datasets[\"test\"]\n",
    "            \n",
    "            dataset = DatasetDict(train_valid_test)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    label_mapping = None\n",
    "    for split in dataset:\n",
    "        if isinstance(dataset[split][label_column][0], str):\n",
    "            all_labels = set()\n",
    "            for example in dataset[split][label_column]:\n",
    "                all_labels.add(example)\n",
    "            \n",
    "            label_mapping = {label: i for i, label in enumerate(sorted(all_labels))}\n",
    "            break\n",
    "    \n",
    "    processed_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in dataset.items():\n",
    "        texts = split_dataset[text_column]\n",
    "        \n",
    "        if label_mapping:\n",
    "            labels = [label_mapping[label] for label in split_dataset[label_column]]\n",
    "        else:\n",
    "            labels = []\n",
    "            for label in split_dataset[label_column]:\n",
    "                if isinstance(label, (int, np.integer)):\n",
    "                    labels.append(int(label))\n",
    "                elif isinstance(label, str):\n",
    "                    try:\n",
    "                        labels.append(int(label))\n",
    "                    except ValueError:\n",
    "                        labels.append(0)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "        \n",
    "        processed_dataset[split_name] = Dataset.from_dict({\n",
    "            \"text\": texts,\n",
    "            \"label\": labels\n",
    "        })\n",
    "        \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = DatasetDict()\n",
    "    for split_name, split_dataset in processed_dataset.items():\n",
    "        tokenized_split = split_dataset.map(\n",
    "            tokenize_function, \n",
    "            batched=True, \n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "        tokenized_dataset[split_name] = tokenized_split\n",
    "        \n",
    "        for required_col in [\"input_ids\", \"attention_mask\", \"label\"]:\n",
    "            if required_col not in tokenized_split.column_names:\n",
    "                return None\n",
    "    \n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=f\"./benchmark_results/{dataset_name}_{run_timestamp}\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        logging_dir=f\"./benchmark_results/{dataset_name}_{run_timestamp}/logs\",\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=True\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=eval_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        benchmark_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "        \n",
    "        return benchmark_results\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "available_datasets = []\n",
    "if swa_dataset:\n",
    "    available_datasets.append((\"Swahili\", swa_dataset, 3))\n",
    "if por_dataset:\n",
    "    available_datasets.append((\"Portuguese\", por_dataset, 3))\n",
    "if sot_dataset:\n",
    "    available_datasets.append((\"Sesotho\", sot_dataset, 3))\n",
    "\n",
    "all_results = []\n",
    "for dataset_name, dataset, num_labels in available_datasets:\n",
    "    try:\n",
    "        results = get_benchmark_metrics(dataset_name, dataset, num_labels)\n",
    "        \n",
    "        if results:\n",
    "            results_df = results_df._append({\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"Model\": \"XLM-RoBERTa\",\n",
    "                \"Loss\": results.get(\"eval_loss\"),\n",
    "                \"Accuracy\": results.get(\"eval_accuracy\"),\n",
    "                \"F1\": results.get(\"eval_f1\"),\n",
    "                \"Precision\": results.get(\"eval_precision\"),\n",
    "                \"Recall\": results.get(\"eval_recall\")\n",
    "            }, ignore_index=True)\n",
    "            \n",
    "            all_results.append({\"Dataset\": dataset_name, \"Results\": results})\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "except Exception as e:\n",
    "    emergency_path = f\"./emergency_results_{run_timestamp}.csv\"\n",
    "    results_df.to_csv(emergency_path, index=False)\n",
    "\n",
    "print(\"\\n==== BENCHMARKING COMPLETE ====\")\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4acb5",
   "metadata": {},
   "source": [
    "# mBERT finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b847f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 16792.59 examples/s]\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 17723.32 examples/s]\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 17146.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='383' max='383' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [383/383 01:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.992800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.940400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.895200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.860800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='554' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 15729.31 examples/s]\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 14378.84 examples/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 11588.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='227' max='227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [227/227 00:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.942600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.946300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.893600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='151' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINE-TUNING RESULTS SUMMARY =====\n",
      "Dataset         | Val Loss   | Val Acc    | Val F1     | Test Loss  | Test Acc   | Test F1    | Path                          \n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "Portuguese      | 0.8324     | 0.6076     | 0.5962     | 0.7996     | 0.6458     | 0.6462     | ./models/portuguese           \n",
      "Swahili         | 0.9038     | 0.5916     | 0.4398     | 0.9009     | 0.5936     | 0.4422     | ./models/swahili              \n",
      "\n",
      "Fine-tuning complete. Models and metrics saved to respective ./models/[language_name] directories.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "def load_datasets():\n",
    "    datasets = {}\n",
    "    \n",
    "    try:\n",
    "        datasets[\"Portuguese\"] = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        datasets[\"Swahili\"] = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    sotho_csv_path = \"datasets/sotho-news/sotho_news_dataset.csv\"\n",
    "    if os.path.exists(sotho_csv_path):\n",
    "        try:\n",
    "            sotho_dataset_raw = load_dataset(\"csv\", data_files={\"train\": sotho_csv_path})\n",
    "            if \"train\" in sotho_dataset_raw and \"validation\" not in sotho_dataset_raw:\n",
    "                train_test_split = sotho_dataset_raw[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                test_valid_split = train_test_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                datasets[\"Sotho\"] = DatasetDict({\n",
    "                    \"train\": train_test_split[\"train\"],\n",
    "                    \"validation\": test_valid_split[\"train\"],\n",
    "                    \"test\": test_valid_split[\"test\"]    \n",
    "                })\n",
    "            else: \n",
    "                datasets[\"Sotho\"] = sotho_dataset_raw\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def preprocess_dataset(dataset, dataset_name):\n",
    "    text_column = None\n",
    "    label_column = None\n",
    "\n",
    "    if \"train\" not in dataset or not dataset[\"train\"]:\n",
    "        return None, None, 0\n",
    "\n",
    "    train_columns = dataset[\"train\"].column_names\n",
    "\n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\", \"headline\"]\n",
    "    for candidate in text_candidates:\n",
    "        if candidate in train_columns:\n",
    "            text_column = candidate\n",
    "            break\n",
    "\n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for candidate in label_candidates:\n",
    "        if candidate in train_columns:\n",
    "            label_column = candidate\n",
    "            break\n",
    "\n",
    "    if text_column is None: \n",
    "        for col in train_columns:\n",
    "            if col != label_column and len(dataset[\"train\"][col]) > 0 and isinstance(dataset[\"train\"][col][0], str):\n",
    "                text_column = col\n",
    "                break\n",
    "\n",
    "    if text_column is None or label_column is None:\n",
    "        return None, None, 0\n",
    "\n",
    "    label_mapping = None\n",
    "    num_labels = 0\n",
    "\n",
    "    processed_dataset = DatasetDict()\n",
    "    all_final_labels_in_dataset = set()\n",
    "\n",
    "    unique_raw_labels_across_splits = set()\n",
    "    first_label_example = None\n",
    "    for split_name in dataset:\n",
    "        if len(dataset[split_name]) > 0:\n",
    "            unique_raw_labels_across_splits.update(dataset[split_name][label_column])\n",
    "            if first_label_example is None:\n",
    "                first_label_example = dataset[split_name][label_column][0]\n",
    "\n",
    "    if not unique_raw_labels_across_splits:\n",
    "        return None, None, 0\n",
    "\n",
    "    if isinstance(first_label_example, str):\n",
    "        sorted_unique_raw_labels = sorted(list(str(label) for label in unique_raw_labels_across_splits))\n",
    "        label_mapping = {label: i for i, label in enumerate(sorted_unique_raw_labels)}\n",
    "        num_labels = len(label_mapping)\n",
    "    else: \n",
    "        numeric_labels_set = set()\n",
    "        valid_numeric_labels_found = False\n",
    "        for label_val in unique_raw_labels_across_splits:\n",
    "            try:\n",
    "                numeric_labels_set.add(int(label_val))\n",
    "                valid_numeric_labels_found = True\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "        if not valid_numeric_labels_found:\n",
    "            return None, None, 0\n",
    "\n",
    "        sorted_numeric_labels = sorted(list(numeric_labels_set))\n",
    "        num_labels = len(sorted_numeric_labels)\n",
    "\n",
    "        needs_remapping = not (\n",
    "            sorted_numeric_labels[0] == 0 and\n",
    "            sorted_numeric_labels[-1] == num_labels - 1 and\n",
    "            len(sorted_numeric_labels) == (sorted_numeric_labels[-1] - sorted_numeric_labels[0] + 1 if num_labels > 0 else 0)\n",
    "        )\n",
    "\n",
    "        if needs_remapping and num_labels > 0:\n",
    "            label_mapping = {str(orig_label): i for i, orig_label in enumerate(sorted_numeric_labels)}\n",
    "\n",
    "    if num_labels == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    for split_name, split_data in dataset.items():\n",
    "        if len(split_data) == 0: \n",
    "            processed_dataset[split_name] = Dataset.from_dict({\"text\": [], \"label\": []}) \n",
    "            continue\n",
    "\n",
    "        texts = split_data[text_column]\n",
    "        final_labels_for_split = []\n",
    "\n",
    "        current_split_labels = split_data[label_column]\n",
    "        if label_mapping: \n",
    "            for label in current_split_labels:\n",
    "                try:\n",
    "                    final_labels_for_split.append(label_mapping[str(label)])\n",
    "                except KeyError:\n",
    "                    return None, None, 0 \n",
    "        else: \n",
    "            for label in current_split_labels:\n",
    "                try:\n",
    "                    final_labels_for_split.append(int(label))\n",
    "                except (ValueError, TypeError):\n",
    "                    final_labels_for_split.append(0) \n",
    "\n",
    "        processed_dataset[split_name] = Dataset.from_dict({\"text\": texts, \"label\": final_labels_for_split})\n",
    "        all_final_labels_in_dataset.update(final_labels_for_split)\n",
    "\n",
    "    if not all_final_labels_in_dataset and num_labels > 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    if num_labels == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    return processed_dataset, label_mapping, num_labels\n",
    "\n",
    "\n",
    "def finetune_model(dataset_name, dataset):\n",
    "    model_save_dir = f\"./models/{dataset_name.lower().replace(' ', '_')}\"\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "    processed_dataset, label_mapping, num_labels_from_data = preprocess_dataset(dataset, dataset_name)\n",
    "\n",
    "    if processed_dataset is None:\n",
    "        return None\n",
    "    if num_labels_from_data == 0:\n",
    "        return None\n",
    "      \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "    try:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"bert-base-multilingual-cased\",\n",
    "            num_labels=num_labels_from_data,\n",
    "            problem_type=\"single_label_classification\" if num_labels_from_data > 1 else None\n",
    "        ).to(device)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        valid_splits = {k: v for k, v in processed_dataset.items() if len(v) > 0}\n",
    "        if not valid_splits:\n",
    "            return None\n",
    "\n",
    "        tokenized_dataset = DatasetDict(valid_splits).map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    if \"train\" not in tokenized_dataset or len(tokenized_dataset[\"train\"]) == 0:\n",
    "        return None\n",
    "\n",
    "    eval_split_name = None\n",
    "    if \"validation\" in tokenized_dataset and len(tokenized_dataset[\"validation\"]) > 0:\n",
    "        eval_split_name = \"validation\"\n",
    "    elif \"test\" in tokenized_dataset and len(tokenized_dataset[\"test\"]) > 0:\n",
    "        eval_split_name = \"test\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./tmp/{dataset_name.lower().replace(' ', '_')}\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"./logs/{dataset_name.lower().replace(' ', '_')}\",\n",
    "        logging_steps=50 if len(tokenized_dataset[\"train\"]) > 50*8 else len(tokenized_dataset[\"train\"]) // (8 * 10) + 1,\n",
    "        save_steps=len(tokenized_dataset[\"train\"]) // 8, \n",
    "        eval_steps=len(tokenized_dataset[\"train\"]) // 8 if eval_split_name else 9999999,\n",
    "        do_eval=True if eval_split_name else False,\n",
    "        metric_for_best_model=\"f1\" if eval_split_name else None,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[eval_split_name] if eval_split_name else None,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    validation_results = {}\n",
    "\n",
    "    if \"validation\" in tokenized_dataset and len(tokenized_dataset[\"validation\"]) > 0:\n",
    "        validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"validation\"])\n",
    "    elif eval_split_name == \"test\":\n",
    "        best_metric_value = trainer.state.best_metric\n",
    "        best_model_checkpoint = trainer.state.best_model_checkpoint\n",
    "     \n",
    "        for log in reversed(trainer.state.log_history):\n",
    "            if 'eval_loss' in log and eval_split_name == 'test': \n",
    "                if self.args.metric_for_best_model and f\"eval_{self.args.metric_for_best_model}\" in log and log[f\"eval_{self.args.metric_for_best_model}\"] == best_metric_value:\n",
    "                    validation_results = {k: v for k, v in log.items() if k.startswith(\"eval_\")}\n",
    "                    break\n",
    "        if not validation_results and best_metric_value :\n",
    "            validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "\n",
    "    test_results = {}\n",
    "    if \"test\" in tokenized_dataset and len(tokenized_dataset[\"test\"]) > 0:\n",
    "        test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "    else:\n",
    "        if eval_split_name == \"test\": \n",
    "            test_results = validation_results \n",
    "\n",
    "    trainer.save_model(model_save_dir)\n",
    "\n",
    "    if label_mapping:\n",
    "        with open(os.path.join(model_save_dir, \"label_mapping.json\"), \"w\") as f:\n",
    "            json.dump(label_mapping, f, indent=2)\n",
    "\n",
    "    config_to_save = {\"num_labels\": num_labels_from_data}\n",
    "    with open(os.path.join(model_save_dir, \"custom_config.json\"), \"w\") as f:\n",
    "        json.dump(config_to_save, f, indent=2)\n",
    "\n",
    "    metrics = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"num_train_examples\": len(tokenized_dataset[\"train\"]),\n",
    "        \"num_eval_examples\": len(tokenized_dataset[eval_split_name]) if eval_split_name else 0,\n",
    "        \"num_test_examples\": len(tokenized_dataset[\"test\"]) if \"test\" in tokenized_dataset else 0,\n",
    "        \"validation_results\": validation_results,\n",
    "        \"test_results\": test_results, \n",
    "        \"best_model_metric_value\": trainer.state.best_metric if eval_split_name else None,\n",
    "        \"best_model_checkpoint\": trainer.state.best_model_checkpoint if eval_split_name else None,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(model_save_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2, default=lambda o: str(o) if isinstance(o, (np.floating, np.integer)) else o) \n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"model_save_dir\": model_save_dir,\n",
    "        \"validation_results\": validation_results,\n",
    "        \"test_results\": test_results\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    datasets_to_process = load_datasets()\n",
    "\n",
    "    results = []\n",
    " \n",
    "    for dataset_name, dataset_obj in datasets_to_process.items():\n",
    "        if not dataset_obj :\n",
    "            continue\n",
    "        if \"train\" not in dataset_obj or not dataset_obj[\"train\"]: \n",
    "             continue\n",
    "        try:\n",
    "            result = finetune_model(dataset_name, dataset_obj)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if not results:\n",
    "        return\n",
    "\n",
    "    print(\"\\n===== FINE-TUNING RESULTS SUMMARY =====\")\n",
    "    header = f\"{'Dataset':<15} | {'Val Loss':<10} | {'Val Acc':<10} | {'Val F1':<10} | {'Test Loss':<10} | {'Test Acc':<10} | {'Test F1':<10} | {'Path':<30}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for result in results:\n",
    "        dataset_name = result[\"dataset\"]\n",
    "        model_path = result[\"model_save_dir\"]\n",
    "        val_metrics = result.get(\"validation_results\", {})\n",
    "        test_metrics = result.get(\"test_results\", {})\n",
    "\n",
    "        val_loss = val_metrics.get(\"eval_loss\", float('nan'))\n",
    "        val_acc = val_metrics.get(\"eval_accuracy\", float('nan'))\n",
    "        val_f1 = val_metrics.get(\"eval_f1\", float('nan'))\n",
    "        test_loss = test_metrics.get(\"eval_loss\", float('nan'))\n",
    "        test_acc = test_metrics.get(\"eval_accuracy\", float('nan'))\n",
    "        test_f1 = test_metrics.get(\"eval_f1\", float('nan'))\n",
    "\n",
    "        print(f\"{dataset_name:<15} | {val_loss:<10.4f} | {val_acc:<10.4f} | {val_f1:<10.4f} | {test_loss:<10.4f} | {test_acc:<10.4f} | {test_f1:<10.4f} | {model_path:<30}\")\n",
    "\n",
    "    print(\"\\nFine-tuning complete. Models and metrics saved to respective ./models/[language_name] directories.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641549a",
   "metadata": {},
   "source": [
    "# XLMR finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a61452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 18537.44 examples/s]\n",
      "Map: 100%|██████████| 767/767 [00:00<00:00, 18354.09 examples/s]\n",
      "Map: 100%|██████████| 3662/3662 [00:00<00:00, 21178.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='383' max='383' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [383/383 01:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.080100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.991500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.963400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='554' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1810/1810 [00:00<00:00, 19267.81 examples/s]\n",
      "Map: 100%|██████████| 453/453 [00:00<00:00, 18816.92 examples/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 19769.87 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='227' max='227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [227/227 01:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.951900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.953200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.992700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.912200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='151' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })\n",
      "\n",
      "===== FINE-TUNING RESULTS SUMMARY =====\n",
      "Dataset         | Val Loss   | Val Acc    | Val F1     | Test Loss  | Test Acc   | Test F1    | Path                          \n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "Portuguese      | 0.9133     | 0.5567     | 0.4631     | 0.8261     | 0.6529     | 0.5814     | ./models/portuguese           \n",
      "\n",
      "Fine-tuning complete. Models and metrics saved to respective ./models/[language_name] directories.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "def load_datasets():\n",
    "    datasets = {}\n",
    "\n",
    "    try:\n",
    "        datasets[\"Portuguese\"] = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        datasets[\"Swahili\"] = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    sotho_csv_path = \"datasets/sotho-news/sotho_news_dataset.csv\"\n",
    "    if os.path.exists(sotho_csv_path):\n",
    "        try:\n",
    "            sotho_dataset_raw = load_dataset(\"csv\", data_files={\"train\": sotho_csv_path})\n",
    "            if \"train\" in sotho_dataset_raw and \"validation\" not in sotho_dataset_raw:\n",
    "                train_test_split = sotho_dataset_raw[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                test_valid_split = train_test_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                datasets[\"Sotho\"] = DatasetDict({\n",
    "                    \"train\": train_test_split[\"train\"],\n",
    "                    \"validation\": test_valid_split[\"train\"],\n",
    "                    \"test\": test_valid_split[\"test\"]    \n",
    "                })\n",
    "            else: \n",
    "                datasets[\"Sotho\"] = sotho_dataset_raw\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def preprocess_dataset(dataset, dataset_name):\n",
    "    text_column = None\n",
    "    label_column = None\n",
    "\n",
    "    if \"train\" not in dataset or not dataset[\"train\"]:\n",
    "        return None, None, 0\n",
    "\n",
    "    train_columns = dataset[\"train\"].column_names\n",
    "\n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\", \"headline\"]\n",
    "    for candidate in text_candidates:\n",
    "        if candidate in train_columns:\n",
    "            text_column = candidate\n",
    "            break\n",
    "\n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for candidate in label_candidates:\n",
    "        if candidate in train_columns:\n",
    "            label_column = candidate\n",
    "            break\n",
    "\n",
    "    if text_column is None: \n",
    "        for col in train_columns:\n",
    "            if col != label_column and len(dataset[\"train\"][col]) > 0 and isinstance(dataset[\"train\"][col][0], str):\n",
    "                text_column = col\n",
    "                break\n",
    "\n",
    "    if text_column is None or label_column is None:\n",
    "        return None, None, 0\n",
    "\n",
    "    label_mapping = None\n",
    "    num_labels = 0\n",
    "\n",
    "    processed_dataset = DatasetDict()\n",
    "    all_final_labels_in_dataset = set()\n",
    "\n",
    "    unique_raw_labels_across_splits = set()\n",
    "    first_label_example = None\n",
    "    for split_name in dataset:\n",
    "        if len(dataset[split_name]) > 0:\n",
    "            unique_raw_labels_across_splits.update(dataset[split_name][label_column])\n",
    "            if first_label_example is None:\n",
    "                first_label_example = dataset[split_name][label_column][0]\n",
    "\n",
    "    if not unique_raw_labels_across_splits:\n",
    "        return None, None, 0\n",
    "\n",
    "    if isinstance(first_label_example, str):\n",
    "        sorted_unique_raw_labels = sorted(list(str(label) for label in unique_raw_labels_across_splits))\n",
    "        label_mapping = {label: i for i, label in enumerate(sorted_unique_raw_labels)}\n",
    "        num_labels = len(label_mapping)\n",
    "    else: \n",
    "        numeric_labels_set = set()\n",
    "        valid_numeric_labels_found = False\n",
    "        for label_val in unique_raw_labels_across_splits:\n",
    "            try:\n",
    "                numeric_labels_set.add(int(label_val))\n",
    "                valid_numeric_labels_found = True\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "        if not valid_numeric_labels_found:\n",
    "            return None, None, 0\n",
    "\n",
    "        sorted_numeric_labels = sorted(list(numeric_labels_set))\n",
    "        num_labels = len(sorted_numeric_labels)\n",
    "\n",
    "        needs_remapping = not (\n",
    "            sorted_numeric_labels[0] == 0 and\n",
    "            sorted_numeric_labels[-1] == num_labels - 1 and\n",
    "            len(sorted_numeric_labels) == (sorted_numeric_labels[-1] - sorted_numeric_labels[0] + 1 if num_labels > 0 else 0)\n",
    "        )\n",
    "\n",
    "        if needs_remapping and num_labels > 0:\n",
    "            label_mapping = {str(orig_label): i for i, orig_label in enumerate(sorted_numeric_labels)}\n",
    "\n",
    "    if num_labels == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    for split_name, split_data in dataset.items():\n",
    "        if len(split_data) == 0: \n",
    "            processed_dataset[split_name] = Dataset.from_dict({\"text\": [], \"label\": []}) \n",
    "            continue\n",
    "\n",
    "        texts = split_data[text_column]\n",
    "        final_labels_for_split = []\n",
    "\n",
    "        current_split_labels = split_data[label_column]\n",
    "        if label_mapping: \n",
    "            for label in current_split_labels:\n",
    "                try:\n",
    "                    final_labels_for_split.append(label_mapping[str(label)])\n",
    "                except KeyError:\n",
    "                    return None, None, 0 \n",
    "        else: \n",
    "            for label in current_split_labels:\n",
    "                try:\n",
    "                    final_labels_for_split.append(int(label))\n",
    "                except (ValueError, TypeError):\n",
    "                    final_labels_for_split.append(0) \n",
    "\n",
    "        processed_dataset[split_name] = Dataset.from_dict({\"text\": texts, \"label\": final_labels_for_split})\n",
    "        all_final_labels_in_dataset.update(final_labels_for_split)\n",
    "\n",
    "    if not all_final_labels_in_dataset and num_labels > 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    if num_labels == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    return processed_dataset, label_mapping, num_labels\n",
    "\n",
    "\n",
    "def finetune_model(dataset_name, dataset):\n",
    "    model_save_dir = f\"./models/{dataset_name.lower().replace(' ', '_')}\"\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "    processed_dataset, label_mapping, num_labels_from_data = preprocess_dataset(dataset, dataset_name)\n",
    "\n",
    "    if processed_dataset is None:\n",
    "        return None\n",
    "    if num_labels_from_data == 0:\n",
    "        return None\n",
    "      \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "    try:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"xlm-roberta-base\",\n",
    "            num_labels=num_labels_from_data,\n",
    "            problem_type=\"single_label_classification\" if num_labels_from_data > 1 else None\n",
    "        ).to(device)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256 \n",
    "        )\n",
    "\n",
    "    try:\n",
    "        valid_splits = {k: v for k, v in processed_dataset.items() if len(v) > 0}\n",
    "        if not valid_splits:\n",
    "            return None\n",
    "\n",
    "        tokenized_dataset = DatasetDict(valid_splits).map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    if \"train\" not in tokenized_dataset or len(tokenized_dataset[\"train\"]) == 0:\n",
    "        return None\n",
    "\n",
    "    eval_split_name = None\n",
    "    if \"validation\" in tokenized_dataset and len(tokenized_dataset[\"validation\"]) > 0:\n",
    "        eval_split_name = \"validation\"\n",
    "    elif \"test\" in tokenized_dataset and len(tokenized_dataset[\"test\"]) > 0:\n",
    "        eval_split_name = \"test\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./tmp/{dataset_name.lower().replace(' ', '_')}\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"./logs/{dataset_name.lower().replace(' ', '_')}\",\n",
    "        logging_steps=50 if len(tokenized_dataset[\"train\"]) > 50*8 else len(tokenized_dataset[\"train\"]) // (8 * 10) + 1,\n",
    "        save_steps=len(tokenized_dataset[\"train\"]) // 8, \n",
    "        eval_steps=len(tokenized_dataset[\"train\"]) // 8 if eval_split_name else 9999999,\n",
    "        do_eval=True if eval_split_name else False,\n",
    "        metric_for_best_model=\"f1\" if eval_split_name else None,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[eval_split_name] if eval_split_name else None,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    validation_results = {}\n",
    "\n",
    "    if \"validation\" in tokenized_dataset and len(tokenized_dataset[\"validation\"]) > 0:\n",
    "        validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"validation\"])\n",
    "    elif eval_split_name == \"test\":\n",
    "        best_metric_value = trainer.state.best_metric\n",
    "        best_model_checkpoint = trainer.state.best_model_checkpoint\n",
    "     \n",
    "        for log in reversed(trainer.state.log_history):\n",
    "            if 'eval_loss' in log and eval_split_name == 'test': \n",
    "                if self.args.metric_for_best_model and f\"eval_{self.args.metric_for_best_model}\" in log and log[f\"eval_{self.args.metric_for_best_model}\"] == best_metric_value:\n",
    "                    validation_results = {k: v for k, v in log.items() if k.startswith(\"eval_\")}\n",
    "                    break\n",
    "        if not validation_results and best_metric_value :\n",
    "            validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "\n",
    "    test_results = {}\n",
    "    if \"test\" in tokenized_dataset and len(tokenized_dataset[\"test\"]) > 0:\n",
    "        test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "    else:\n",
    "        if eval_split_name == \"test\": \n",
    "            test_results = validation_results \n",
    "\n",
    "    trainer.save_model(model_save_dir)\n",
    "\n",
    "    if label_mapping:\n",
    "        with open(os.path.join(model_save_dir, \"label_mapping.json\"), \"w\") as f:\n",
    "            json.dump(label_mapping, f, indent=2)\n",
    "\n",
    "    config_to_save = {\"num_labels\": num_labels_from_data}\n",
    "    with open(os.path.join(model_save_dir, \"custom_config.json\"), \"w\") as f:\n",
    "        json.dump(config_to_save, f, indent=2)\n",
    "\n",
    "    metrics = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"num_train_examples\": len(tokenized_dataset[\"train\"]),\n",
    "        \"num_eval_examples\": len(tokenized_dataset[eval_split_name]) if eval_split_name else 0,\n",
    "        \"num_test_examples\": len(tokenized_dataset[\"test\"]) if \"test\" in tokenized_dataset else 0,\n",
    "        \"validation_results\": validation_results,\n",
    "        \"test_results\": test_results, \n",
    "        \"best_model_metric_value\": trainer.state.best_metric if eval_split_name else None,\n",
    "        \"best_model_checkpoint\": trainer.state.best_model_checkpoint if eval_split_name else None,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(model_save_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2, default=lambda o: str(o) if isinstance(o, (np.floating, np.integer)) else o) \n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"model_save_dir\": model_save_dir,\n",
    "        \"validation_results\": validation_results,\n",
    "        \"test_results\": test_results\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    datasets_to_process = load_datasets()\n",
    "\n",
    "    results = []\n",
    " \n",
    "    for dataset_name, dataset_obj in datasets_to_process.items():\n",
    "        if not dataset_obj :\n",
    "            continue\n",
    "        if \"train\" not in dataset_obj or not dataset_obj[\"train\"]: \n",
    "             continue\n",
    "        try:\n",
    "            result = finetune_model(dataset_name, dataset_obj)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if not results:\n",
    "        return\n",
    "\n",
    "    print(\"\\n===== FINE-TUNING RESULTS SUMMARY =====\")\n",
    "    header = f\"{'Dataset':<15} | {'Val Loss':<10} | {'Val Acc':<10} | {'Val F1':<10} | {'Test Loss':<10} | {'Test Acc':<10} | {'Test F1':<10} | {'Path':<30}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for result in results:\n",
    "        dataset_name = result[\"dataset\"]\n",
    "        model_path = result[\"model_save_dir\"]\n",
    "        val_metrics = result.get(\"validation_results\", {})\n",
    "        test_metrics = result.get(\"test_results\", {})\n",
    "\n",
    "        val_loss = val_metrics.get(\"eval_loss\", float('nan'))\n",
    "        val_acc = val_metrics.get(\"eval_accuracy\", float('nan'))\n",
    "        val_f1 = val_metrics.get(\"eval_f1\", float('nan'))\n",
    "        test_loss = test_metrics.get(\"eval_loss\", float('nan'))\n",
    "        test_acc = test_metrics.get(\"eval_accuracy\", float('nan'))\n",
    "        test_f1 = test_metrics.get(\"eval_f1\", float('nan'))\n",
    "\n",
    "        print(f\"{dataset_name:<15} | {val_loss:<10.4f} | {val_acc:<10.4f} | {val_f1:<10.4f} | {test_loss:<10.4f} | {test_acc:<10.4f} | {test_f1:<10.4f} | {model_path:<30}\")\n",
    "\n",
    "    print(\"\\nFine-tuning complete. Models and metrics saved to respective ./models/[language_name] directories.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eaa432",
   "metadata": {},
   "source": [
    "# Afro-XLMR finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f605ff1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/datasets/masakhane/afrisenti/resolve/eb42667d2e83d0081864767b47681fbaf00144fb/afrisenti.py",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/datasets/load.py:1580\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1580\u001b[0m     dataset_script_path \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _require_custom_configs \u001b[38;5;129;01mor\u001b[39;00m (revision \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:5475\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5473\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5478\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5487\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5491\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1024\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1484\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 309\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:420\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    419\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(EntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-685332b8-2b296a230c3be13157f439ca;1040a8ea-69f3-42e8-8d9e-994a5a641cff)\n\nEntry Not Found for url: https://huggingface.co/datasets/masakhane/afrisenti/resolve/eb42667d2e83d0081864767b47681fbaf00144fb/afrisenti.py.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 385\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal successful fine-tuning runs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 322\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m--> 322\u001b[0m     datasets_to_process \u001b[38;5;241m=\u001b[39m \u001b[43mload_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m datasets_to_process:\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo datasets loaded. Please check your data files and internet connection.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m, in \u001b[0;36mload_datasets\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPortuguese\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmasakhane/afrisenti\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading Portuguese dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/datasets/load.py:2062\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2058\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2059\u001b[0m )\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2062\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/datasets/load.py:1782\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1781\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1782\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/datasets/load.py:1629\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1620\u001b[0m         use_exported_dataset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithoutScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1631\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/datasets/load.py:978\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mdownload_desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading standalone yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 978\u001b[0m     standalone_yaml_path \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_dataset_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREPOYAML_FILENAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(standalone_yaml_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    983\u001b[0m         standalone_yaml_data \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(f\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/datasets/utils/file_utils.py:191\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mHfFileSystem(\n\u001b[1;32m    188\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT, token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m    189\u001b[0m )\u001b[38;5;241m.\u001b[39mresolve_path(url_or_filename)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHF_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_datasets_user_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    206\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRepositoryNotFoundError,\n\u001b[1;32m    207\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mEntryNotFoundError,\n\u001b[1;32m    208\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRevisionNotFoundError,\n\u001b[1;32m    209\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGatedRepoError,\n\u001b[1;32m    210\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:5475\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5472\u001b[0m     \u001b[38;5;66;03m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[1;32m   5473\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5478\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5487\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5491\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    943\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1024\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1483\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1484\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1489\u001b[0m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1398\u001b[0m hf_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:308\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Documents/nlp-research/.venv/lib/python3.10/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "def load_datasets():\n",
    "    datasets = {}\n",
    "\n",
    "    try:\n",
    "        datasets[\"Portuguese\"] = load_dataset(\"masakhane/afrisenti\", \"por\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Portuguese dataset: {e}\")\n",
    "\n",
    "    try:\n",
    "        datasets[\"Swahili\"] = load_dataset(\"masakhane/afrisenti\", \"swa\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Swahili dataset: {e}\")\n",
    "\n",
    "    sotho_csv_path = \"datasets/sotho-news/sotho_news_dataset.csv\"\n",
    "    if os.path.exists(sotho_csv_path):\n",
    "        try:\n",
    "            sotho_dataset_raw = load_dataset(\"csv\", data_files={\"train\": sotho_csv_path})\n",
    "            if \"train\" in sotho_dataset_raw and \"validation\" not in sotho_dataset_raw:\n",
    "                train_test_split = sotho_dataset_raw[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "                test_valid_split = train_test_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "                datasets[\"Sotho\"] = DatasetDict({\n",
    "                    \"train\": train_test_split[\"train\"],\n",
    "                    \"validation\": test_valid_split[\"train\"],\n",
    "                    \"test\": test_valid_split[\"test\"]    \n",
    "                })\n",
    "            else: \n",
    "                datasets[\"Sotho\"] = sotho_dataset_raw\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Sotho dataset: {e}\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def preprocess_dataset(dataset, dataset_name):\n",
    "    text_column = None\n",
    "    label_column = None\n",
    "\n",
    "    if \"train\" not in dataset or not dataset[\"train\"]:\n",
    "        return None, None, 0\n",
    "\n",
    "    train_columns = dataset[\"train\"].column_names\n",
    "\n",
    "    text_candidates = [\"text\", \"content\", \"tweet\", \"sentence\", \"document\", \"headline\"]\n",
    "    for candidate in text_candidates:\n",
    "        if candidate in train_columns:\n",
    "            text_column = candidate\n",
    "            break\n",
    "\n",
    "    label_candidates = [\"label\", \"sentiment\", \"class\", \"category\"]\n",
    "    for candidate in label_candidates:\n",
    "        if candidate in train_columns:\n",
    "            label_column = candidate\n",
    "            break\n",
    "\n",
    "    if text_column is None: \n",
    "        for col in train_columns:\n",
    "            if col != label_column and len(dataset[\"train\"][col]) > 0 and isinstance(dataset[\"train\"][col][0], str):\n",
    "                text_column = col\n",
    "                break\n",
    "\n",
    "    if text_column is None or label_column is None:\n",
    "        return None, None, 0\n",
    "\n",
    "    label_mapping = None\n",
    "    num_labels = 0\n",
    "\n",
    "    processed_dataset = DatasetDict()\n",
    "    all_final_labels_in_dataset = set()\n",
    "\n",
    "    unique_raw_labels_across_splits = set()\n",
    "    first_label_example = None\n",
    "    for split_name in dataset:\n",
    "        if len(dataset[split_name]) > 0:\n",
    "            unique_raw_labels_across_splits.update(dataset[split_name][label_column])\n",
    "            if first_label_example is None:\n",
    "                first_label_example = dataset[split_name][label_column][0]\n",
    "\n",
    "    if not unique_raw_labels_across_splits:\n",
    "        return None, None, 0\n",
    "\n",
    "    if isinstance(first_label_example, str):\n",
    "        sorted_unique_raw_labels = sorted(list(str(label) for label in unique_raw_labels_across_splits))\n",
    "        label_mapping = {label: i for i, label in enumerate(sorted_unique_raw_labels)}\n",
    "        num_labels = len(label_mapping)\n",
    "    else: \n",
    "        numeric_labels_set = set()\n",
    "        valid_numeric_labels_found = False\n",
    "        for label_val in unique_raw_labels_across_splits:\n",
    "            try:\n",
    "                numeric_labels_set.add(int(label_val))\n",
    "                valid_numeric_labels_found = True\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "        if not valid_numeric_labels_found:\n",
    "            return None, None, 0\n",
    "\n",
    "        sorted_numeric_labels = sorted(list(numeric_labels_set))\n",
    "        num_labels = len(sorted_numeric_labels)\n",
    "\n",
    "        needs_remapping = not (\n",
    "            sorted_numeric_labels[0] == 0 and\n",
    "            sorted_numeric_labels[-1] == num_labels - 1 and\n",
    "            len(sorted_numeric_labels) == (sorted_numeric_labels[-1] - sorted_numeric_labels[0] + 1 if num_labels > 0 else 0)\n",
    "        )\n",
    "\n",
    "        if needs_remapping and num_labels > 0:\n",
    "            label_mapping = {str(orig_label): i for i, orig_label in enumerate(sorted_numeric_labels)}\n",
    "\n",
    "    if num_labels == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    for split_name, split_data in dataset.items():\n",
    "        if len(split_data) == 0: \n",
    "            processed_dataset[split_name] = Dataset.from_dict({\"text\": [], \"label\": []}) \n",
    "            continue\n",
    "\n",
    "        texts = split_data[text_column]\n",
    "        final_labels_for_split = []\n",
    "\n",
    "        current_split_labels = split_data[label_column]\n",
    "        if label_mapping: \n",
    "            for label in current_split_labels:\n",
    "                try:\n",
    "                    final_labels_for_split.append(label_mapping[str(label)])\n",
    "                except KeyError:\n",
    "                    return None, None, 0 \n",
    "        else: \n",
    "            for label in current_split_labels:\n",
    "                try:\n",
    "                    final_labels_for_split.append(int(label))\n",
    "                except (ValueError, TypeError):\n",
    "                    final_labels_for_split.append(0) \n",
    "\n",
    "        processed_dataset[split_name] = Dataset.from_dict({\"text\": texts, \"label\": final_labels_for_split})\n",
    "        all_final_labels_in_dataset.update(final_labels_for_split)\n",
    "\n",
    "    if not all_final_labels_in_dataset and num_labels > 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    if num_labels == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    return processed_dataset, label_mapping, num_labels\n",
    "\n",
    "\n",
    "def finetune_model(dataset_name, dataset, model_name=\"Davlan/afro-xlmr-base\"):\n",
    "    model_save_dir = f\"./models/{dataset_name.lower().replace(' ', '_')}_afroxlmr\"\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "    processed_dataset, label_mapping, num_labels_from_data = preprocess_dataset(dataset, dataset_name)\n",
    "\n",
    "    if processed_dataset is None:\n",
    "        print(f\"Failed to preprocess dataset {dataset_name}\")\n",
    "        return None\n",
    "    if num_labels_from_data == 0:\n",
    "        print(f\"No valid labels found in dataset {dataset_name}\")\n",
    "        return None\n",
    "      \n",
    "    print(f\"Loading AfroXLMR model: {model_name}\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels_from_data,\n",
    "            problem_type=\"single_label_classification\" if num_labels_from_data > 1 else None\n",
    "        ).to(device)\n",
    "        print(f\"Successfully loaded {model_name} with {num_labels_from_data} labels\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256 \n",
    "        )\n",
    "\n",
    "    try:\n",
    "        valid_splits = {k: v for k, v in processed_dataset.items() if len(v) > 0}\n",
    "        if not valid_splits:\n",
    "            print(f\"No valid splits found for dataset {dataset_name}\")\n",
    "            return None\n",
    "\n",
    "        tokenized_dataset = DatasetDict(valid_splits).map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=[\"text\"]\n",
    "        )\n",
    "        print(f\"Successfully tokenized dataset with splits: {list(tokenized_dataset.keys())}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error tokenizing dataset {dataset_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"train\" not in tokenized_dataset or len(tokenized_dataset[\"train\"]) == 0:\n",
    "        print(f\"No training data found for dataset {dataset_name}\")\n",
    "        return None\n",
    "\n",
    "    eval_split_name = None\n",
    "    if \"validation\" in tokenized_dataset and len(tokenized_dataset[\"validation\"]) > 0:\n",
    "        eval_split_name = \"validation\"\n",
    "    elif \"test\" in tokenized_dataset and len(tokenized_dataset[\"test\"]) > 0:\n",
    "        eval_split_name = \"test\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./tmp/{dataset_name.lower().replace(' ', '_')}_afroxlmr\",\n",
    "        learning_rate=2e-5,  \n",
    "        per_device_train_batch_size=16,  \n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3, \n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=500,  \n",
    "        logging_dir=f\"./logs/{dataset_name.lower().replace(' ', '_')}_afroxlmr\",\n",
    "        logging_steps=50 if len(tokenized_dataset[\"train\"]) > 50*16 else len(tokenized_dataset[\"train\"]) // (16 * 10) + 1,\n",
    "        save_steps=len(tokenized_dataset[\"train\"]) // 16, \n",
    "        eval_steps=len(tokenized_dataset[\"train\"]) // 16 if eval_split_name else 9999999,\n",
    "        evaluation_strategy=\"steps\" if eval_split_name else \"no\",\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True if eval_split_name else False,\n",
    "        metric_for_best_model=\"f1\" if eval_split_name else None,\n",
    "        greater_is_better=True if eval_split_name else None,\n",
    "        report_to=\"none\",\n",
    "        save_total_limit=2,  \n",
    "        dataloader_pin_memory=False,  \n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[eval_split_name] if eval_split_name else None,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting training for {dataset_name}...\")\n",
    "    try:\n",
    "        trainer.train()\n",
    "        print(f\"Training completed for {dataset_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training for {dataset_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "    validation_results = {}\n",
    "    test_results = {}\n",
    "\n",
    "    if \"validation\" in tokenized_dataset and len(tokenized_dataset[\"validation\"]) > 0:\n",
    "        print(f\"Evaluating on validation set for {dataset_name}...\")\n",
    "        validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"validation\"])\n",
    "\n",
    "    if \"test\" in tokenized_dataset and len(tokenized_dataset[\"test\"]) > 0:\n",
    "        print(f\"Evaluating on test set for {dataset_name}...\")\n",
    "        test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "    elif eval_split_name == \"test\": \n",
    "        test_results = validation_results \n",
    "\n",
    "    print(f\"Saving model for {dataset_name}...\")\n",
    "    trainer.save_model(model_save_dir)\n",
    "    tokenizer.save_pretrained(model_save_dir)\n",
    "\n",
    "    if label_mapping:\n",
    "        with open(os.path.join(model_save_dir, \"label_mapping.json\"), \"w\") as f:\n",
    "            json.dump(label_mapping, f, indent=2)\n",
    "\n",
    "    config_to_save = {\n",
    "        \"num_labels\": num_labels_from_data,\n",
    "        \"model_name\": model_name,\n",
    "        \"dataset_name\": dataset_name\n",
    "    }\n",
    "    with open(os.path.join(model_save_dir, \"custom_config.json\"), \"w\") as f:\n",
    "        json.dump(config_to_save, f, indent=2)\n",
    "\n",
    "    metrics = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"model_name\": model_name,\n",
    "        \"num_train_examples\": len(tokenized_dataset[\"train\"]),\n",
    "        \"num_eval_examples\": len(tokenized_dataset[eval_split_name]) if eval_split_name else 0,\n",
    "        \"num_test_examples\": len(tokenized_dataset[\"test\"]) if \"test\" in tokenized_dataset else 0,\n",
    "        \"validation_results\": validation_results,\n",
    "        \"test_results\": test_results, \n",
    "        \"best_model_metric_value\": trainer.state.best_metric if eval_split_name else None,\n",
    "        \"best_model_checkpoint\": trainer.state.best_model_checkpoint if eval_split_name else None,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(model_save_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2, default=lambda o: str(o) if isinstance(o, (np.floating, np.integer)) else o) \n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"model_name\": model_name,\n",
    "        \"model_save_dir\": model_save_dir,\n",
    "        \"validation_results\": validation_results,\n",
    "        \"test_results\": test_results\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    datasets_to_process = load_datasets()\n",
    "    \n",
    "    if not datasets_to_process:\n",
    "        print(\"No datasets loaded. Please check your data files and internet connection.\")\n",
    "        return\n",
    "\n",
    "    model_name = \"Davlan/afro-xlmr-base\"  \n",
    "    print(f\"Using model: {model_name}\")\n",
    "\n",
    "    results = []\n",
    " \n",
    "    for dataset_name, dataset_obj in datasets_to_process.items():\n",
    "        if not dataset_obj:\n",
    "            print(f\"Skipping {dataset_name}: dataset is None\")\n",
    "            continue\n",
    "        if \"train\" not in dataset_obj or not dataset_obj[\"train\"]: \n",
    "            print(f\"Skipping {dataset_name}: no training data\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing dataset: {dataset_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            result = finetune_model(dataset_name, dataset_obj, model_name)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "                print(f\"Successfully completed fine-tuning for {dataset_name}\")\n",
    "            else:\n",
    "                print(f\"Failed to fine-tune {dataset_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {dataset_name}: {e}\")\n",
    "\n",
    "    if not results:\n",
    "        print(\"No successful fine-tuning results.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"AFROXLMR FINE-TUNING RESULTS SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    header = f\"{'Dataset':<15} | {'Model':<25} | {'Val Loss':<10} | {'Val Acc':<10} | {'Val F1':<10} | {'Test Loss':<10} | {'Test Acc':<10} | {'Test F1':<10}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for result in results:\n",
    "        dataset_name = result[\"dataset\"]\n",
    "        model_name = result[\"model_name\"].split(\"/\")[-1]  \n",
    "        val_metrics = result.get(\"validation_results\", {})\n",
    "        test_metrics = result.get(\"test_results\", {})\n",
    "\n",
    "        val_loss = val_metrics.get(\"eval_loss\", float('nan'))\n",
    "        val_acc = val_metrics.get(\"eval_accuracy\", float('nan'))\n",
    "        val_f1 = val_metrics.get(\"eval_f1\", float('nan'))\n",
    "        test_loss = test_metrics.get(\"eval_loss\", float('nan'))\n",
    "        test_acc = test_metrics.get(\"eval_accuracy\", float('nan'))\n",
    "        test_f1 = test_metrics.get(\"eval_f1\", float('nan'))\n",
    "\n",
    "        print(f\"{dataset_name:<15} | {model_name:<25} | {val_loss:<10.4f} | {val_acc:<10.4f} | {val_f1:<10.4f} | {test_loss:<10.4f} | {test_acc:<10.4f} | {test_f1:<10.4f}\")\n",
    "\n",
    "    print(f\"\\nFine-tuning complete! Models saved to ./models/[dataset_name]_afroxlmr directories.\")\n",
    "    print(f\"Total successful fine-tuning runs: {len(results)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73b1e1",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5242ae",
   "metadata": {},
   "source": [
    "Firstly, we want to check the actual distribution of the classes for Mozambican Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f7e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Swahili (swa) dataset from disk...\n",
      "Swahili dataset loaded!\n",
      "Loading Portuguese (por) dataset from disk...\n",
      "Portuguese dataset loaded!\n",
      "Loading Sesotho (sot) dataset from disk...\n",
      "Sesotho dataset loaded!\n",
      "Portuguese dataset size: 3063 examples\n",
      "Dataset features: {'tweet': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
      "\n",
      "Sample entry:\n",
      "{'tweet': 'Pedi uma resposta a Deus, ele deu me. Estou muito triste com ela. Mas mais tarde sei que vou entender.', 'label': 'negative'}\n",
      "\n",
      "Sentiment Distribution:\n",
      "Negative: 782 (25.53%)\n",
      "Neutral: 1600 (52.24%)\n",
      "Positive: 681 (22.23%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk, load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_sentiment_distribution(dataset, split='train'):\n",
    "    \"\"\"Analyze sentiment distribution in a dataset with string labels.\"\"\"\n",
    "    if dataset is None:\n",
    "        return\n",
    "    \n",
    "    # Count the occurrences of each sentiment label\n",
    "    label_counts = Counter(dataset[split]['label'])\n",
    "    \n",
    "    # Print the distribution\n",
    "    print(f\"\\nSentiment Distribution:\")\n",
    "    total = len(dataset[split])\n",
    "    \n",
    "    # Sort labels in a meaningful order: negative, neutral, positive\n",
    "    ordered_labels = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    for label in ordered_labels:\n",
    "        if label in label_counts:\n",
    "            count = label_counts[label]\n",
    "            percentage = (count / total) * 100\n",
    "            # Capitalize first letter for display\n",
    "            display_label = label.capitalize()\n",
    "            print(f\"{display_label}: {count} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Check for any other labels not in our expected list\n",
    "    for label, count in label_counts.items():\n",
    "        if label not in ordered_labels:\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"Other ({label}): {count} ({percentage:.2f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    swa, por, sot = load_local_datasets()\n",
    "\n",
    "    if por is not None:\n",
    "        print(f\"Portuguese dataset size: {len(por['train'])} examples\")\n",
    "        print(f\"Dataset features: {por['train'].features}\")\n",
    "        print(\"\\nSample entry:\")\n",
    "        print(por['train'][0])\n",
    "        analyze_sentiment_distribution(por)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60be43",
   "metadata": {},
   "source": [
    "### There is a clear imbalance in the classes and so data augmentation techniques will be used such as dropout and back-translation in order to create synthetic data for the minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243185bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Swahili (swa) dataset from disk...\n",
      "Swahili dataset loaded!\n",
      "Loading Portuguese (por) dataset from disk...\n",
      "Portuguese dataset loaded!\n",
      "Loading Sesotho (sot) dataset from disk...\n",
      "Sesotho dataset loaded!\n",
      "Original Portuguese dataset:\n",
      "\n",
      "Sentiment Distribution:\n",
      "Negative: 782 (25.53%)\n",
      "Neutral: 1600 (52.24%)\n",
      "Positive: 681 (22.23%)\n",
      "\n",
      "After balancing and augmentation:\n",
      "\n",
      "Sentiment Distribution:\n",
      "Negative: 1120 (33.33%)\n",
      "Neutral: 1120 (33.33%)\n",
      "Positive: 1120 (33.33%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 3360/3360 [00:00<00:00, 660056.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced and augmented dataset saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from datasets import load_from_disk, load_dataset, Dataset\n",
    "from collections import Counter\n",
    "\n",
    "def load_local_datasets():\n",
    "    swa_path = \"./datasets/afrisenti/swa\"\n",
    "    por_path = \"./datasets/afrisenti/por\"\n",
    "    sot_path = \"./datasets/news\"\n",
    "\n",
    "    if not all(os.path.exists(path) for path in [swa_path, por_path, sot_path]):\n",
    "        print(\"One or more dataset directories not found. Please check the paths.\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(\"Loading Swahili (swa) dataset from disk...\")\n",
    "    swa_dataset = load_from_disk(swa_path)\n",
    "    print(\"Swahili dataset loaded!\")\n",
    "\n",
    "    print(\"Loading Portuguese (por) dataset from disk...\")\n",
    "    por_dataset = load_from_disk(por_path)\n",
    "    print(\"Portuguese dataset loaded!\")\n",
    "\n",
    "    print(\"Loading Sesotho (sot) dataset from disk...\")\n",
    "    sot_dataset = load_dataset(\"csv\", data_files=\"datasets/sotho-news/sotho_news_dataset.csv\")\n",
    "    print(\"Sesotho dataset loaded!\")\n",
    "\n",
    "    return swa_dataset, por_dataset, sot_dataset\n",
    "\n",
    "def analyze_sentiment_distribution(dataset, split='train'):\n",
    "    \"\"\"Analyze sentiment distribution in a dataset with string labels.\"\"\"\n",
    "    if dataset is None:\n",
    "        return\n",
    "    \n",
    "    # Check if this is a Dataset object with splits or just a simple Dataset\n",
    "    if split in dataset:\n",
    "        # This is a dataset with splits\n",
    "        data = dataset[split]\n",
    "    else:\n",
    "        # This is a simple Dataset without splits\n",
    "        data = dataset\n",
    "    \n",
    "    # Count the occurrences of each sentiment label\n",
    "    label_counts = Counter(data['label'])\n",
    "    \n",
    "    # Print the distribution\n",
    "    print(f\"\\nSentiment Distribution:\")\n",
    "    total = len(data)\n",
    "    \n",
    "    # Sort labels in a meaningful order: negative, neutral, positive\n",
    "    ordered_labels = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    for label in ordered_labels:\n",
    "        if label in label_counts:\n",
    "            count = label_counts[label]\n",
    "            percentage = (count / total) * 100\n",
    "            # Capitalize first letter for display\n",
    "            display_label = label.capitalize()\n",
    "            print(f\"{display_label}: {count} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Check for any other labels not in our expected list\n",
    "    for label, count in label_counts.items():\n",
    "        if label not in ordered_labels:\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"Other ({label}): {count} ({percentage:.2f}%)\")\n",
    "\n",
    "def simple_augment_text(text):\n",
    "    \"\"\"Simple text augmentation without relying on translation models\"\"\"\n",
    "    augmentation_techniques = [\n",
    "        lambda t: word_deletion(t, p=0.1),\n",
    "        lambda t: word_swap(t, p=0.1),\n",
    "        lambda t: add_punctuation(t)\n",
    "    ]\n",
    "    \n",
    "    # Randomly select an augmentation technique\n",
    "    technique = random.choice(augmentation_techniques)\n",
    "    return technique(text)\n",
    "\n",
    "def word_deletion(text, p=0.1):\n",
    "    \"\"\"Randomly delete words with probability p\"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) <= 3:  # Don't delete from very short texts\n",
    "        return text\n",
    "        \n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if random.random() > p:  # Keep the word with probability (1-p)\n",
    "            new_words.append(word)\n",
    "    \n",
    "    # Ensure we don't delete all words\n",
    "    if not new_words:\n",
    "        return random.choice(words)\n",
    "        \n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def word_swap(text, p=0.1):\n",
    "    \"\"\"Randomly swap adjacent words with probability p\"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) <= 1:\n",
    "        return text\n",
    "        \n",
    "    for i in range(len(words) - 1):\n",
    "        if random.random() < p:\n",
    "            words[i], words[i+1] = words[i+1], words[i]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "def add_punctuation(text):\n",
    "    \"\"\"Add or modify punctuation without changing meaning\"\"\"\n",
    "    # Add emphasis for positive/negative texts\n",
    "    if text[-1] not in '!?.':\n",
    "        if random.random() < 0.5:\n",
    "            text += '!'\n",
    "        else:\n",
    "            text += '.'\n",
    "    elif text[-1] == '.' and random.random() < 0.3:\n",
    "        text = text[:-1] + '!'\n",
    "    \n",
    "    return text\n",
    "\n",
    "def balance_and_augment_dataset(dataset, target_neutral_ratio=0.7, split='train'):\n",
    "    \"\"\"\n",
    "    Balance and augment dataset:\n",
    "    1. Undersample neutral class\n",
    "    2. Augment negative and positive classes using simple techniques\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each label\n",
    "    label_counts = {}\n",
    "    for label in ['negative', 'neutral', 'positive']:\n",
    "        label_counts[label] = sum(1 for l in dataset[split]['label'] if l == label)\n",
    "    \n",
    "    # Separate data by label\n",
    "    data_by_label = {\n",
    "        'negative': [],\n",
    "        'neutral': [],\n",
    "        'positive': []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(dataset[split])):\n",
    "        label = dataset[split][i]['label']\n",
    "        data_by_label[label].append({\n",
    "            'tweet': dataset[split][i]['tweet'],\n",
    "            'label': label\n",
    "        })\n",
    "    \n",
    "    # Undersample neutral class\n",
    "    neutral_target_size = int(label_counts['neutral'] * target_neutral_ratio)\n",
    "    sampled_neutral = random.sample(data_by_label['neutral'], neutral_target_size)\n",
    "    \n",
    "    # Prepare balanced data with originals\n",
    "    balanced_data = data_by_label['negative'] + sampled_neutral + data_by_label['positive']\n",
    "    \n",
    "    # Augment minority classes\n",
    "    augmented_data = balanced_data.copy()\n",
    "    \n",
    "    # Target count for each class after balancing\n",
    "    target_count = max(len(data_by_label['negative']), len(data_by_label['positive']), neutral_target_size)\n",
    "    \n",
    "    # Augment negative class\n",
    "    negative_to_add = target_count - len(data_by_label['negative'])\n",
    "    if negative_to_add > 0:\n",
    "        # Select samples to augment (can select the same sample multiple times)\n",
    "        for _ in range(negative_to_add):\n",
    "            sample = random.choice(data_by_label['negative'])\n",
    "            augmented_tweet = simple_augment_text(sample['tweet'])\n",
    "            augmented_data.append({'tweet': augmented_tweet, 'label': 'negative'})\n",
    "    \n",
    "    # Augment positive class\n",
    "    positive_to_add = target_count - len(data_by_label['positive'])\n",
    "    if positive_to_add > 0:\n",
    "        for _ in range(positive_to_add):\n",
    "            sample = random.choice(data_by_label['positive'])\n",
    "            augmented_tweet = simple_augment_text(sample['tweet'])\n",
    "            augmented_data.append({'tweet': augmented_tweet, 'label': 'positive'})\n",
    "    \n",
    "    # Shuffle the augmented data\n",
    "    random.shuffle(augmented_data)\n",
    "    \n",
    "    # Return the augmented data directly (not as a Dataset object)\n",
    "    return augmented_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    swa, por, sot = load_local_datasets()\n",
    "    \n",
    "    if por is not None:\n",
    "        print(\"Original Portuguese dataset:\")\n",
    "        analyze_sentiment_distribution(por)\n",
    "        \n",
    "        # Balance and augment dataset\n",
    "        augmented_data = balance_and_augment_dataset(por)\n",
    "        \n",
    "        # Create a new dataset from the augmented data\n",
    "        augmented_dataset = Dataset.from_dict({\n",
    "            'tweet': [item['tweet'] for item in augmented_data],\n",
    "            'label': [item['label'] for item in augmented_data]\n",
    "        })\n",
    "        \n",
    "        print(\"\\nAfter balancing and augmentation:\")\n",
    "        analyze_sentiment_distribution(augmented_dataset)  # Now analyzing the dataset directly\n",
    "        \n",
    "        # Create a dataset with splits for saving\n",
    "        full_dataset_with_splits = {\"train\": augmented_dataset}\n",
    "        full_dataset = Dataset.from_dict({\n",
    "            'train': augmented_dataset\n",
    "        })\n",
    "        \n",
    "        # Save the balanced and augmented dataset\n",
    "        full_dataset.save_to_disk(\"./datasets/afrisenti/por_balanced_augmented\")\n",
    "        print(\"\\nBalanced and augmented dataset saved!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcb0dc",
   "metadata": {},
   "source": [
    "These text augmentation techniques (word deletion, word swap, punctuation changes) are more appropriate for Mozambican Portuguese since they don't rely on external translation models that might not understand the dialect. They preserve the unique characteristics of Mozambican Portuguese while still creating useful variations of the original text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70a400",
   "metadata": {},
   "source": [
    "Now let's see if there is any improvement when training the best performing BERT model on the Mozambican Portuguese data which was Afro-XLMR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U transformers datasets peft evaluate plotly sentencepiece --quiet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from datasets import load_dataset\n",
    "# import torch_optimizer as optim\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(language):\n",
    "    try:\n",
    "        aug_por_path = \"./datasets/afrisenti/por_balanced_augmented\"\n",
    "\n",
    "        if language=='por':\n",
    "            chosen_dataset=load_from_disk(aug_por_path)\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        for ds in [chosen_dataset]: # Change to all three later\n",
    "            for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "                if ds[lbl].column_names[0]== \"tweet\":\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "                else:\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "\n",
    "        train_df  = chosen_dataset[\"train\"].to_pandas()\n",
    "        val_df  = chosen_dataset[\"validation\"].to_pandas()\n",
    "        test_df  = chosen_dataset[\"test\"].to_pandas()\n",
    "        logger.info(f\"Data loaded successfully: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test examples\")\n",
    "        return train_df, val_df, test_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Function to create DataLoaders\n",
    "def create_data_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, text_column='text', label_column='label'):\n",
    "    train_dataset = SentimentDataset(\n",
    "        texts=train_df[text_column].tolist(),\n",
    "        labels=train_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        texts=val_df[text_column].tolist(),\n",
    "        labels=val_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        texts=test_df[text_column].tolist(),\n",
    "        labels=test_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Tuple of (loss, accuracy, precision, recall, f1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, class_names):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_afro_xlmr_for_lang(language):\n",
    "    config = {\n",
    "        'model_name': 'Davlan/afro-xlmr-base',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    logger.info(f\"Loading model: {config['model_name']}...\")\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['model_name'])\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=config['num_labels']\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{language}')\n",
    "\n",
    "    # Create data loaders\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column']\n",
    "    )\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=config['warmup_steps'],\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    logger.info(\"Starting training...\")\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        logger.info(f\"Epoch {epoch + 1}/{config['epochs']}\")\n",
    "\n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_loader,optimizer,scheduler, device) # train_epoch(model, train_loader, scheduler, device)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1} results:\")\n",
    "        logger.info(f\"Train Loss: {train_loss:.4f}, Time: {train_time:.2f}s\")\n",
    "        logger.info(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            logger.info(f\"New best model with F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Load best model for testing\n",
    "    if best_model_state:\n",
    "        logger.info(\"Loading best model for testing...\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Test evaluation\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{language}_augmented.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Save model\n",
    "    logger.info(\"Saving model...\")\n",
    "    model_save_path = f'./xmlr_sentiment_model_{language}_augmented'\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    logger.info(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# evaluate_afro_xlmr()\n",
    "langs = ['por']\n",
    "\n",
    "for l in langs:\n",
    "    evaluate_afro_xlmr_for_lang(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e22688a4e23ce",
   "metadata": {},
   "source": [
    "## Next, we evaluate the use of Adapters to perform cross-lingual transfer\n",
    "This section will explore the effect of Adapters on model performance when doing cross-lingual transfer. This evaluation will use the Afroxlmr model, because it had the highest accuracy when analysing the Swahili data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd40eb40cd09c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T18:42:10.467789Z",
     "start_time": "2025-06-18T18:00:20.448207Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-18 20:00:28,239 - INFO - Loading model: ./xmlr_sentiment_model_swa...\n",
      "2025-06-18 20:00:30,479 - INFO - Adding head 'default' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}, 'use_pooler': False, 'bias': True, 'dropout_prob': None}.\n",
      "Some weights of XLMRobertaAdapterModel were not initialized from the model checkpoint at ./xmlr_sentiment_model_swa and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-06-18 20:00:30,568 - INFO - Successfully loaded as AutoAdapterModel\n",
      "2025-06-18 20:00:30,569 - INFO - Adding adapter 'lang_swa'.\n",
      "2025-06-18 20:00:30,631 - INFO - Added source language adapter: lang_swa\n",
      "2025-06-18 20:00:30,631 - INFO - Adding adapter 'lang_sot'.\n",
      "2025-06-18 20:00:30,696 - INFO - Added target language adapter: lang_sot\n",
      "2025-06-18 20:00:30,696 - INFO - Adding adapter 'sentiment_task'.\n",
      "2025-06-18 20:00:30,716 - INFO - Adding head 'sentiment_task' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'negative': 0, 'neutral': 1, 'positive': 2}, 'use_pooler': False, 'bias': True, 'dropout_prob': None}.\n",
      "2025-06-18 20:00:30,716 - INFO - Loading source data...\n",
      "2025-06-18 20:00:33,664 - INFO - Data loaded successfully: 1810 training, 453 validation, 748 test examples\n",
      "2025-06-18 20:00:33,665 - INFO - Creating data loaders...\n",
      "2025-06-18 20:00:33,668 - INFO - Loading target data...\n",
      "2025-06-18 20:00:40,564 - INFO - Data loaded successfully: 1740 training, 349 validation, 349 test examples\n",
      "2025-06-18 20:00:40,565 - INFO - Creating data loaders...\n",
      "2025-06-18 20:00:40,571 - INFO - Phase 1: Training source language + task adapters...\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\adapters\\composition.py:243: FutureWarning: Passing list objects for adapter activation is deprecated. Please use Stack or Fuse explicitly.\n",
      "  warnings.warn(\n",
      "2025-06-18 20:00:40,573 - WARNING - There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequential cross-lingual training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Source Epoch 1/3: 100%|██████████| 114/114 [06:29<00:00,  3.42s/it, loss=0.32] \n",
      "2025-06-18 20:07:10,391 - INFO - Source Epoch 1: Average Loss = 0.7161\n",
      "2025-06-18 20:07:36,907 - INFO - Source Epoch 1: Validation Accuracy = 0.0172\n",
      "Source Epoch 2/3: 100%|██████████| 114/114 [06:29<00:00,  3.42s/it, loss=0.428]\n",
      "2025-06-18 20:14:06,397 - INFO - Source Epoch 2: Average Loss = 0.5928\n",
      "2025-06-18 20:14:32,277 - INFO - Source Epoch 2: Validation Accuracy = 0.0172\n",
      "Source Epoch 3/3: 100%|██████████| 114/114 [06:28<00:00,  3.41s/it, loss=0.107]\n",
      "2025-06-18 20:21:00,716 - INFO - Source Epoch 3: Average Loss = 0.5571\n",
      "2025-06-18 20:21:26,970 - INFO - Source Epoch 3: Validation Accuracy = 0.0172\n",
      "2025-06-18 20:21:26,971 - INFO - Phase 2: Training target language adapter...\n",
      "Target Epoch 1/3: 100%|██████████| 109/109 [06:08<00:00,  3.38s/it, loss=1.21] \n",
      "2025-06-18 20:27:35,475 - INFO - Target Epoch 1: Average Loss = 1.1552\n",
      "2025-06-18 20:28:01,304 - INFO - Target Epoch 1: Validation Accuracy = 0.7135\n",
      "Target Epoch 2/3: 100%|██████████| 109/109 [06:18<00:00,  3.48s/it, loss=0.605]\n",
      "2025-06-18 20:34:20,202 - INFO - Target Epoch 2: Average Loss = 0.8313\n",
      "2025-06-18 20:34:46,323 - INFO - Target Epoch 2: Validation Accuracy = 0.7135\n",
      "Target Epoch 3/3: 100%|██████████| 109/109 [06:16<00:00,  3.45s/it, loss=0.553]\n",
      "2025-06-18 20:41:02,508 - INFO - Target Epoch 3: Average Loss = 0.7600\n",
      "2025-06-18 20:41:28,044 - INFO - Target Epoch 3: Validation Accuracy = 0.7135\n",
      "2025-06-18 20:41:28,046 - INFO - Attempting to save model and tokenizer\n",
      "2025-06-18 20:41:39,841 - INFO - Evaluating on test set...\n",
      "Evaluating: 100%|██████████| 22/22 [00:30<00:00,  1.39s/it]\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-06-18 20:42:10,383 - INFO - Test Results:\n",
      "2025-06-18 20:42:10,384 - INFO - Loss: 0.7058\n",
      "2025-06-18 20:42:10,384 - INFO - Accuracy: 0.7393\n",
      "2025-06-18 20:42:10,385 - INFO - Precision: 0.5465\n",
      "2025-06-18 20:42:10,386 - INFO - Recall: 0.7393\n",
      "2025-06-18 20:42:10,386 - INFO - F1 Score: 0.6284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to afroxlmr_results_sot_adapters.csv\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U transformers datasets peft evaluate plotly sentencepiece adapters adapter-transformers --quiet\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "from adapters import AutoAdapterModel,AdapterConfig\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128, lang=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.lang = lang\n",
    "        if self.lang=='sot':\n",
    "            self.label_mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}  # Label conversion\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        if self.lang=='sot':\n",
    "            label = self.label_mapping[self.labels[idx]]\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(language):\n",
    "    try:\n",
    "        if language=='por':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"por\",trust_remote_code=True)\n",
    "        elif language=='swa':\n",
    "            chosen_dataset=load_dataset(\"HausaNLP/AfriSenti-Twitter\", \"swa\",trust_remote_code=True)\n",
    "        elif language=='sot':\n",
    "            chosen_dataset=load_dataset(\"hamza-student-123/nlp-assignment-news-data\",'sot')\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        for ds in [chosen_dataset]: # Change to all three later\n",
    "            for lbl in [\"train\",\"validation\",\"test\"]:\n",
    "                if ds[lbl].column_names[0]== \"tweet\":\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"tweet\",\"text\")\n",
    "                else:\n",
    "                    ds[lbl] = ds[lbl].rename_column(\"headline\",\"text\")\n",
    "\n",
    "        train_df  = chosen_dataset[\"train\"].to_pandas()\n",
    "        val_df  = chosen_dataset[\"validation\"].to_pandas()\n",
    "        test_df  = chosen_dataset[\"test\"].to_pandas()\n",
    "        logger.info(f\"Data loaded successfully: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test examples\")\n",
    "        return train_df, val_df, test_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def create_data_loaders(train_df, val_df, test_df, tokenizer, batch_size=16, text_column='text', label_column='label', lang=None):\n",
    "    train_dataset = SentimentDataset(\n",
    "        texts=train_df[text_column].tolist(),\n",
    "        labels=train_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        lang=lang\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        texts=val_df[text_column].tolist(),\n",
    "        labels=val_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        lang=lang\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        texts=test_df[text_column].tolist(),\n",
    "        labels=test_df[label_column].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        lang=lang\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "def setup_crosslingual_adapters(config, source_language, target_language):\n",
    "\n",
    "    logger.info(f\"Loading model: {config['model_name']}...\")\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['extern_model_name'])\n",
    "    model = AutoAdapterModel.from_pretrained(config['model_name'], num_labels=config['num_labels'])\n",
    "    logger.info(\"Successfully loaded as AutoAdapterModel\")\n",
    "\n",
    "    lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "\n",
    "    source_adapter_name = f\"lang_{source_language}\"\n",
    "    model.add_adapter(source_adapter_name, config=lang_adapter_config)\n",
    "    logger.info(f\"Added source language adapter: {source_adapter_name}\")\n",
    "\n",
    "    target_adapter_name = f\"lang_{target_language}\"\n",
    "    model.add_adapter(target_adapter_name, config=lang_adapter_config)\n",
    "    logger.info(f\"Added target language adapter: {target_adapter_name}\")\n",
    "\n",
    "    task_adapter_name = \"sentiment_task\"\n",
    "    task_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=16)\n",
    "    model.add_adapter(task_adapter_name, config=task_adapter_config)\n",
    "\n",
    "    model.add_classification_head(\n",
    "        task_adapter_name,\n",
    "        num_labels=config['num_labels'],\n",
    "        id2label={i: label for i, label in enumerate(config['class_names'])}\n",
    "    )\n",
    "\n",
    "    return model, tokenizer, source_adapter_name, target_adapter_name, task_adapter_name\n",
    "\n",
    "def setup_madx_adapter(config, source_language, target_language):\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['extern_model_name'])\n",
    "    model = AutoAdapterModel.from_pretrained(config['model_name'], num_labels=config['num_labels'])\n",
    "\n",
    "    # I chose to use a MAD-X style configuration (using standard AdapterConfig)\n",
    "    # reason being, it typically uses smaller reduction factors for language adapters\n",
    "    lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "    task_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=16)\n",
    "\n",
    "    model.add_adapter(f\"lang_{source_language}\", config=lang_adapter_config)\n",
    "    model.add_adapter(f\"lang_{target_language}\", config=lang_adapter_config)\n",
    "\n",
    "    model.add_adapter(\"sentiment\", config=task_adapter_config)\n",
    "    model.add_classification_head(\"sentiment\", num_labels=config['num_labels'])\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def train_cross_lingual_transfer(model, source_train_loader, target_train_loader,\n",
    "                               val_loader, config, source_adapter, target_adapter, task_adapter):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    logger.info(\"Phase 1: Training source language + task adapters...\")\n",
    "\n",
    "    model.set_active_adapters([source_adapter, task_adapter])\n",
    "    model.train_adapter([source_adapter, task_adapter])\n",
    "\n",
    "    trainable_params = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params.append(param)\n",
    "\n",
    "    optimizer_source = torch.optim.AdamW(trainable_params, lr=config['learning_rate'])\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        progress_bar = tqdm(source_train_loader, desc=f\"Source Epoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer_source.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(trainable_params, config['max_grad_norm'])\n",
    "            optimizer_source.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        avg_loss = total_loss / len(source_train_loader)\n",
    "        logger.info(f\"Source Epoch {epoch+1}: Average Loss = {avg_loss:.4f}\")\n",
    "\n",
    "        val_accuracy = validate_model(model, val_loader, device)\n",
    "        logger.info(f\"Source Epoch {epoch+1}: Validation Accuracy = {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    logger.info(\"Phase 2: Training target language adapter...\")\n",
    "\n",
    "\n",
    "    model.set_active_adapters([target_adapter, task_adapter])\n",
    "    model.train_adapter([target_adapter])\n",
    "\n",
    "    target_params = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and target_adapter in name:\n",
    "            target_params.append(param)\n",
    "\n",
    "\n",
    "    optimizer_target = torch.optim.AdamW(target_params, lr=config['learning_rate'] * 0.1)\n",
    "\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        progress_bar = tqdm(target_train_loader, desc=f\"Target Epoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer_target.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(target_params, config['max_grad_norm'])\n",
    "            optimizer_target.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        avg_loss = total_loss / len(target_train_loader)\n",
    "        logger.info(f\"Target Epoch {epoch+1}: Average Loss = {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation on target language\n",
    "        val_accuracy = validate_model(model, val_loader, device)\n",
    "        logger.info(f\"Target Epoch {epoch+1}: Validation Accuracy = {val_accuracy:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predicted = torch.max(outputs.logits.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def load_pretrained_lang_adapters(model, source_language, target_language):\n",
    "    try:\n",
    "        model.load_adapter(f\"lang/{source_language}\", source=\"hf\", load_as=f\"lang_{source_language}\")\n",
    "        logger.info(f\"Loaded pretrained {source_language} adapter\")\n",
    "    except:\n",
    "        logger.warning(f\"No pretrained adapter found for {source_language}, using random initialization\")\n",
    "\n",
    "    try:\n",
    "        model.load_adapter(f\"lang/{target_language}\", source=\"hf\", load_as=f\"lang_{target_language}\")\n",
    "        logger.info(f\"Loaded pretrained {target_language} adapter\")\n",
    "    except:\n",
    "        logger.warning(f\"No pretrained adapter found for {target_language}, using random initialization\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_afro_xlmr_adapter(source_language, target_language='sot'):\n",
    "    config = {\n",
    "        'extern_model_name': f'Davlan/afro-xlmr-base',\n",
    "        'model_name': f'./xmlr_sentiment_model_{source_language}',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    model, tokenizer, src_adapter, tgt_adapter, task_adapter = setup_crosslingual_adapters(\n",
    "    config, source_language, target_language)\n",
    "\n",
    "    logger.info(\"Loading source data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{source_language}')\n",
    "\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    source_train_loader, source_val_loader, source_test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column'],\n",
    "        lang=source_language\n",
    "    )\n",
    "\n",
    "    logger.info(\"Loading target data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{target_language}')\n",
    "\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    target_train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column'],\n",
    "        lang=target_language\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Starting sequential cross-lingual training...\")\n",
    "    model = train_cross_lingual_transfer(\n",
    "        model, source_train_loader, target_train_loader, val_loader,\n",
    "        config, src_adapter, tgt_adapter, task_adapter\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        logger.info(\"Attempting to save model and tokenizer\")\n",
    "        model.save_pretrained(f\"./cross_lingual_model_{source_language}_{target_language}\")\n",
    "        tokenizer.save_pretrained(f\"./cross_lingual_model_{source_language}_{target_language}\")\n",
    "    except:\n",
    "        logger.info(\"Failed to save model and tokenizer\")\n",
    "\n",
    "    # Test evaluation: Showing results after training and adapters\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{target_language}_adapters.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Saving the adapters\n",
    "    # model.save_adapter(f\"./adapters/{src_adapter}\", src_adapter)\n",
    "    # model.save_adapter(f\"./adapters/{tgt_adapter}\", tgt_adapter)\n",
    "    # model.save_adapter(f\"./adapters/{task_adapter}\", task_adapter)\n",
    "\n",
    "\n",
    "train_afro_xlmr_adapter('swa','sot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8590b126ea01cb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:17:17.032929Z",
     "start_time": "2025-05-24T08:16:49.399333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 10:16:50,951 - INFO - Adding head 'default' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}, 'use_pooler': False, 'bias': True, 'dropout_prob': None}.\n",
      "2025-05-24 10:16:50,953 - INFO - Adding head 'sentiment_task' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'negative': 0, 'neutral': 1, 'positive': 2}, 'use_pooler': False, 'bias': True, 'dropout_prob': None}.\n",
      "2025-05-24 10:16:51,088 - INFO - Successfully loaded as AutoAdapterModel\n",
      "2025-05-24 10:16:51,088 - INFO - Loading target data...\n",
      "2025-05-24 10:16:55,320 - INFO - Data loaded successfully: 1740 training, 349 validation, 349 test examples\n",
      "2025-05-24 10:16:55,321 - INFO - Creating data loaders...\n",
      "2025-05-24 10:16:55,322 - INFO - Evaluating on test set...\n",
      "Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]2025-05-24 10:16:55,329 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:   5%|▍         | 1/22 [00:01<00:21,  1.04s/it]2025-05-24 10:16:56,373 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:   9%|▉         | 2/22 [00:02<00:20,  1.02s/it]2025-05-24 10:16:57,385 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  14%|█▎        | 3/22 [00:03<00:19,  1.01s/it]2025-05-24 10:16:58,383 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  18%|█▊        | 4/22 [00:04<00:18,  1.01s/it]2025-05-24 10:16:59,399 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  23%|██▎       | 5/22 [00:05<00:17,  1.01s/it]2025-05-24 10:17:00,392 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  27%|██▋       | 6/22 [00:06<00:16,  1.00s/it]2025-05-24 10:17:01,391 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  32%|███▏      | 7/22 [00:07<00:15,  1.01s/it]2025-05-24 10:17:02,404 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  36%|███▋      | 8/22 [00:08<00:14,  1.00s/it]2025-05-24 10:17:03,398 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  41%|████      | 9/22 [00:09<00:13,  1.00s/it]2025-05-24 10:17:04,404 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  45%|████▌     | 10/22 [00:10<00:11,  1.00it/s]2025-05-24 10:17:05,382 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  50%|█████     | 11/22 [00:11<00:10,  1.01it/s]2025-05-24 10:17:06,372 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  55%|█████▍    | 12/22 [00:12<00:09,  1.01it/s]2025-05-24 10:17:07,348 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  59%|█████▉    | 13/22 [00:13<00:08,  1.01it/s]2025-05-24 10:17:08,334 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  64%|██████▎   | 14/22 [00:14<00:07,  1.01it/s]2025-05-24 10:17:09,330 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  68%|██████▊   | 15/22 [00:14<00:06,  1.01it/s]2025-05-24 10:17:10,306 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  73%|███████▎  | 16/22 [00:15<00:05,  1.01it/s]2025-05-24 10:17:11,296 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  77%|███████▋  | 17/22 [00:16<00:04,  1.01it/s]2025-05-24 10:17:12,292 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  82%|████████▏ | 18/22 [00:17<00:03,  1.01it/s]2025-05-24 10:17:13,283 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  86%|████████▋ | 19/22 [00:18<00:02,  1.01it/s]2025-05-24 10:17:14,263 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  91%|█████████ | 20/22 [00:19<00:01,  1.02it/s]2025-05-24 10:17:15,220 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating:  95%|█████████▌| 21/22 [00:20<00:00,  1.03it/s]2025-05-24 10:17:16,184 - WARNING - There are adapters available but none are activated for the forward pass.\n",
      "Evaluating: 100%|██████████| 22/22 [00:21<00:00,  1.02it/s]\n",
      "C:\\Users\\User\\Desktop\\UP\\COS 760 (Natural Language Processing)\\Research\\Environment\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-24 10:17:16,995 - INFO - Test Results:\n",
      "2025-05-24 10:17:16,995 - INFO - Loss: 1.8235\n",
      "2025-05-24 10:17:16,996 - INFO - Accuracy: 0.0544\n",
      "2025-05-24 10:17:16,997 - INFO - Precision: 0.0030\n",
      "2025-05-24 10:17:16,997 - INFO - Recall: 0.0544\n",
      "2025-05-24 10:17:16,998 - INFO - F1 Score: 0.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to afroxlmr_results_sot_adapters.csv\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1, all_preds, all_labels\n",
    "\n",
    "\n",
    "def evaluate_afro_xlmr_adapter(source_language,target_language):\n",
    "    config = {\n",
    "        'extern_model_name': f'Davlan/afro-xlmr-base',\n",
    "        'model_name': f'./xmlr_sentiment_model_{source_language}',\n",
    "        'adapter_model_name': f'./cross_lingual_model_{source_language}_{target_language}',\n",
    "        'num_labels': 3,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_steps': 0,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'text_column': 'text',\n",
    "        'label_column': 'label',\n",
    "        'class_names': ['negative', 'neutral', 'positive']\n",
    "    }\n",
    "\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(config['extern_model_name'])\n",
    "\n",
    "    try:\n",
    "        model = AutoAdapterModel.from_pretrained(config['adapter_model_name'], num_labels=config['num_labels'])\n",
    "        logger.info(\"Successfully loaded as AutoAdapterModel\")\n",
    "    except:\n",
    "        exit(9)\n",
    "\n",
    "    logger.info(\"Loading target data...\")\n",
    "    train_df, val_df, test_df = load_data(f'{target_language}')\n",
    "\n",
    "    logger.info(\"Creating data loaders...\")\n",
    "    target_train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_df, val_df, test_df,\n",
    "        tokenizer,\n",
    "        batch_size=config['batch_size'],\n",
    "        text_column=config['text_column'],\n",
    "        label_column=config['label_column'],\n",
    "        lang=target_language\n",
    "    )\n",
    "    # Test evaluation: Showing results after training and adapters\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {test_precision:.4f}\")\n",
    "    logger.info(f\"Recall: {test_recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results_df_afro = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"test_f1\": test_f1,\n",
    "    \"test_precision\": test_precision,\n",
    "    \"test_recall\": test_recall,\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"batch_size\": config['batch_size'],\n",
    "}\n",
    "\n",
    "    path = f\"afroxlmr_results_{target_language}_adapters.csv\"\n",
    "    pd.DataFrame([results_df_afro]).to_csv(path, index=False)\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "    # Saving the individual adapters\n",
    "    # model.save_adapter(f\"./adapters/{src_adapter}\", src_adapter)\n",
    "    # model.save_adapter(f\"./adapters/{tgt_adapter}\", tgt_adapter)\n",
    "    # model.save_adapter(f\"./adapters/{task_adapter}\", task_adapter)\n",
    "\n",
    "evaluate_afro_xlmr_adapter('swa','sot')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
